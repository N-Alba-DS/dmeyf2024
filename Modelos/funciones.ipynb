{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ganancia(model, X, y, prop):\n",
    "    y_pred = model.predict(X)\n",
    "    return f1_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_gan_eval(y_pred, data):\n",
    "    weight = data.get_weight()\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(expected, actual, buckets=10):\n",
    "\n",
    "    def psi_formula(expected_prop, actual_prop):\n",
    "        result = (actual_prop - expected_prop) * np.log(actual_prop / expected_prop)\n",
    "        return result\n",
    "\n",
    "    expected_not_null = expected.dropna()\n",
    "    actual_not_null = actual.dropna()\n",
    "\n",
    "    bin_edges = pd.qcut(expected_not_null, q=buckets, duplicates='drop').unique()\n",
    "    bin_edges2 = [edge.left for edge in bin_edges] + [edge.right for edge in bin_edges]\n",
    "    breakpoints = sorted(list(set(bin_edges2)))\n",
    "\n",
    "    expected_counts, _ = np.histogram(expected_not_null, bins=breakpoints)\n",
    "    actual_counts, _ = np.histogram(actual_not_null, bins=breakpoints)\n",
    "\n",
    "    expected_prop = expected_counts / len(expected_not_null)\n",
    "    actual_prop = actual_counts / len(actual_not_null)\n",
    "\n",
    "    psi_not_null = psi_formula(expected_prop, actual_prop).sum()\n",
    "\n",
    "    psi_null = 0\n",
    "\n",
    "    if expected.isnull().sum() > 0 and actual.isnull().sum() > 0 :\n",
    "      expected_null_percentage = expected.isnull().mean()\n",
    "      actual_null_percentage = actual.isnull().mean()\n",
    "      psi_null = psi_formula(expected_null_percentage, actual_null_percentage)\n",
    "\n",
    "    return psi_not_null + psi_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creador clase ternaria\n",
    "\n",
    "# df_parallel = pd.read_csv(r\"C:\\Users\\Admin\\Documents\\1_Notebook\\1_Estudio\\1_UBA_Maestria_DS\\1_Especializacion\\1_Segundo_Semestre\\DMEyF\\Git\\dmeyf2024\\datasets\\competencia_01_crudo.csv\")\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# # Crear la columna clase_ternaria usando la columna 'foto_mes' basada en la presencia real\n",
    "\n",
    "# df_ternaria= duckdb.query('''\n",
    "\n",
    "#     WITH siguiente_mes AS (\n",
    "\n",
    "#         SELECT\n",
    "\n",
    "#             numero_de_cliente,\n",
    "\n",
    "#             foto_mes,\n",
    "\n",
    "#             -- Obtener los meses siguientes en los que el cliente está presente\n",
    "\n",
    "#             LEAD(foto_mes, 1) OVER (PARTITION BY numero_de_cliente ORDER BY foto_mes) AS foto_mes_proximo1,\n",
    "\n",
    "#             LEAD(foto_mes, 2) OVER (PARTITION BY numero_de_cliente ORDER BY foto_mes) AS foto_mes_proximo2\n",
    "\n",
    "#         FROM df_parallel\n",
    "\n",
    "#     )\n",
    "\n",
    "#     SELECT\n",
    "\n",
    "#         numero_de_cliente,\n",
    "\n",
    "#         foto_mes,\n",
    "\n",
    "#         CASE\n",
    "\n",
    "#             -- Si el cliente está en los dos meses consecutivos siguientes\n",
    "\n",
    "#             WHEN foto_mes_proximo1 = foto_mes + 1 AND foto_mes_proximo2 = foto_mes + 2 THEN 'CONTINUA'\n",
    "\n",
    "#             -- Si el cliente no está en el siguiente mes\n",
    "\n",
    "#             WHEN foto_mes_proximo1 IS NULL OR foto_mes_proximo1 <> foto_mes + 1 THEN 'BAJA+1'\n",
    "\n",
    "#             -- Si el cliente está en el siguiente mes pero no en el segundo mes consecutivo\n",
    "\n",
    "#             WHEN foto_mes_proximo1 = foto_mes + 1 AND (foto_mes_proximo2 IS NULL OR foto_mes_proximo2 <> foto_mes + 2) THEN 'BAJA+2'\n",
    "\n",
    "#             ELSE NULL\n",
    "\n",
    "#         END AS clase_ternaria\n",
    "\n",
    "#     FROM siguiente_mes\n",
    "\n",
    "#     ORDER BY numero_de_cliente, foto_mes\n",
    "\n",
    "#     ''')\n",
    "\n",
    "# df_ternaria = df_ternaria.to_df()\n",
    "# df_ternaria = df_ternaria[['numero_de_cliente', 'foto_mes', 'clase_ternaria']]\n",
    "\n",
    "\n",
    "# df_parallel = df_parallel.merge(df_ternaria, on=['numero_de_cliente', 'foto_mes'], how='left')\n",
    "\n",
    "# df_train = df_parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# con = duckdb.connect(database=':memory:', read_only=False)\n",
    "\n",
    "# ruta_csv = r\"C:\\Users\\Admin\\Documents\\1_Notebook\\1_Estudio\\1_UBA_Maestria_DS\\1_Especializacion\\1_Segundo_Semestre\\DMEyF\\datasets\\competencia_2\\competencia_02_f_e_lags.parquet\"\n",
    "\n",
    "# con.execute(f\"CREATE TABLE df_train AS SELECT * FROM read_parquet('{ruta_csv}')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
