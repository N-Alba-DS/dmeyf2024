{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ganancia(model, X, y, prop):\n",
    "    y_pred = model.predict(X)\n",
    "    return f1_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_gan_eval(y_pred, data):\n",
    "    weight = data.get_weight()\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(expected, actual, buckets=10):\n",
    "\n",
    "    def psi_formula(expected_prop, actual_prop):\n",
    "        result = (actual_prop - expected_prop) * np.log(actual_prop / expected_prop)\n",
    "        return result\n",
    "\n",
    "    expected_not_null = expected.dropna()\n",
    "    actual_not_null = actual.dropna()\n",
    "\n",
    "    bin_edges = pd.qcut(expected_not_null, q=buckets, duplicates='drop').unique()\n",
    "    breakpoints = sorted(set(\n",
    "    [edge.left for edge in bin_edges if isinstance(edge, pd.Interval)] + \n",
    "    [edge.right for edge in bin_edges if isinstance(edge, pd.Interval)]))\n",
    "\n",
    "    expected_counts, _ = np.histogram(expected_not_null, bins=breakpoints)\n",
    "    actual_counts, _ = np.histogram(actual_not_null, bins=breakpoints)\n",
    "\n",
    "    expected_prop = expected_counts / len(expected_not_null)\n",
    "    actual_prop = actual_counts / len(actual_not_null)\n",
    "\n",
    "    psi_not_null = psi_formula(expected_prop, actual_prop).sum()\n",
    "\n",
    "    psi_null = 0\n",
    "\n",
    "    if expected.isnull().sum() > 0 and actual.isnull().sum() > 0 :\n",
    "      expected_null_percentage = expected.isnull().mean()\n",
    "      actual_null_percentage = actual.isnull().mean()\n",
    "      psi_null = psi_formula(expected_null_percentage, actual_null_percentage)\n",
    "\n",
    "    return psi_not_null + psi_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creador clase ternaria\n",
    "\n",
    "# df_parallel = pd.read_csv(r\"C:\\Users\\Admin\\Documents\\1_Notebook\\1_Estudio\\1_UBA_Maestria_DS\\1_Especializacion\\1_Segundo_Semestre\\DMEyF\\Git\\dmeyf2024\\datasets\\competencia_01_crudo.csv\")\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# # Crear la columna clase_ternaria usando la columna 'foto_mes' basada en la presencia real\n",
    "\n",
    "# df_ternaria= duckdb.query('''\n",
    "\n",
    "#     WITH siguiente_mes AS (\n",
    "\n",
    "#         SELECT\n",
    "\n",
    "#             numero_de_cliente,\n",
    "\n",
    "#             foto_mes,\n",
    "\n",
    "#             -- Obtener los meses siguientes en los que el cliente está presente\n",
    "\n",
    "#             LEAD(foto_mes, 1) OVER (PARTITION BY numero_de_cliente ORDER BY foto_mes) AS foto_mes_proximo1,\n",
    "\n",
    "#             LEAD(foto_mes, 2) OVER (PARTITION BY numero_de_cliente ORDER BY foto_mes) AS foto_mes_proximo2\n",
    "\n",
    "#         FROM df_parallel\n",
    "\n",
    "#     )\n",
    "\n",
    "#     SELECT\n",
    "\n",
    "#         numero_de_cliente,\n",
    "\n",
    "#         foto_mes,\n",
    "\n",
    "#         CASE\n",
    "\n",
    "#             -- Si el cliente está en los dos meses consecutivos siguientes\n",
    "\n",
    "#             WHEN foto_mes_proximo1 = foto_mes + 1 AND foto_mes_proximo2 = foto_mes + 2 THEN 'CONTINUA'\n",
    "\n",
    "#             -- Si el cliente no está en el siguiente mes\n",
    "\n",
    "#             WHEN foto_mes_proximo1 IS NULL OR foto_mes_proximo1 <> foto_mes + 1 THEN 'BAJA+1'\n",
    "\n",
    "#             -- Si el cliente está en el siguiente mes pero no en el segundo mes consecutivo\n",
    "\n",
    "#             WHEN foto_mes_proximo1 = foto_mes + 1 AND (foto_mes_proximo2 IS NULL OR foto_mes_proximo2 <> foto_mes + 2) THEN 'BAJA+2'\n",
    "\n",
    "#             ELSE NULL\n",
    "\n",
    "#         END AS clase_ternaria\n",
    "\n",
    "#     FROM siguiente_mes\n",
    "\n",
    "#     ORDER BY numero_de_cliente, foto_mes\n",
    "\n",
    "#     ''')\n",
    "\n",
    "# df_ternaria = df_ternaria.to_df()\n",
    "# df_ternaria = df_ternaria[['numero_de_cliente', 'foto_mes', 'clase_ternaria']]\n",
    "\n",
    "\n",
    "# df_parallel = df_parallel.merge(df_ternaria, on=['numero_de_cliente', 'foto_mes'], how='left')\n",
    "\n",
    "# df_train = df_parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# con = duckdb.connect(database=':memory:', read_only=False)\n",
    "\n",
    "# ruta_csv = r\"C:\\Users\\Admin\\Documents\\1_Notebook\\1_Estudio\\1_UBA_Maestria_DS\\1_Especializacion\\1_Segundo_Semestre\\DMEyF\\datasets\\competencia_2\\competencia_02_f_e_lags.parquet\"\n",
    "\n",
    "# con.execute(f\"CREATE TABLE df_train AS SELECT * FROM read_parquet('{ruta_csv}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_medidas(X_train, Y_train, w_train, X_test, Y_test, w_test):\n",
    "\n",
    "    lista_medidas = [accuracy_score, precision_score, recall_score, f1_score, roc_auc_score]\n",
    "    train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "    test_data = lgb.Dataset(X_test, label=X_test, weight=w_test)\n",
    "    df_voting = pd.DataFrame()\n",
    "\n",
    "    for semilla in semillas:\n",
    "        params = {\n",
    "            'objective': 'binary',  \n",
    "            'metric': 'binary_logloss',  \n",
    "            'seed': semilla, }\n",
    "        model_default = lgb.train(params, train_data)   \n",
    "        \n",
    "        df_voting[f'semilla_{semilla}'] = model_default.predict(X_test)\n",
    "\n",
    "    df_voting['promedio'] = df_voting.mean(axis=1)\n",
    "    y_pred_default = df_voting['promedio']\n",
    "    y_pred_labels = (y_pred_default >= 0.025).astype(int)\n",
    "    dicc_medidas = {}\n",
    "    \n",
    "    for medida in lista_medidas:\n",
    "     dicc_medidas[medida.__name__] = medida(Y_test, y_pred_labels)\n",
    "    ganancia = lgb_gan_eval(y_pred_default, test_data)\n",
    "    dicc_medidas['ganancia'] = ganancia[1]\n",
    "    \n",
    "    return dicc_medidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anotar_excel(path_excel, dicc_medidas):\n",
    "    if excel == True:\n",
    "    \n",
    "        wb = load_workbook(path_excel)\n",
    "        ws = wb.active\n",
    "\n",
    "        header_row = 1  \n",
    "        column_mapping = {cell.value: cell.column for cell in ws[header_row]}\n",
    "    \n",
    "    row_to_update = None\n",
    "\n",
    "    for row in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=1, max_col=1):\n",
    "        cell = row[0]  # La primera celda de la fila\n",
    "        if cell.value is None:  # Si el valor de la celda está vacía\n",
    "            print(f\"Primera celda vacía en la fila {cell.row}\")\n",
    "            row_to_update = cell.row\n",
    "            break\n",
    "\n",
    "    # Si no se encontró ninguna celda vacía, agregar al final\n",
    "    if row_to_update is None:\n",
    "        print(\"No se encontro celda vacía, agregando al final\")\n",
    "        row_to_update = ws.max_row + 1  # Agregar en una nueva fila al final\n",
    "\n",
    "    print(f\"Fila a actualizar: {row_to_update}\")\n",
    "    fila_actualizar = row_to_update  # Fila donde escribir los datos\n",
    "\n",
    "    for col_name, value in dicc_medidas.items():\n",
    "        if col_name in column_mapping:  # Asegurarse de que la columna existe\n",
    "            col_idx = column_mapping[col_name]\n",
    "            ws.cell(row=fila_actualizar, column=col_idx, value=value)\n",
    "\n",
    "    # Guardar los cambios\n",
    "    wb.save(path_excel)\n",
    "    \n",
    "    return print (f\"se actualizó fila {fila_actualizar} en el excel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_medidas(X_train, Y_train, w_train, X_test, Y_test, w_test):\n",
    "\n",
    "    lista_medidas = [accuracy_score, precision_score, recall_score, f1_score, roc_auc_score]\n",
    "    train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "    test_data = lgb.Dataset(X_test, label=Y_test, weight=w_test)\n",
    "    df_voting = pd.DataFrame()\n",
    "\n",
    "    for semilla in semillas:\n",
    "        params = {\n",
    "            'objective': 'binary',  \n",
    "            'metric': 'binary_logloss',  \n",
    "            'seed': semilla, }\n",
    "        model_default = lgb.train(params, train_data)   \n",
    "        \n",
    "        df_voting[f'semilla_{semilla}'] = model_default.predict(X_test)\n",
    "\n",
    "    df_voting['promedio'] = df_voting.mean(axis=1)\n",
    "    y_pred_default = df_voting['promedio']\n",
    "    y_pred_labels = (y_pred_default >= 0.025).astype(int)\n",
    "    \n",
    "    dicc_medidas = {}\n",
    "    \n",
    "    for medida in lista_medidas:\n",
    "     dicc_medidas[medida.__name__] = medida(Y_test, y_pred_labels)\n",
    "     \n",
    "    ganancia = lgb_gan_eval(y_pred_default, test_data)\n",
    "    dicc_medidas['ganancia'] = ganancia[1]\n",
    "    \n",
    "    return dicc_medidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculoGanancia(bajas,prediccion,corte,seed):\n",
    "    ''' \n",
    "    Calcula la ganancia para una semilla específica.\n",
    "    \n",
    "    Parámetros:\n",
    "    bajas: DataFrame con columnas \"numero_de_cliente\" y \"clase_ternaria\".\n",
    "    prediccion: DataFrame con columnas \"numero_de_cliente\" y \"Probabilidad\".\n",
    "    corte: int, cantidad de estímulos.\n",
    "    random_state: int, semilla para train_test_split.\n",
    "    \n",
    "    Retorna:\n",
    "    ganancia_publico: Ganancia para el público.\n",
    "    ganancia_privado: Ganancia para el privado.\n",
    "    '''\n",
    "    # Realizar el split en público y privado\n",
    "    Publico, Privado = train_test_split(\n",
    "        bajas,\n",
    "        test_size=0.7,\n",
    "        stratify=bajas['clase_ternaria'],\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    # Clientes que decido estimular\n",
    "    estimulos = prediccion.iloc[:corte] \n",
    "\n",
    "    # Obtener los estímulos en el conjunto público y privado\n",
    "    estimulos_publico = pd.merge(estimulos, Publico, on='numero_de_cliente', how='inner')\n",
    "    estimulos_privado = pd.merge(estimulos, Privado, on='numero_de_cliente', how='inner')\n",
    "\n",
    "    # Calcular los verdaderos positivos en cada conjunto\n",
    "    TP_publico = estimulos_publico[estimulos_publico['clase_ternaria'] == 'BAJA+2']\n",
    "    TP_privado = estimulos_privado[estimulos_privado['clase_ternaria'] == 'BAJA+2']\n",
    "\n",
    "    # 5. Calcular la ganancia para cada conjunto con normalización\n",
    "    # Primero, calculamos la ganancia en cada conjunto\n",
    "    ganancia_publico_sin_norm = (len(TP_publico) * 273000) - ((len(estimulos_publico) - len(TP_publico)) * 7000)\n",
    "    ganancia_privado_sin_norm = (len(TP_privado) * 273000) - ((len(estimulos_privado) - len(TP_privado)) * 7000)\n",
    "\n",
    "    # Luego, normalizamos dividiendo por el porcentaje correspondiente\n",
    "    ganancia_publico = ganancia_publico_sin_norm / 0.3\n",
    "    ganancia_privado = ganancia_privado_sin_norm / 0.7\n",
    "\n",
    "    return ganancia_publico, ganancia_privado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_punto_de_corte (dataset, mes_de_entrenamiento, mes_de_prueba, best_params, best_iteration, rango_cortes, semillas):\n",
    "    if isinstance(dataset, pd.DataFrame):\n",
    "        df_train = pd.read_parquet(dataset_path)\n",
    "    elif isinstance(dataset, str):\n",
    "        df_train = pd.read_parquet(dataset)\n",
    "    else: print('dataset debe ser un DataFrame o un string con el path del archivo')\n",
    "    \n",
    "    ganancia_acierto = 273000\n",
    "    costo_estimulo = 7000\n",
    "    mes_train = mes_de_entrenamiento\n",
    "    mes_test = mes_de_prueba\n",
    "    data = df_train\n",
    "    data['clase_peso'] = 1.0\n",
    "    data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "    data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "    data['clase_binaria'] = np.where(data['clase_ternaria']=='CONTINUA', 0, 1)\n",
    "    data['foto_mes'].unique()\n",
    "    if isinstance(mes_de_entrenamiento, list):\n",
    "        df_train = data[data['foto_mes'].isin(mes_train)]\n",
    "    else: df_train = data[data['foto_mes']==mes_train]\n",
    "    df_test = data[data['foto_mes']==mes_test]\n",
    "    clase_peso = df_train['clase_peso']\n",
    "    X_train = df_train.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "    Y_train =df_train['clase_binaria']\n",
    "    X_test = df_test.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "    Y_test =df_test['clase_binaria']\n",
    "    w_train = df_train['clase_peso']\n",
    "    w_test = df_test['clase_peso']\n",
    "    best_params = best_params\n",
    "    best_iter = best_iteration    \n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                                label=Y_train,\n",
    "                                weight=w_train)\n",
    "    best_iter = 1789\n",
    "\n",
    "    df_voting = pd.DataFrame()\n",
    "\n",
    "    for x in semillas:\n",
    "        params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': best_params['num_leaves'],\n",
    "        'learning_rate': best_params['learning_rate'],\n",
    "        'min_data_in_leaf': best_params['min_data_in_leaf'],\n",
    "        'feature_fraction': best_params['feature_fraction'],\n",
    "        'bagging_fraction': best_params['bagging_fraction'],\n",
    "        'seed': x,\n",
    "        'verbose': 0}\n",
    "            \n",
    "                \n",
    "        model = lgb.train(params,\n",
    "                        train_data,\n",
    "                        num_boost_round=best_iter)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        df_voting[f'prediccion_seed_{x}'] = y_pred\n",
    "\n",
    "    df_voting['prediccion'] = df_voting.mean(axis=1)\n",
    "    df_voting.index = X_test.index\n",
    "    bajas = pd.DataFrame({'numero_de_cliente': X_test['numero_de_cliente'], 'clase_ternaria': df_test['clase_ternaria']}, index= X_test.index)\n",
    "    prediccion = pd.DataFrame({'numero_de_cliente': X_test['numero_de_cliente'], 'probabilidad': df_voting ['prediccion']}, index=X_test.index) \n",
    "    resultados = []\n",
    "    cortes = range(5000, 20000, rango_cortes)\n",
    "\n",
    "\n",
    "    pred_model_sorted = prediccion.sort_values('probabilidad', ascending=False)\n",
    "\n",
    "    model_name = 'LightGBM'\n",
    "\n",
    "    # Iteramos sobre cada corte\n",
    "    for corte in cortes:\n",
    "        lista_ganancia_publico =[]\n",
    "        lista_ganancia_privado = []\n",
    "        for semilla in semillas: \n",
    "            ganancia_publico, ganancia_privado = calculoGanancia(bajas, pred_model_sorted, corte, semilla)        \n",
    "            lista_ganancia_publico.append(ganancia_publico)\n",
    "            lista_ganancia_privado.append(ganancia_privado)\n",
    "        promedio_ganancia_publico = np.mean(lista_ganancia_publico)\n",
    "        promedio_ganancia_privado = np.mean(lista_ganancia_privado)\n",
    "            \n",
    "        resultados.append({\n",
    "        'Modelo': model_name,\n",
    "        'Corte': corte,\n",
    "        'Ganancia Público': promedio_ganancia_publico,\n",
    "        'Ganancia Privado': promedio_ganancia_privado\n",
    "        })\n",
    "\n",
    "    # Convertimos los resultados en un DataFrame\n",
    "    resultados = pd.DataFrame(resultados)\n",
    "    resultados_pivot = resultados.pivot_table(\n",
    "    index='Corte',\n",
    "    columns='Modelo',\n",
    "    values=['Ganancia Público', 'Ganancia Privado'])\n",
    "\n",
    "    # Aplanamos las columnas para facilitar el acceso\n",
    "    resultados_pivot.columns = [f'{ganancia}_{modelo}' for ganancia, modelo in resultados_pivot.columns]\n",
    "\n",
    "    # Reordenamos las columnas alternando 'Público' y 'Privado' para cada modelo\n",
    "    # Ordenamos primero por el modelo, luego alternando entre 'Público' y 'Privado'\n",
    "    columnas_ordenadas = []\n",
    "    for modelo in resultados['Modelo'].unique():\n",
    "        columnas_ordenadas.append(f'Ganancia Público_{modelo}')\n",
    "        columnas_ordenadas.append(f'Ganancia Privado_{modelo}')\n",
    "\n",
    "    # Reorganizamos el DataFrame usando el nuevo orden de columnas\n",
    "    resultados_pivot = resultados_pivot[columnas_ordenadas]\n",
    "\n",
    "    # Convertimos el índice 'Corte' en una columna si prefieres tenerla como tal\n",
    "    resultados_pivot = resultados_pivot.reset_index()\n",
    "    maxima_ganancia_publico = resultados_pivot['Ganancia Público_LightGBM'].max()\n",
    "    maxima_ganancia_privado = resultados_pivot['Ganancia Privado_LightGBM'].max()\n",
    "\n",
    "\n",
    "    for indice, resultado in resultados_pivot.iterrows():\n",
    "        if resultado['Ganancia Público_LightGBM'] == maxima_ganancia_publico:\n",
    "            corte_maxima_ganancia_publico = indice  # Puedes ajustar según la lógica de \"corte\"\n",
    "            ganancia_si_corte_maxima_ganancia_publico = (\n",
    "                resultado['Ganancia Público_LightGBM'] + resultado['Ganancia Privado_LightGBM']\n",
    "            )\n",
    "            print(f'Ganancia si se hace corte por máxima ganancia público: {ganancia_si_corte_maxima_ganancia_publico}, el corte será {corte_maxima_ganancia_publico}')\n",
    "        \n",
    "        if resultado['Ganancia Privado_LightGBM'] == maxima_ganancia_privado:\n",
    "            corte_maxima_ganancia_privado = indice  # Puedes ajustar según la lógica de \"corte\"\n",
    "            ganancia_si_corte_maxima_ganancia_privado = (\n",
    "                resultado['Ganancia Público_LightGBM'] + resultado['Ganancia Privado_LightGBM']\n",
    "            )\n",
    "            print(f'Ganancia si se hace corte por máxima ganancia privado: {ganancia_si_corte_maxima_ganancia_privado}, el corte será {corte_maxima_ganancia_privado}')\n",
    "                \n",
    "    corte_publico_ganancia_total = resultados_pivot.loc[corte_maxima_ganancia_publico,'Ganancia Privado_LightGBM'] + resultados_pivot.loc[corte_maxima_ganancia_publico,'Ganancia Público_LightGBM']\n",
    "    corte_privado_ganancia_total = resultados_pivot.loc[corte_maxima_ganancia_privado,'Ganancia Privado_LightGBM'] + resultados_pivot.loc[corte_maxima_ganancia_privado,'Ganancia Público_LightGBM']\n",
    "    corte_maxima_ganancia_total = corte_maxima_ganancia_privado if corte_privado_ganancia_total > corte_publico_ganancia_total else corte_maxima_ganancia_publico\n",
    "    incentivos = resultados_pivot.loc[corte_maxima_ganancia_total,'Corte']\n",
    "    print (f'El corte recomendado por máxima ganancia total es {corte_maxima_ganancia_total} con un incentivo de {incentivos}')\n",
    "    return incentivos, resultados_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hacer_anotacion_corte (dataset:str, extra:str, df_train:pd.DataFrame, incentivos:int, mensaje:str):\n",
    "    \"\"\"\n",
    "    variables: fecha,hora,dataset,cantidad_variables,corte,extra\n",
    "    \"\"\"\n",
    "    \n",
    "    fecha = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    hora = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    cantidad_variables = df_train.shape\n",
    "    \n",
    "    dataframe = pd.read_csv(r\"../../anotaciones_punto_de_corte.csv\")\n",
    "    nueva_fila = pd.DataFrame({'fecha':[fecha],'hora':[hora],'dataset':[dataset],'cantidad_variables':[cantidad_variables],'corte':[incentivos],'extra':[extra],'mensaje':[mensaje]})\n",
    "    dataframe = pd.concat([dataframe, nueva_fila], ignore_index=True)\n",
    "    dataframe.to_csv(r\"../../anotaciones_punto_de_corte.csv\", index=False)\n",
    "    os.system('git add ../../anotaciones_punto_de_corte.csv')\n",
    "    os.system(f\"git commit -m '{mensaje}'\")\n",
    "    os.system(\"git push\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hacer_anotacion_back_testing (dataset:str, extra:str, df_train:pd.DataFrame, continuas:int, baja_1:int, baja_2:int , mensaje:str):\n",
    "    \"\"\"\n",
    "    variables: fecha,hora,dataset,continuas,baja+1,baja+2,corte,extra\n",
    "    \"\"\"\n",
    "    \n",
    "    fecha = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    hora = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    cantidad_variables = df_train.shape\n",
    "    \n",
    "    dataframe = pd.read_csv(r\"../../anotaciones_back_testing.csv\")\n",
    "    nueva_fila = pd.DataFrame({'fecha':[fecha],'hora':[hora],'dataset':[dataset],'cantidad_variables':[cantidad_variables],'continuas':[continuas], 'baja+1':[baja_1],'extra':[baja_2],'mensaje':[mensaje]})\n",
    "    dataframe = pd.concat([dataframe, nueva_fila], ignore_index=True)\n",
    "    dataframe.to_csv(r\"../../anotaciones_back_testing.csv\", index=False)\n",
    "    os.system('git add ../../anotaciones_back_testing.csv')\n",
    "    os.system(f\"git commit -m '{mensaje}'\")\n",
    "    os.system(\"git push\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
