{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias y kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#visualizacion\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#modelos\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree,  _tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "#base de datos\n",
    "import duckdb\n",
    "%load_ext sql\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "%sql duckdb:///:memory:\n",
    "\n",
    "#optimizacion\n",
    "import time\n",
    "import optuna\n",
    "from optuna.study import MaxTrialsCallback\n",
    "from optuna.trial import TrialState\n",
    "from optuna.visualization import plot_param_importances, plot_contour,  plot_slice, plot_optimization_history\n",
    "import plotly.express as px\n",
    "\n",
    "#kaggle y otros\n",
    "import os\n",
    "import kaggle \n",
    "import glob\n",
    "\n",
    "#Shap values\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "numeros_random = random.sample(range(1, 1000), 100)\n",
    "semillas =[ 400009,  500009, 500011, 500021, 600009]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/n_alba_dscience/'\n",
    "modelos_path = base_path + 'buckets/b1/modelos/'\n",
    "db_path = base_path + 'buckets/b1/db/'\n",
    "datasets_path = base_path + 'buckets/b1/datasets/'\n",
    "exp_path = base_path + 'buckets/b1/exp/'\n",
    "save_path = base_path + 'buckets/b1/'\n",
    "\n",
    "\n",
    "# 1 - dataset sólo con clase ternaria\n",
    "dataset_clase_ternaria = datasets_path + 'competencia_02_ct.parquet'\n",
    "\n",
    "# 2 - dataset con clase ternaria creada y feature engineering de lags \n",
    "dataset_lags_clase_ternaria = datasets_path + 'competencia_02_lags_y_clase_ternaria.parquet'\n",
    "\n",
    "\n",
    "\n",
    "# 3 - dataset con clase ternaria creada y feature engineering de lags y deltas\n",
    "dataset_lags_deltas_y_clase_ternaria = datasets_path + 'competencia_02_lags_deltas_y_clase_ternaria.parquet'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_l = r'C:\\Users\\Admin\\Documents\\1_Notebook\\1_Estudio\\1_UBA_Maestria_DS\\1_Especializacion\\1_Segundo_Semestre\\DMEyF'\n",
    "optuna_path_l = base_path_l + r'\\Optuna\\rf_segmentacion1\\optimization_tree.db'\n",
    "\n",
    "entregas_l = base_path_l + r'\\Entregas'\n",
    "db_path_l = base_path_l + r'datasets\\competencia_2'\n",
    "\n",
    "datasets_path_l = base_path_l + r'\\datasets\\competencia_2'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1 dataset sólo con clase ternaria\n",
    "dataset_clase_ternaria_l = datasets_path_l + r'\\competencia_02_ct.parquet'\n",
    "\n",
    "# 2 dataset con clase ternaria creada y feature engineering de lags \n",
    "dataset_lags_clase_ternaria_l = datasets_path_l + r'\\competencia_02_lags_y_clase_ternaria.parquet'\n",
    "\n",
    "# 3 dataset con clase ternaria creada y feature engineering de lags y deltas\n",
    "dataset_lags_deltas_y_clase_ternaria_l = datasets_path_l + r'\\competencia_02_lags_deltas_y_clase_ternaria.parquet'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
