{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precarga de librerias y funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "ERROR: Invalid requirement: ''\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "pip install shap ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "ERROR: Invalid requirement: ''\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "pip install openpyxl ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "ERROR: Invalid requirement: ''\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "pip install imblearn ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#visualizacion\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#modelos\n",
    "import lightgbm as lgb\n",
    "from lightgbm.callback import early_stopping\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree,  _tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "\n",
    "\n",
    "#base de datos\n",
    "import duckdb\n",
    "%load_ext sql\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "%sql duckdb:///:memory:\n",
    "\n",
    "#optimizacion\n",
    "import time\n",
    "import optuna\n",
    "from optuna.study import MaxTrialsCallback\n",
    "from optuna.trial import TrialState\n",
    "from optuna.visualization import plot_param_importances, plot_contour,  plot_slice, plot_optimization_history\n",
    "import plotly.express as px\n",
    "\n",
    "#kaggle y otros\n",
    "import os\n",
    "import kaggle \n",
    "import glob\n",
    "from openpyxl import load_workbook\n",
    "from datetime import datetime\n",
    "import contextlib\n",
    "\n",
    "\n",
    "\n",
    "#Shap values\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "numeros_random = random.sample(range(1, 1000), 35)\n",
    "semillas =[ 400009,  500009, 500011, 500021, 600009]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/n_alba_dscience/'\n",
    "modelos_path = base_path + 'buckets/b1/modelos/'\n",
    "db_path = base_path + 'buckets/b1/db/'\n",
    "datasets_path = base_path + 'buckets/b1/datasets/'\n",
    "exp_path = base_path + 'buckets/b1/exp/'\n",
    "save_path = base_path + 'buckets/b1/'\n",
    "\n",
    "\n",
    "# 1 - dataset sólo con clase ternaria\n",
    "dataset_clase_ternaria = datasets_path + 'competencia_03_ct.parquet'\n",
    "dataset_clase_ternaria_sin_PCI = datasets_path + 'competencia_03_ct_sin_PCI.parquet'\n",
    "dataset_competencia_03_lags_deltas_y_clase_ternaria = datasets_path + 'competencia_03_lags_deltas_y_clase_ternaria.parquet'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_l = r'C:\\Users\\Admin\\Documents\\1_Notebook\\1_Estudio\\1_UBA_Maestria_DS\\1_Especializacion\\1_Segundo_Semestre\\DMEyF'\n",
    "optuna_path_l = base_path_l + r'\\Optuna\\rf_segmentacion1\\optimization_tree.db'\n",
    "\n",
    "entregas_l = base_path_l + r'\\Entregas\\competencia_03'\n",
    "\n",
    "\n",
    "db_path_l = base_path_l + r'datasets\\competencia_3'\n",
    "\n",
    "datasets_path_l = base_path_l + r'\\datasets\\competencia_3'\n",
    "\n",
    "\n",
    "\n",
    "# Competencia 0\n",
    "# 1 dataset sólo con clase ternaria\n",
    "dataset_clase_ternaria_l = datasets_path_l + r'\\competencia_03_ct.parquet'\n",
    "dataset_clase_ternaria_sin_psi_l = datasets_path_l + r'\\competencia_03_ct_sin_psi.parquet'\n",
    "dataset_competencia_03_lags_deltas_y_clase_ternaria_l = datasets_path_l + r'\\competencia_03_lags_deltas_y_clase_ternaria.parquet'\n",
    "# 2 dataset con clase ternaria creada y feature engineering de lags \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_gan_eval(y_pred, data):\n",
    "    weight = data.get_weight()\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(expected, actual, buckets=10):\n",
    "\n",
    "    def psi_formula(expected_prop, actual_prop):\n",
    "        result = (actual_prop - expected_prop) * np.log(actual_prop / expected_prop)\n",
    "        return result\n",
    "\n",
    "    expected_not_null = expected.dropna()\n",
    "    actual_not_null = actual.dropna()\n",
    "\n",
    "    bin_edges = pd.qcut(expected_not_null, q=buckets, duplicates='drop').unique()\n",
    "    breakpoints = sorted(set(\n",
    "    [edge.left for edge in bin_edges if isinstance(edge, pd.Interval)] + \n",
    "    [edge.right for edge in bin_edges if isinstance(edge, pd.Interval)]))\n",
    "\n",
    "    expected_counts, _ = np.histogram(expected_not_null, bins=breakpoints)\n",
    "    actual_counts, _ = np.histogram(actual_not_null, bins=breakpoints)\n",
    "\n",
    "    expected_prop = expected_counts / len(expected_not_null)\n",
    "    actual_prop = actual_counts / len(actual_not_null)\n",
    "\n",
    "    psi_not_null = psi_formula(expected_prop, actual_prop).sum()\n",
    "\n",
    "    psi_null = 0\n",
    "\n",
    "    if expected.isnull().sum() > 0 and actual.isnull().sum() > 0 :\n",
    "      expected_null_percentage = expected.isnull().mean()\n",
    "      actual_null_percentage = actual.isnull().mean()\n",
    "      psi_null = psi_formula(expected_null_percentage, actual_null_percentage)\n",
    "\n",
    "    return psi_not_null + psi_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creador clase ternaria\n",
    "\n",
    "# df_parallel = pd.read_csv(r\"C:\\Users\\Admin\\Documents\\1_Notebook\\1_Estudio\\1_UBA_Maestria_DS\\1_Especializacion\\1_Segundo_Semestre\\DMEyF\\Git\\dmeyf2024\\datasets\\competencia_01_crudo.csv\")\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# # Crear la columna clase_ternaria usando la columna 'foto_mes' basada en la presencia real\n",
    "\n",
    "# df_ternaria= duckdb.query('''\n",
    "\n",
    "#     WITH siguiente_mes AS (\n",
    "\n",
    "#         SELECT\n",
    "\n",
    "#             numero_de_cliente,\n",
    "\n",
    "#             foto_mes,\n",
    "\n",
    "#             -- Obtener los meses siguientes en los que el cliente está presente\n",
    "\n",
    "#             LEAD(foto_mes, 1) OVER (PARTITION BY numero_de_cliente ORDER BY foto_mes) AS foto_mes_proximo1,\n",
    "\n",
    "#             LEAD(foto_mes, 2) OVER (PARTITION BY numero_de_cliente ORDER BY foto_mes) AS foto_mes_proximo2\n",
    "\n",
    "#         FROM df_parallel\n",
    "\n",
    "#     )\n",
    "\n",
    "#     SELECT\n",
    "\n",
    "#         numero_de_cliente,\n",
    "\n",
    "#         foto_mes,\n",
    "\n",
    "#         CASE\n",
    "\n",
    "#             -- Si el cliente está en los dos meses consecutivos siguientes\n",
    "\n",
    "#             WHEN foto_mes_proximo1 = foto_mes + 1 AND foto_mes_proximo2 = foto_mes + 2 THEN 'CONTINUA'\n",
    "\n",
    "#             -- Si el cliente no está en el siguiente mes\n",
    "\n",
    "#             WHEN foto_mes_proximo1 IS NULL OR foto_mes_proximo1 <> foto_mes + 1 THEN 'BAJA+1'\n",
    "\n",
    "#             -- Si el cliente está en el siguiente mes pero no en el segundo mes consecutivo\n",
    "\n",
    "#             WHEN foto_mes_proximo1 = foto_mes + 1 AND (foto_mes_proximo2 IS NULL OR foto_mes_proximo2 <> foto_mes + 2) THEN 'BAJA+2'\n",
    "\n",
    "#             ELSE NULL\n",
    "\n",
    "#         END AS clase_ternaria\n",
    "\n",
    "#     FROM siguiente_mes\n",
    "\n",
    "#     ORDER BY numero_de_cliente, foto_mes\n",
    "\n",
    "#     ''')\n",
    "\n",
    "# df_ternaria = df_ternaria.to_df()\n",
    "# df_ternaria = df_ternaria[['numero_de_cliente', 'foto_mes', 'clase_ternaria']]\n",
    "\n",
    "\n",
    "# df_parallel = df_parallel.merge(df_ternaria, on=['numero_de_cliente', 'foto_mes'], how='left')\n",
    "\n",
    "# df_train = df_parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# con = duckdb.connect(database=':memory:', read_only=False)\n",
    "\n",
    "# ruta_csv = r\"C:\\Users\\Admin\\Documents\\1_Notebook\\1_Estudio\\1_UBA_Maestria_DS\\1_Especializacion\\1_Segundo_Semestre\\DMEyF\\datasets\\competencia_2\\competencia_02_f_e_lags.parquet\"\n",
    "\n",
    "# con.execute(f\"CREATE TABLE df_train AS SELECT * FROM read_parquet('{ruta_csv}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_medidas(X_train, Y_train, w_train, X_test, Y_test, w_test):\n",
    "\n",
    "    lista_medidas = [accuracy_score, precision_score, recall_score, f1_score, roc_auc_score]\n",
    "    train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "    test_data = lgb.Dataset(X_test, label=X_test, weight=w_test)\n",
    "    df_voting = pd.DataFrame()\n",
    "\n",
    "    for semilla in semillas:\n",
    "        params = {\n",
    "            'objective': 'binary',  \n",
    "            'metric': 'binary_logloss',  \n",
    "            'seed': semilla, }\n",
    "        model_default = lgb.train(params, train_data)   \n",
    "        \n",
    "        df_voting[f'semilla_{semilla}'] = model_default.predict(X_test)\n",
    "\n",
    "    df_voting['promedio'] = df_voting.mean(axis=1)\n",
    "    y_pred_default = df_voting['promedio']\n",
    "    y_pred_labels = (y_pred_default >= 0.025).astype(int)\n",
    "    dicc_medidas = {}\n",
    "    \n",
    "    for medida in lista_medidas:\n",
    "     dicc_medidas[medida.__name__] = medida(Y_test, y_pred_labels)\n",
    "    ganancia = lgb_gan_eval(y_pred_default, test_data)\n",
    "    dicc_medidas['ganancia'] = ganancia[1]\n",
    "    \n",
    "    return dicc_medidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anotar_excel(path_excel, dicc_medidas):\n",
    "    if excel == True:\n",
    "    \n",
    "        wb = load_workbook(path_excel)\n",
    "        ws = wb.active\n",
    "\n",
    "        header_row = 1  \n",
    "        column_mapping = {cell.value: cell.column for cell in ws[header_row]}\n",
    "    \n",
    "    row_to_update = None\n",
    "\n",
    "    for row in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=1, max_col=1):\n",
    "        cell = row[0]  # La primera celda de la fila\n",
    "        if cell.value is None:  # Si el valor de la celda está vacía\n",
    "            print(f\"Primera celda vacía en la fila {cell.row}\")\n",
    "            row_to_update = cell.row\n",
    "            break\n",
    "\n",
    "    # Si no se encontró ninguna celda vacía, agregar al final\n",
    "    if row_to_update is None:\n",
    "        print(\"No se encontro celda vacía, agregando al final\")\n",
    "        row_to_update = ws.max_row + 1  # Agregar en una nueva fila al final\n",
    "\n",
    "    print(f\"Fila a actualizar: {row_to_update}\")\n",
    "    fila_actualizar = row_to_update  # Fila donde escribir los datos\n",
    "\n",
    "    for col_name, value in dicc_medidas.items():\n",
    "        if col_name in column_mapping:  # Asegurarse de que la columna existe\n",
    "            col_idx = column_mapping[col_name]\n",
    "            ws.cell(row=fila_actualizar, column=col_idx, value=value)\n",
    "\n",
    "    # Guardar los cambios\n",
    "    wb.save(path_excel)\n",
    "    \n",
    "    return print (f\"se actualizó fila {fila_actualizar} en el excel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_medidas(X_train, Y_train, w_train, X_test, Y_test, w_test):\n",
    "\n",
    "    lista_medidas = [accuracy_score, precision_score, recall_score, f1_score, roc_auc_score]\n",
    "    train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "    test_data = lgb.Dataset(X_test, label=Y_test, weight=w_test)\n",
    "    df_voting = pd.DataFrame()\n",
    "\n",
    "    for semilla in semillas:\n",
    "        params = {\n",
    "            'objective': 'binary',  \n",
    "            'metric': 'binary_logloss',  \n",
    "            'seed': semilla, }\n",
    "        model_default = lgb.train(params, train_data)   \n",
    "        \n",
    "        df_voting[f'semilla_{semilla}'] = model_default.predict(X_test)\n",
    "\n",
    "    df_voting['promedio'] = df_voting.mean(axis=1)\n",
    "    y_pred_default = df_voting['promedio']\n",
    "    y_pred_labels = (y_pred_default >= 0.025).astype(int)\n",
    "    \n",
    "    dicc_medidas = {}\n",
    "    \n",
    "    for medida in lista_medidas:\n",
    "     dicc_medidas[medida.__name__] = medida(Y_test, y_pred_labels)\n",
    "     \n",
    "    ganancia = lgb_gan_eval(y_pred_default, test_data)\n",
    "    dicc_medidas['ganancia'] = ganancia[1]\n",
    "    \n",
    "    return dicc_medidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculoGanancia(bajas,prediccion,corte,seed):\n",
    "    ''' \n",
    "    Calcula la ganancia para una semilla específica.\n",
    "    \n",
    "    Parámetros:\n",
    "    bajas: DataFrame con columnas \"numero_de_cliente\" y \"clase_ternaria\".\n",
    "    prediccion: DataFrame con columnas \"numero_de_cliente\" y \"Probabilidad\".\n",
    "    corte: int, cantidad de estímulos.\n",
    "    random_state: int, semilla para train_test_split.\n",
    "    \n",
    "    Retorna:\n",
    "    ganancia_publico: Ganancia para el público.\n",
    "    ganancia_privado: Ganancia para el privado.\n",
    "    '''\n",
    "    # Realizar el split en público y privado\n",
    "    Publico, Privado = train_test_split(\n",
    "        bajas,\n",
    "        test_size=0.7,\n",
    "        stratify=bajas['clase_ternaria'],\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    # Clientes que decido estimular\n",
    "    estimulos = prediccion.iloc[:corte] \n",
    "\n",
    "    # Obtener los estímulos en el conjunto público y privado\n",
    "    estimulos_publico = pd.merge(estimulos, Publico, on='numero_de_cliente', how='inner')\n",
    "    estimulos_privado = pd.merge(estimulos, Privado, on='numero_de_cliente', how='inner')\n",
    "\n",
    "    # Calcular los verdaderos positivos en cada conjunto\n",
    "    TP_publico = estimulos_publico[estimulos_publico['clase_ternaria'] == 'BAJA+2']\n",
    "    TP_privado = estimulos_privado[estimulos_privado['clase_ternaria'] == 'BAJA+2']\n",
    "\n",
    "    # 5. Calcular la ganancia para cada conjunto con normalización\n",
    "    # Primero, calculamos la ganancia en cada conjunto\n",
    "    ganancia_publico_sin_norm = (len(TP_publico) * 273000) - ((len(estimulos_publico) - len(TP_publico)) * 7000)\n",
    "    ganancia_privado_sin_norm = (len(TP_privado) * 273000) - ((len(estimulos_privado) - len(TP_privado)) * 7000)\n",
    "\n",
    "    # Luego, normalizamos dividiendo por el porcentaje correspondiente\n",
    "    ganancia_publico = ganancia_publico_sin_norm / 0.3\n",
    "    ganancia_privado = ganancia_privado_sin_norm / 0.7\n",
    "\n",
    "    return ganancia_publico, ganancia_privado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_punto_de_corte (dataset, mes_de_entrenamiento, mes_de_prueba, best_params, best_iteration, rango_cortes, semillas):\n",
    "    if isinstance(dataset, pd.DataFrame):\n",
    "        df_train = pd.read_parquet(dataset_path)\n",
    "    elif isinstance(dataset, str):\n",
    "        df_train = pd.read_parquet(dataset)\n",
    "    else: print('dataset debe ser un DataFrame o un string con el path del archivo')\n",
    "    \n",
    "    ganancia_acierto = 273000\n",
    "    costo_estimulo = 7000\n",
    "    mes_train = mes_de_entrenamiento\n",
    "    mes_test = mes_de_prueba\n",
    "    data = df_train\n",
    "    data['clase_peso'] = 1.0\n",
    "    data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "    data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "    data['clase_binaria'] = np.where(data['clase_ternaria']=='CONTINUA', 0, 1)\n",
    "    data['foto_mes'].unique()\n",
    "    if isinstance(mes_de_entrenamiento, list):\n",
    "        df_train = data[data['foto_mes'].isin(mes_train)]\n",
    "    else: df_train = data[data['foto_mes']==mes_train]\n",
    "    df_test = data[data['foto_mes']==mes_test]\n",
    "    clase_peso = df_train['clase_peso']\n",
    "    X_train = df_train.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "    Y_train =df_train['clase_binaria']\n",
    "    X_test = df_test.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "    Y_test =df_test['clase_binaria']\n",
    "    w_train = df_train['clase_peso']\n",
    "    w_test = df_test['clase_peso']\n",
    "    best_params = best_params\n",
    "    best_iter = best_iteration    \n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                                label=Y_train,\n",
    "                                weight=w_train)\n",
    "    best_iter = 1789\n",
    "\n",
    "    df_voting = pd.DataFrame()\n",
    "\n",
    "    for x in semillas:\n",
    "        params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': best_params['num_leaves'],\n",
    "        'learning_rate': best_params['learning_rate'],\n",
    "        'min_data_in_leaf': best_params['min_data_in_leaf'],\n",
    "        'feature_fraction': best_params['feature_fraction'],\n",
    "        'bagging_fraction': best_params['bagging_fraction'],\n",
    "        'seed': x,\n",
    "        'verbose': 0}\n",
    "            \n",
    "                \n",
    "        model = lgb.train(params,\n",
    "                        train_data,\n",
    "                        num_boost_round=best_iter)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        df_voting[f'prediccion_seed_{x}'] = y_pred\n",
    "\n",
    "    df_voting['prediccion'] = df_voting.mean(axis=1)\n",
    "    df_voting.index = X_test.index\n",
    "    bajas = pd.DataFrame({'numero_de_cliente': X_test['numero_de_cliente'], 'clase_ternaria': df_test['clase_ternaria']}, index= X_test.index)\n",
    "    prediccion = pd.DataFrame({'numero_de_cliente': X_test['numero_de_cliente'], 'probabilidad': df_voting ['prediccion']}, index=X_test.index) \n",
    "    resultados = []\n",
    "    cortes = range(5000, 20000, rango_cortes)\n",
    "\n",
    "\n",
    "    pred_model_sorted = prediccion.sort_values('probabilidad', ascending=False)\n",
    "\n",
    "    model_name = 'LightGBM'\n",
    "\n",
    "    # Iteramos sobre cada corte\n",
    "    for corte in cortes:\n",
    "        lista_ganancia_publico =[]\n",
    "        lista_ganancia_privado = []\n",
    "        for semilla in semillas: \n",
    "            ganancia_publico, ganancia_privado = calculoGanancia(bajas, pred_model_sorted, corte, semilla)        \n",
    "            lista_ganancia_publico.append(ganancia_publico)\n",
    "            lista_ganancia_privado.append(ganancia_privado)\n",
    "        promedio_ganancia_publico = np.mean(lista_ganancia_publico)\n",
    "        promedio_ganancia_privado = np.mean(lista_ganancia_privado)\n",
    "            \n",
    "        resultados.append({\n",
    "        'Modelo': model_name,\n",
    "        'Corte': corte,\n",
    "        'Ganancia Público': promedio_ganancia_publico,\n",
    "        'Ganancia Privado': promedio_ganancia_privado\n",
    "        })\n",
    "\n",
    "    # Convertimos los resultados en un DataFrame\n",
    "    resultados = pd.DataFrame(resultados)\n",
    "    resultados_pivot = resultados.pivot_table(\n",
    "    index='Corte',\n",
    "    columns='Modelo',\n",
    "    values=['Ganancia Público', 'Ganancia Privado'])\n",
    "\n",
    "    # Aplanamos las columnas para facilitar el acceso\n",
    "    resultados_pivot.columns = [f'{ganancia}_{modelo}' for ganancia, modelo in resultados_pivot.columns]\n",
    "\n",
    "    # Reordenamos las columnas alternando 'Público' y 'Privado' para cada modelo\n",
    "    # Ordenamos primero por el modelo, luego alternando entre 'Público' y 'Privado'\n",
    "    columnas_ordenadas = []\n",
    "    for modelo in resultados['Modelo'].unique():\n",
    "        columnas_ordenadas.append(f'Ganancia Público_{modelo}')\n",
    "        columnas_ordenadas.append(f'Ganancia Privado_{modelo}')\n",
    "\n",
    "    # Reorganizamos el DataFrame usando el nuevo orden de columnas\n",
    "    resultados_pivot = resultados_pivot[columnas_ordenadas]\n",
    "\n",
    "    # Convertimos el índice 'Corte' en una columna si prefieres tenerla como tal\n",
    "    resultados_pivot = resultados_pivot.reset_index()\n",
    "    maxima_ganancia_publico = resultados_pivot['Ganancia Público_LightGBM'].max()\n",
    "    maxima_ganancia_privado = resultados_pivot['Ganancia Privado_LightGBM'].max()\n",
    "\n",
    "\n",
    "    for indice, resultado in resultados_pivot.iterrows():\n",
    "        if resultado['Ganancia Público_LightGBM'] == maxima_ganancia_publico:\n",
    "            corte_maxima_ganancia_publico = indice  # Puedes ajustar según la lógica de \"corte\"\n",
    "            ganancia_si_corte_maxima_ganancia_publico = (\n",
    "                resultado['Ganancia Público_LightGBM'] + resultado['Ganancia Privado_LightGBM']\n",
    "            )\n",
    "            print(f'Ganancia si se hace corte por máxima ganancia público: {ganancia_si_corte_maxima_ganancia_publico}, el corte será {corte_maxima_ganancia_publico}')\n",
    "        \n",
    "        if resultado['Ganancia Privado_LightGBM'] == maxima_ganancia_privado:\n",
    "            corte_maxima_ganancia_privado = indice  # Puedes ajustar según la lógica de \"corte\"\n",
    "            ganancia_si_corte_maxima_ganancia_privado = (\n",
    "                resultado['Ganancia Público_LightGBM'] + resultado['Ganancia Privado_LightGBM']\n",
    "            )\n",
    "            print(f'Ganancia si se hace corte por máxima ganancia privado: {ganancia_si_corte_maxima_ganancia_privado}, el corte será {corte_maxima_ganancia_privado}')\n",
    "                \n",
    "    corte_publico_ganancia_total = resultados_pivot.loc[corte_maxima_ganancia_publico,'Ganancia Privado_LightGBM'] + resultados_pivot.loc[corte_maxima_ganancia_publico,'Ganancia Público_LightGBM']\n",
    "    corte_privado_ganancia_total = resultados_pivot.loc[corte_maxima_ganancia_privado,'Ganancia Privado_LightGBM'] + resultados_pivot.loc[corte_maxima_ganancia_privado,'Ganancia Público_LightGBM']\n",
    "    corte_maxima_ganancia_total = corte_maxima_ganancia_privado if corte_privado_ganancia_total > corte_publico_ganancia_total else corte_maxima_ganancia_publico\n",
    "    incentivos = resultados_pivot.loc[corte_maxima_ganancia_total,'Corte']\n",
    "    print (f'El corte recomendado por máxima ganancia total es {corte_maxima_ganancia_total} con un incentivo de {incentivos}')\n",
    "    return incentivos, resultados_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hacer_anotacion_corte (dataset:str, extra:str, df_train:pd.DataFrame, incentivos:int, mensaje:str):\n",
    "    \"\"\"\n",
    "    variables: fecha,hora,dataset,cantidad_variables,corte,extra\n",
    "    \"\"\"\n",
    "    \n",
    "    fecha = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    hora = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    cantidad_variables = df_train.shape\n",
    "    \n",
    "    dataframe = pd.read_csv(r\"../../anotaciones_punto_de_corte.csv\")\n",
    "    nueva_fila = pd.DataFrame({'fecha':[fecha],'hora':[hora],'dataset':[dataset],'cantidad_variables':[cantidad_variables],'corte':[incentivos],'extra':[extra],'mensaje':[mensaje]})\n",
    "    dataframe = pd.concat([dataframe, nueva_fila], ignore_index=True)\n",
    "    dataframe.to_csv(r\"../../anotaciones_punto_de_corte.csv\", index=False)\n",
    "    os.system('git add ../../anotaciones_punto_de_corte.csv')\n",
    "    os.system(f\"git commit -m '{mensaje}'\")\n",
    "    os.system(\"git push\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hacer_anotacion_back_testing (dataset:str, extra:str, df_train:pd.DataFrame, continuas:int, baja_1:int, baja_2:int , mensaje:str):\n",
    "    \"\"\"\n",
    "    variables: fecha,hora,dataset,continuas,baja+1,baja+2,corte,extra\n",
    "    \"\"\"\n",
    "    \n",
    "    fecha = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    hora = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    cantidad_variables = df_train.shape\n",
    "    \n",
    "    dataframe = pd.read_csv(r\"../../anotaciones_back_testing.csv\")\n",
    "    nueva_fila = pd.DataFrame({'fecha':[fecha],'hora':[hora],'dataset':[dataset],'cantidad_variables':[cantidad_variables],'continuas':[continuas], 'baja+1':[baja_1],'extra':[baja_2],'mensaje':[mensaje]})\n",
    "    dataframe = pd.concat([dataframe, nueva_fila], ignore_index=True)\n",
    "    dataframe.to_csv(r\"../../anotaciones_back_testing.csv\", index=False)\n",
    "    os.system('git add ../../anotaciones_back_testing.csv')\n",
    "    os.system(f\"git commit -m '{mensaje}'\")\n",
    "    os.system(\"git push\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - parametros para modelo\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "\n",
    "mes_train = [201901, 201902, 201903, 201905, 201907, 201911, 202011, 202012,\n",
    "       202101, 202102, 202103, 202104, 202105, 202106, 202107]\n",
    "mes_test = 202109\n",
    "\n",
    "best_params=### \n",
    "\n",
    "best_iter= ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "# 1 configuración de la base de datos\n",
    "\n",
    "%load_ext sql\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "%sql duckdb:///:memory:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Success]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TABLE competencia_03 AS\n",
    "SELECT * FROM read_parquet(:dataset_clase_ternaria_sin_psi_l);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero_de_cliente</th>\n",
       "      <th>foto_mes</th>\n",
       "      <th>active_quarter</th>\n",
       "      <th>cliente_vip</th>\n",
       "      <th>cliente_edad</th>\n",
       "      <th>cliente_antiguedad</th>\n",
       "      <th>mrentabilidad</th>\n",
       "      <th>mactivos_margen</th>\n",
       "      <th>mpasivos_margen</th>\n",
       "      <th>cproductos</th>\n",
       "      <th>...</th>\n",
       "      <th>Visa_fultimo_cierre</th>\n",
       "      <th>Visa_mpagado</th>\n",
       "      <th>Visa_mpagospesos</th>\n",
       "      <th>Visa_mpagosdolares</th>\n",
       "      <th>Visa_fechaalta</th>\n",
       "      <th>Visa_mconsumototal</th>\n",
       "      <th>Visa_cconsumos</th>\n",
       "      <th>Visa_cadelantosefectivo</th>\n",
       "      <th>Visa_mpagominimo</th>\n",
       "      <th>clase_ternaria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250480925</td>\n",
       "      <td>201901</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>166</td>\n",
       "      <td>2734.28</td>\n",
       "      <td>-221.90</td>\n",
       "      <td>1424.55</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-23237.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>6766.59</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>938.40</td>\n",
       "      <td>CONTINUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250480925</td>\n",
       "      <td>201902</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>167</td>\n",
       "      <td>2269.95</td>\n",
       "      <td>558.15</td>\n",
       "      <td>685.30</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11730.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2205.0</td>\n",
       "      <td>6748.23</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1630.47</td>\n",
       "      <td>CONTINUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250480925</td>\n",
       "      <td>201903</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>168</td>\n",
       "      <td>3928.99</td>\n",
       "      <td>897.46</td>\n",
       "      <td>1584.45</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10557.0</td>\n",
       "      <td>-25731.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>13258.06</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>CONTINUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250480925</td>\n",
       "      <td>201904</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>169</td>\n",
       "      <td>3431.69</td>\n",
       "      <td>247.72</td>\n",
       "      <td>1537.30</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19107.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2266.0</td>\n",
       "      <td>17332.37</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1243.38</td>\n",
       "      <td>CONTINUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250480925</td>\n",
       "      <td>201905</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>170</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14662.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2297.0</td>\n",
       "      <td>8311.09</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2557.14</td>\n",
       "      <td>CONTINUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901232</th>\n",
       "      <td>1590099528</td>\n",
       "      <td>202105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>134.97</td>\n",
       "      <td>2.63</td>\n",
       "      <td>112.44</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>CONTINUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901233</th>\n",
       "      <td>1590099528</td>\n",
       "      <td>202106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>228.19</td>\n",
       "      <td>3.45</td>\n",
       "      <td>19.10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>CONTINUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901234</th>\n",
       "      <td>1590099528</td>\n",
       "      <td>202107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>318.34</td>\n",
       "      <td>1.23</td>\n",
       "      <td>98.19</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>CONTINUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901235</th>\n",
       "      <td>1590099528</td>\n",
       "      <td>202108</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>469.97</td>\n",
       "      <td>58.16</td>\n",
       "      <td>154.16</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901236</th>\n",
       "      <td>1590099528</td>\n",
       "      <td>202109</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>-119.17</td>\n",
       "      <td>17.51</td>\n",
       "      <td>95.70</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4901237 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         numero_de_cliente  foto_mes  active_quarter  cliente_vip  \\\n",
       "0                250480925    201901               1            0   \n",
       "1                250480925    201902               1            0   \n",
       "2                250480925    201903               1            0   \n",
       "3                250480925    201904               1            0   \n",
       "4                250480925    201905               1            0   \n",
       "...                    ...       ...             ...          ...   \n",
       "4901232         1590099528    202105               1            0   \n",
       "4901233         1590099528    202106               1            0   \n",
       "4901234         1590099528    202107               1            0   \n",
       "4901235         1590099528    202108               1            0   \n",
       "4901236         1590099528    202109               1            0   \n",
       "\n",
       "         cliente_edad  cliente_antiguedad  mrentabilidad  mactivos_margen  \\\n",
       "0                  39                 166        2734.28          -221.90   \n",
       "1                  39                 167        2269.95           558.15   \n",
       "2                  39                 168        3928.99           897.46   \n",
       "3                  39                 169        3431.69           247.72   \n",
       "4                  39                 170           0.00             0.00   \n",
       "...               ...                 ...            ...              ...   \n",
       "4901232            55                   1         134.97             2.63   \n",
       "4901233            55                   2         228.19             3.45   \n",
       "4901234            55                   3         318.34             1.23   \n",
       "4901235            55                   4         469.97            58.16   \n",
       "4901236            55                   5        -119.17            17.51   \n",
       "\n",
       "         mpasivos_margen  cproductos  ...  Visa_fultimo_cierre  Visa_mpagado  \\\n",
       "0                1424.55           7  ...                  1.0           0.0   \n",
       "1                 685.30           7  ...                  1.0           0.0   \n",
       "2                1584.45           7  ...                  4.0       10557.0   \n",
       "3                1537.30           7  ...                 -1.0           0.0   \n",
       "4                   0.00           7  ...                  2.0           0.0   \n",
       "...                  ...         ...  ...                  ...           ...   \n",
       "4901232           112.44           7  ...                  5.0           0.0   \n",
       "4901233            19.10           7  ...                  0.0           0.0   \n",
       "4901234            98.19           7  ...                  3.0           0.0   \n",
       "4901235           154.16           7  ...                  6.0           0.0   \n",
       "4901236            95.70           7  ...                  1.0           0.0   \n",
       "\n",
       "         Visa_mpagospesos  Visa_mpagosdolares  Visa_fechaalta  \\\n",
       "0               -23237.35                 0.0          2177.0   \n",
       "1               -11730.00                 0.0          2205.0   \n",
       "2               -25731.12                 0.0          2236.0   \n",
       "3               -19107.25                 0.0          2266.0   \n",
       "4               -14662.50                 0.0          2297.0   \n",
       "...                   ...                 ...             ...   \n",
       "4901232               NaN                 NaN            28.0   \n",
       "4901233               NaN                 NaN            58.0   \n",
       "4901234               NaN                 NaN            89.0   \n",
       "4901235               NaN                 NaN           120.0   \n",
       "4901236               NaN                 NaN           150.0   \n",
       "\n",
       "         Visa_mconsumototal  Visa_cconsumos  Visa_cadelantosefectivo  \\\n",
       "0                   6766.59             9.0                      0.0   \n",
       "1                   6748.23            12.0                      0.0   \n",
       "2                  13258.06            18.0                      0.0   \n",
       "3                  17332.37            16.0                      0.0   \n",
       "4                   8311.09            16.0                      0.0   \n",
       "...                     ...             ...                      ...   \n",
       "4901232                 NaN             NaN                      NaN   \n",
       "4901233                 NaN             NaN                      NaN   \n",
       "4901234                 NaN             NaN                      NaN   \n",
       "4901235                 NaN             NaN                      NaN   \n",
       "4901236                 NaN             NaN                      NaN   \n",
       "\n",
       "         Visa_mpagominimo  clase_ternaria  \n",
       "0                  938.40        CONTINUA  \n",
       "1                 1630.47        CONTINUA  \n",
       "2                    0.00        CONTINUA  \n",
       "3                 1243.38        CONTINUA  \n",
       "4                 2557.14        CONTINUA  \n",
       "...                   ...             ...  \n",
       "4901232              0.00        CONTINUA  \n",
       "4901233              0.00        CONTINUA  \n",
       "4901234              0.00        CONTINUA  \n",
       "4901235              0.00            None  \n",
       "4901236              0.00            None  \n",
       "\n",
       "[4901237 rows x 145 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql \n",
    "SELECT * FROM competencia_03;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarjetas_variables = [\n",
    "    \n",
    "    ('ctarjeta_visa_debitos_automaticos', 'ctarjeta_master_debitos_automaticos'),\n",
    "    ('mttarjeta_visa_debitos_automaticos', 'mttarjeta_master_debitos_automaticos'),\n",
    "    ('ctarjeta_visa_descuentos', 'ctarjeta_master_descuentos'),\n",
    "    ('mtarjeta_visa_descuentos', 'mtarjeta_master_descuentos'),\n",
    "   \n",
    "    ('Visa_msaldototal', 'Master_msaldototal'),\n",
    "    ('Visa_msaldopesos', 'Master_msaldopesos'),\n",
    "    ('Visa_msaldodolares', 'Master_msaldodolares'),\n",
    "    ('Visa_mconsumospesos', 'Master_mconsumospesos'),\n",
    "    ('Visa_mconsumosdolares', 'Master_mconsumosdolares'),\n",
    "    ('Visa_mlimitecompra', 'Master_mlimitecompra'),\n",
    "    ('Visa_madelantopesos', 'Master_madelantopesos'),\n",
    "    ('Visa_madelantodolares', 'Master_madelantodolares'),\n",
    "    ('Visa_fultimo_cierre', 'Master_fultimo_cierre'),\n",
    "    ('Visa_mpagado', 'Master_mpagado'),\n",
    "    ('Visa_mpagospesos', 'Master_mpagospesos'),\n",
    "    ('Visa_mpagosdolares', 'Master_mpagosdolares'),\n",
    "    ('Visa_fechaalta', 'Master_fechaalta'),\n",
    "    \n",
    "    ('Visa_cconsumos', 'Master_cconsumos'),\n",
    "    ('Visa_cadelantosefectivo', 'Master_cadelantosefectivo'),\n",
    "    ('Visa_mpagominimo', 'Master_mpagominimo')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_columns = []\n",
    "for visa, master in tarjetas_variables:\n",
    "    paired_columns.append(f\"IFNULL({visa}, 0) + IFNULL ({master},0) AS conjunto_{visa}\")\n",
    "\n",
    "paired_columns_sql = \",\\n    \".join(paired_columns)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Success]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "CREATE OR REPLACE TABLE competencia_03 AS\n",
    "SELECT *,\n",
    "    {paired_columns_sql}\n",
    "FROM competencia_03\n",
    "\"\"\"\n",
    "\n",
    "%sql {{query}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Success]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "\n",
    "create or replace table competencia_03 as\n",
    "select\n",
    "    *,\n",
    "    (case when Visa_status = 0 then True end) as T_Visa_normal,\n",
    "    (case when Master_status = 0 then True end) as T_Master_normal\n",
    "from competencia_03;\n",
    "\n",
    "\n",
    "create or replace table competencia_03 as\n",
    "        select *,\n",
    "        CASE \n",
    "        WHEN Visa_status = 6 then 1\n",
    "        WHEN Visa_status = 7 then 2 \n",
    "        WHEN Visa_status = 8 then 3\n",
    "        ELSE NULL\n",
    "        END as Visa_status\n",
    "        from competencia_03;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Success]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "alter table competencia_03 drop column visa_status;\n",
    "alter table competencia_03 drop column Master_status;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Success]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lag_columns = []\n",
    "for variable in lista_feature:\n",
    "    lag_columns.append(f\"lag({variable}, 1) over (partition by numero_de_cliente order by foto_mes) as {variable}_lag_1\")\n",
    "    lag_columns.append(f\"lag({variable}, 2) over (partition by numero_de_cliente order by foto_mes) as {variable}_lag_2\")\n",
    "\n",
    "\n",
    "lag_columns_sql = \",\\n    \".join(lag_columns)\n",
    "\n",
    "\n",
    "query = f\"\"\"\n",
    "CREATE OR REPLACE TABLE competencia_03 AS\n",
    "SELECT *,\n",
    "    {lag_columns_sql}\n",
    "FROM competencia_03\n",
    "\"\"\"\n",
    "\n",
    "%sql {{query}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Success]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "delta_columns = []\n",
    "for variable in lista_feature:\n",
    "    nombre_variable = variable+'_delta_1'\n",
    "    nombre_variable_2 = variable+'_delta_2'\n",
    "    delta_columns.append(f\"{variable} - {variable}_lag_1 as {nombre_variable}\")\n",
    "    delta_columns.append(f\"{variable}_lag_1 - {variable}_lag_2 as {nombre_variable_2}\")\n",
    "\n",
    "delta_columns_sql = \",\\n    \".join(delta_columns)\n",
    "\n",
    "\n",
    "query = f'''CREATE OR REPLACE TABLE competencia_03 AS\n",
    "            select *,\n",
    "            {delta_columns_sql}\n",
    "            from competencia_03'''\n",
    "%sql {{query}}\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Admin\\\\Documents\\\\1_Notebook\\\\1_Estudio\\\\1_UBA_Maestria_DS\\\\1_Especializacion\\\\1_Segundo_Semestre\\\\DMEyF\\\\datasets\\\\competencia_3\\\\competencia_03_lags_deltas_y_clase_ternaria.parquet'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Ingrese path para guardar dataset\n",
    "\n",
    "path_dataset_lags_deltas_y_clase_ternaria = datasets_path_l+r'\\competencia_03_lags_deltas_y_clase_ternaria.parquet'\n",
    "path_dataset_lags_deltas_y_clase_ternaria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Success]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql COPY competencia_03 TO '{{path_dataset_lags_deltas_y_clase_ternaria}}' (FORMAT 'parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(dataset_competencia_03_lags_deltas_y_clase_ternaria_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['foto_mes']==201908]['clase_ternaria'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['foto_mes']==201909]['clase_ternaria'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['foto_mes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_counts = df_train.groupby(['foto_mes', 'clase_ternaria'])['clase_ternaria'].count()\n",
    "df_unstacked = df_counts.unstack(fill_value=0)\n",
    "df_unstacked['diferencia'] = df_unstacked.get('BAJA+2', 0) - df_unstacked.get('BAJA+1', 0)\n",
    "df_baja = df_unstacked.reset_index()\n",
    "df_baja.style.background_gradient(cmap='CMRmap_r', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_baja[df_baja['BAJA+2']>630]['foto_mes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Agrupar por 'foto_mes' y sumar las bajas 'BAJA+2'\n",
    "bajas_por_mes = df_baja.groupby('foto_mes')['BAJA+2'].sum()\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(bajas_por_mes.index, bajas_por_mes.values, marker='o', linestyle='-', label='Cantidad de BAJA+2')\n",
    "plt.xticks(bajas_por_mes.index, rotation=45)\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Cantidad de BAJA+2')\n",
    "plt.title('Cantidad de BAJA+2 por Mes')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_columnas = df_train.columns\n",
    "listas_drop = [col for col in lista_columnas if 'lag' in col]\n",
    "df_train = df_train.drop(columns=listas_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_num = df_train.select_dtypes(exclude=['bool','object'])\n",
    "lista_columnas_num = columnas_num.columns\n",
    "\n",
    "df_train['max'] = df_train[lista_columnas_num].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    'cmobile_app_trx', 'Master_cconsumos', 'ctarjeta_debito_transacciones',\n",
    "    'ctarjeta_visa_transacciones', 'ctarjeta_master_transacciones', 'cpayroll_trx',\n",
    "    'cpayroll2_trx', 'ccuenta_debitos_automaticos', 'cpagodeservicios', 'cforex',\n",
    "    'cforex_buy', 'mforex_sell', 'cextraccion_autoservicio',\n",
    "    'ccallcenter_transacciones', 'chomebanking_transacciones'\n",
    "]\n",
    "if 'ctrx_quarter' not in df_train.columns:\n",
    "    raise KeyError(\"La variable 'ctrx_quarter' no existe en el dataset.\")\n",
    "variables_presentes = [var for var in variables if var in df_train.columns]\n",
    "if variables_presentes:\n",
    "    for var in variables_presentes:\n",
    "        denominator = df_train[var].replace(0, 1e-6) ** 2\n",
    "        df_train['power_ratio_' + var] = df_train['ctrx_quarter'] / denominator\n",
    "    variables_faltantes = [var for var in variables if var not in df_train.columns]\n",
    "    if variables_faltantes:\n",
    "        print(f\"Las siguientes variables no existen en el dataset y no se calcularon: {variables_faltantes}\")\n",
    "else:\n",
    "    print(\"Ninguna de las variables especificadas existe en el dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2574489, 336)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formateo previo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'T_Visa_normal' in df_train.columns:\n",
    "    df_train['T_Visa_normal'] = df_train['T_Visa_normal'].astype(bool)\n",
    "if 'T_Master_normal'in df_train.columns:\n",
    "    df_train['T_Master_normal'] = df_train['T_Master_normal'].astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tmobile_app'] = pd.to_numeric(data['tmobile_app'], errors='coerce')  \n",
    "data['tmobile_app'] = data['tmobile_app'].fillna(0).astype('bool')  \n",
    "\n",
    "\n",
    "\n",
    "data['cmobile_app_trx'] = pd.to_numeric(data['cmobile_app_trx'], errors='coerce')  \n",
    "data['cmobile_app_trx'] = data['cmobile_app_trx'].fillna(0).astype('bool')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['clase_peso'] = 1.0\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "data['clase_binaria'] = np.where(data['clase_ternaria']=='CONTINUA', 0, 1)\n",
    "df_test = data[data['foto_mes'] == mes_test]\n",
    "df_train = data[data['foto_mes'].isin(mes_train)]\n",
    "\n",
    "clase_peso = df_train['clase_peso']\n",
    "X_train = df_train.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_train =df_train['clase_binaria']\n",
    "X_test = df_test.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_test =df_test['clase_binaria']\n",
    "w_train = df_train.loc[X_train.index, 'clase_peso']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y Semillero-Voting GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "# 7 - Voting promedio de modelos para reducir varianza\n",
    "numeros_random = np.random.randint(0, 100000, 15)\n",
    "train_data = lgb.Dataset(X_train,\n",
    "                            label=Y_train,\n",
    "                            weight=w_train)\n",
    "\n",
    "\n",
    "\n",
    "df_voting = pd.DataFrame()\n",
    "\n",
    "for semilla in numeros_random: \n",
    "        \n",
    "    \n",
    "    df_modelos = pd.DataFrame\n",
    "    params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': best_params['num_leaves'],\n",
    "    'learning_rate': best_params['learning_rate'],\n",
    "    'min_data_in_leaf': best_params['min_data_in_leaf'],\n",
    "    'feature_fraction': best_params['feature_fraction'],\n",
    "    'bagging_fraction': best_params['bagging_fraction'],\n",
    "    'seed': semilla,\n",
    "    'verbose': 0\n",
    "    }\n",
    "        \n",
    "        \n",
    "    model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=best_iter)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    df_voting[f'pred_{semilla}'] = y_pred\n",
    "    \n",
    "df_voting['pred_mean'] = df_voting.mean(axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = df_voting['pred_mean']\n",
    "\n",
    "predicciones = y_pred\n",
    "\n",
    "X_test['Probabilidad'] = predicciones\n",
    "\n",
    "tb_entrega = X_test.sort_values(by='Probabilidad', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de clientes 9730\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tb_entrega['Predicted'] = 0\n",
    "\n",
    "envios = 9730\n",
    "tb_entrega.iloc[:envios, tb_entrega.columns.get_loc('Predicted')] = 1\n",
    "\n",
    "resultados = tb_entrega[[\"numero_de_cliente\", 'Predicted']].reset_index(drop=True)\n",
    "\n",
    "print(\"Cantidad de clientes {}\".format(envios))\n",
    "num_subida_kaggle = 18\n",
    "nombre_archivo = '\\entrega_0{}.csv'.format(num_subida_kaggle)\n",
    "entrega_final = f'{entregas_l}{nombre_archivo}'\n",
    "resultados.to_csv(entrega_final, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_de_cliente = X_test['numero_de_cliente']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nombres = model.feature_name()\n",
    "df_resultado = pd.DataFrame({\n",
    "    'numero_de_cliente': numero_de_cliente,\n",
    "    'Predicted': y\n",
    "}, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicciones = y_pred_lgm\n",
    "\n",
    "X_test['Probabilidad'] = predicciones\n",
    "\n",
    "tb_entrega = X_test.sort_values(by='Probabilidad', ascending=False)\n",
    "\n",
    "cortes = range(9000,14000,100)\n",
    "\n",
    "num_subida_kaggle = 65\n",
    "for envios in cortes:\n",
    "    \n",
    "    tb_entrega['Predicted'] = 0\n",
    "    tb_entrega.iloc[:envios, tb_entrega.columns.get_loc('Predicted')] = 1\n",
    "    resultados = tb_entrega[[\"numero_de_cliente\", 'Predicted']].reset_index(drop=True)\n",
    "    \n",
    "    print(\"Cantidad de clientes {}\".format(envios))\n",
    "    \n",
    "    nombre_archivo = 'entrega_0{}.csv'.format(num_subida_kaggle)\n",
    "    entrega_final = os.path.join(path, nombre_archivo)\n",
    "    resultados.to_csv(entrega_final, index=False)\n",
    "    \n",
    "    \n",
    "    cantidad_columnas = df_train.shape[1]\n",
    "    message = f\"{entrega}, cantidad de columnas en el train: {cantidad_columnas}, modelo: LGBM, mejores parametros: {best_params}, mejor iteracion: {best_iter}, archivo: {entrega_final}, punto de corte: {envios}, optimizado con optuna: {study_name}\"\n",
    "    \n",
    "    num_subida_kaggle += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    entrega_final = os.path.join(path, nombre_archivo)   \n",
    "    competencia = 'dm-ey-f-2024-primera'\n",
    "    try:\n",
    "        api.competition_submit(file_name=entrega_final,message=message,competition=competencia)\n",
    "    except:\n",
    "        print(f\"Numero máximo de envios, último envio ={num_subida_kaggle}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
