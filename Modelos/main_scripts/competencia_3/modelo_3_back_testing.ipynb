{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precarga de librerias y funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run \"../../recurrentes.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run \"../../funciones.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activar Excel de seguimiento de medidas? \n",
    "\n",
    "excel = True\n",
    "if excel == True:\n",
    "    # Ingresar path excel para anotar resultados\n",
    "    path_excel = base_path_l + r'\\resultados_backtesting.xlsx'\n",
    "    date = datetime.now().strftime(\"%d-%m-%Y %H-%M-%S\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Cargar datos\n",
    "# Opciones:\n",
    "# a) dataset_clase_ternaria_l\n",
    "# b) competencia_03_ct_sin_psi.parquet\n",
    "\n",
    "dataset = dataset_competencia_03_lags_deltas_y_clase_ternaria\n",
    "dataset_name = os.path.basename(dataset)\n",
    "df_train = pd.read_parquet(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = df_train.columns\n",
    "columnas_lags = [col for col in columnas if 'lag' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=columnas_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4901237, 320)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_num = df_train.select_dtypes(exclude=['bool','object'])\n",
    "lista_columnas_num = columnas_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['max'] = df_train[lista_columnas_num].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables a verificar\n",
    "variables = [\n",
    "    'cmobile_app_trx', 'Master_cconsumos', 'ctarjeta_debito_transacciones', \n",
    "    'ctarjeta_visa_transacciones', 'ctarjeta_master_transacciones', 'cpayroll_trx', \n",
    "    'cpayroll2_trx', 'ccuenta_debitos_automaticos', 'cpagodeservicios', 'cforex', \n",
    "    'cforex_buy', 'mforex_sell', 'cextraccion_autoservicio', 'ccallcenter_transacciones', \n",
    "    'chomebanking_transacciones'\n",
    "]\n",
    "\n",
    "# Verificar si 'ctrx_quarter' existe en el DataFrame\n",
    "if 'ctrx_quarter' not in df_train.columns:\n",
    "    raise KeyError(\"La variable 'ctrx_quarter' no existe en el dataset.\")\n",
    "\n",
    "# Lista de las variables que sí están presentes en el DataFrame\n",
    "variables_presentes = [var for var in variables if var in df_train.columns]\n",
    "\n",
    "# Si hay variables presentes en el DataFrame, calcular la Power Ratio\n",
    "if variables_presentes:\n",
    "    for var in variables_presentes:\n",
    "        # Evitar división por cero reemplazando ceros en el denominador por un valor mínimo (1e-6)\n",
    "        denominator = df_train[var].replace(0, 1e-6) ** 2  # Elevar al cuadrado el denominador\n",
    "        # Crear una nueva columna con el prefijo 'power_ratio_'\n",
    "        df_train['power_ratio_' + var] = df_train['ctrx_quarter'] / denominator\n",
    "else:\n",
    "    print(\"No se encontraron variables para calcular la Power Ratio.\")\n",
    "\n",
    "# Informar sobre las variables que faltan en el DataFrame\n",
    "variables_faltantes = [var for var in variables if var not in df_train.columns]\n",
    "if variables_faltantes:\n",
    "    print(f\"Las siguientes variables no existen en el dataset y no se calcularon: {variables_faltantes}\")\n",
    "else:\n",
    "    print(\"Todas las variables fueron verificadas correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_tarjeta = df_train.columns\n",
    "columnas_tarjeta= [col for col in columnas_tarjeta if 'conjunto' in col]\n",
    "columnas_tarjeta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Lista de columnas a las que se aplicará PolynomialFeatures\n",
    "columnas_polynomial = ['ctrx_quarter', 'conjunto_Visa_msaldototal', 'cpayroll_trx']\n",
    "\n",
    "# Verificar que las columnas existen en df_train\n",
    "for col in columnas_polynomial:\n",
    "    if col not in df_train.columns:\n",
    "        raise KeyError(f\"La columna '{col}' no existe en df_train.\")\n",
    "\n",
    "# Extraer las columnas seleccionadas\n",
    "df_poly = df_train[columnas_polynomial].copy()\n",
    "\n",
    "# Configurar PolynomialFeatures\n",
    "grado_polinomio = 3  # Cambia este valor según tus necesidades\n",
    "poly = PolynomialFeatures(degree=grado_polinomio, include_bias=False, interaction_only=True)\n",
    "\n",
    "# Ajustar y transformar las características para generar las nuevas características polinomiales\n",
    "poly_features = poly.fit_transform(df_poly)\n",
    "\n",
    "# Obtener los nombres de las nuevas características generadas\n",
    "nombres_columnas = poly.get_feature_names_out(columnas_polynomial)\n",
    "\n",
    "# Crear un DataFrame con las nuevas características polinomiales\n",
    "df_poly_features = pd.DataFrame(poly_features, columns=nombres_columnas, index=df_poly.index)\n",
    "\n",
    "# Concatenar las nuevas características al DataFrame original\n",
    "df_train_expanded = pd.concat([df_train, df_poly_features], axis=1)\n",
    "\n",
    "# Opcional: Si deseas eliminar las columnas originales después de la expansión\n",
    "# df_train_expanded = df_train_expanded.drop(columns=columnas_polynomial)\n",
    "\n",
    "# Resultado final en df_train_expanded con las nuevas características\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_expanded = df_train_expanded.drop(columns=columnas_polynomial)\n",
    "\n",
    "df_train_expanded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_expanded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formateo pre modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [202011, 202012, 202101, 202102, 202103, 202104, 202105, 202106] modelo 10 meses\n",
    "\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "#Defenir mes de train y test\n",
    "\n",
    "mes_train = [201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908,\n",
    "       201909, 201910, 201911, 201912, 202010, 202011, 202012,\n",
    "       202101, 202102, 202103, 202104, 202105]\n",
    "mes_test = 202107\n",
    "\n",
    "\n",
    "# Defenir mejores parámetros para el modelo\n",
    "\n",
    "best_params = {'num_leaves': 94,\n",
    " 'learning_rate': 0.050129899443463674,\n",
    " 'min_data_in_leaf': 1004,\n",
    " 'feature_fraction': 0.2530957925821187,\n",
    " 'bagging_fraction': 0.28656832468240556}\n",
    "best_iter = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predecir_punto_de_corte(  \n",
    "#     dataset,  \n",
    "#     mes_de_entrenamiento,  \n",
    "#     mes_de_prueba,  \n",
    "#     best_params,  \n",
    "#     best_iteration,  \n",
    "#     rango_cortes,  \n",
    "#     semillas,  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = df_train\n",
    "data['tmobile_app'] = pd.to_numeric(data['tmobile_app'], errors='coerce')  # Convierte no numéricos a NaN\n",
    "data['tmobile_app'] = data['tmobile_app'].fillna(0).astype('bool')  # Llena los NaN y convierte a booleano\n",
    "\n",
    "\n",
    "data['cmobile_app_trx'] = pd.to_numeric(data['cmobile_app_trx'], errors='coerce')  # Convierte no numéricos a NaN\n",
    "data['cmobile_app_trx'] = data['cmobile_app_trx'].fillna(0).astype('bool')  # Llena los NaN y convierte a booleano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'T_Visa_normal' in df_train.columns:\n",
    "    df_train['T_Visa_normal'] = df_train['T_Visa_normal'].astype(bool)\n",
    "if 'T_Master_normal'in df_train.columns:\n",
    "    df_train['T_Master_normal'] = df_train['T_Master_normal'].astype(bool)\n",
    "    \n",
    "# Binarización de la variable target\n",
    "\n",
    "data['clase_peso'] = 1.0\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "data['clase_binaria'] = np.where(data['clase_ternaria']=='BAJA+2', 1, 0)\n",
    "\n",
    "# Train-Test Split\n",
    "\n",
    "if isinstance(mes_train, list):\n",
    "    df_train = data[data['foto_mes'].isin(mes_train)]\n",
    "    \n",
    "else: df_train = data[data['foto_mes']<=mes_train]\n",
    "\n",
    "df_test = data[data['foto_mes']==mes_test]\n",
    "\n",
    "# definiendo X e Y\n",
    "\n",
    "clase_peso = df_train['clase_peso']\n",
    "X_train = df_train.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_train =df_train['clase_binaria']\n",
    "X_test = df_test.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_test =df_test['clase_binaria']\n",
    "w_train = df_train['clase_peso']\n",
    "w_test = df_test['clase_peso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['foto_mes'].unique(), df_test['foto_mes'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta = 'personalizado'\n",
    "if respuesta == '':\n",
    "   input (\" 'personalizado' o 'default': \")\n",
    "   if respuesta == 'personalizado':\n",
    "      \n",
    "      best_params = {'num_leaves': '',\n",
    "      'learning_rate': '',\n",
    "      'min_data_in_leaf': '',\n",
    "      'feature_fraction': '',\n",
    "      'bagging_fraction': ''}\n",
    "   elif respuesta == 'default':\n",
    "      params = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_voting = pd.DataFrame()\n",
    "\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "\n",
    "for x in semillas:\n",
    "\n",
    "    if respuesta == 'personalizado':\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'first_metric_only': True,\n",
    "            'boost_from_average': True,\n",
    "            'feature_pre_filter': False,\n",
    "            'max_bin': 31,\n",
    "            'num_leaves': best_params['num_leaves'],\n",
    "            'learning_rate': best_params['learning_rate'],\n",
    "            'min_data_in_leaf': best_params['min_data_in_leaf'],\n",
    "            'feature_fraction': best_params['feature_fraction'],\n",
    "            'bagging_fraction': best_params['bagging_fraction'],\n",
    "            'seed': x,  # Usamos el x actual del bucle\n",
    "            'verbose': 0\n",
    "        }\n",
    "\n",
    "    elif respuesta == 'default':\n",
    "        params = {\n",
    "            'seed': x  # Si deseas usar x también en el caso 'default'\n",
    "        }\n",
    "\n",
    "    # Entrenar el modelo con los parámetros actualizados\n",
    "    model = lgb.train(params,\n",
    "                      train_data,\n",
    "                      num_boost_round=best_iter)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    df_voting[f'prediccion_seed_{x}'] = y_pred\n",
    "\n",
    "df_voting['prediccion'] = df_voting.mean(axis=1)\n",
    "df_voting.index = X_test.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = pd.DataFrame({'numero_de_cliente': X_test['numero_de_cliente'], 'probabilidad': df_voting ['prediccion']}, index=X_test.index) \n",
    "prediccion.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['foto_mes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.reindex(X_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bajas = pd.DataFrame({'numero_de_cliente': X_test['numero_de_cliente'], 'clase_ternaria': df_test['clase_ternaria']}, index= X_test.index)\n",
    "bajas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test['clase_ternaria'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bajas.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion.shape\n",
    "merged_data = prediccion.merge(bajas, on='numero_de_cliente', how='inner')\n",
    "\n",
    "merged_data.columns\n",
    "merged_data_sorted = merged_data.sort_values('probabilidad', ascending=False)\n",
    "\n",
    "\n",
    "# Ordenar por probabilidad de mayor a menor\n",
    "\n",
    "# Seleccionar top clientes\n",
    "top_clients = merged_data_sorted.iloc[:12000].copy()  # Trabajar con una copia\n",
    "\n",
    "# Convertir 'clase_ternaria' a variable binaria para los top clientes\n",
    "top_clients.loc[:, 'bajas_reales'] = (top_clients['clase_ternaria'] == 'BAJA+2').astype(int)\n",
    "\n",
    "top_clients.value_counts('clase_ternaria')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_clients.value_counts('bajas_reales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
