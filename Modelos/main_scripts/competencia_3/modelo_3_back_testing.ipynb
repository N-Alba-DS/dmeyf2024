{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precarga de librerias y funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run \"../../recurrentes.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run \"../../funciones.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activar Excel de seguimiento de medidas? \n",
    "\n",
    "excel = True\n",
    "if excel == True:\n",
    "    # Ingresar path excel para anotar resultados\n",
    "    path_excel = base_path_l + r'\\resultados_backtesting.xlsx'\n",
    "    date = datetime.now().strftime(\"%d-%m-%Y %H-%M-%S\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Cargar datos\n",
    "# Opciones:\n",
    "# a) dataset_clase_ternaria_l\n",
    "# b) competencia_03_ct_sin_psi.parquet\n",
    "\n",
    "dataset = dataset_clase_ternaria_l\n",
    "dataset_name = os.path.basename(dataset)\n",
    "df_train = pd.read_parquet(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formateo pre modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [202011, 202012, 202101, 202102, 202103, 202104, 202105, 202106] modelo 10 meses\n",
    "\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "#Defenir mes de train y test\n",
    "\n",
    "mes_train = 202106\n",
    "mes_test = 202108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'T_Visa_normal' in df_train.columns:\n",
    "    df_train['T_Visa_normal'] = df_train['T_Visa_normal'].astype(bool)\n",
    "if 'T_Master_normal'in df_train.columns:\n",
    "    df_train['T_Master_normal'] = df_train['T_Master_normal'].astype(bool)\n",
    "    \n",
    "# Binarización de la variable target\n",
    "\n",
    "data = df_train\n",
    "data['clase_peso'] = 1.0\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "data['clase_binaria'] = np.where(data['clase_ternaria']=='CONTINUA', 0, 1)\n",
    "\n",
    "# Train-Test Split\n",
    "\n",
    "if isinstance(mes_train, list):\n",
    "    df_train = data[data['foto_mes'].isin(mes_train)]\n",
    "else: df_test = data[data['foto_mes']==mes_test]\n",
    "\n",
    "# definiendo X e Y\n",
    "\n",
    "clase_peso = df_train['clase_peso']\n",
    "X_train = df_train.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_train =df_train['clase_binaria']\n",
    "X_test = df_test.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_test =df_test['clase_binaria']\n",
    "w_train = df_train['clase_peso']\n",
    "w_test = df_test['clase_peso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predecir_punto_de_corte(  \n",
    "    dataset,  \n",
    "    mes_de_entrenamiento,  \n",
    "    mes_de_prueba,  \n",
    "    best_params,  \n",
    "    best_iteration,  \n",
    "    rango_cortes,  \n",
    "    semillas,  \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predecir_punto_de_corte (df_train, 202106, 202108, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta = ''\n",
    "if respuesta == '':\n",
    "   input (\" 'personalizado' o 'default': \")\n",
    "   if respuesta == 'personalizado':\n",
    "      \n",
    "      best_params = {'num_leaves': '',\n",
    "      'learning_rate': '',\n",
    "      'min_data_in_leaf': '',\n",
    "      'feature_fraction': '',\n",
    "      'bagging_fraction': ''}\n",
    "   elif respuesta == 'default':\n",
    "      params = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 966676, number of negative: 3768917\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.497922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22084\n",
      "[LightGBM] [Info] Number of data points in the train set: 4735593, number of used features: 154\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204132 -> initscore=-1.360665\n",
      "[LightGBM] [Info] Start training from score -1.360665\n",
      "[LightGBM] [Info] Number of positive: 966676, number of negative: 3768917\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.422076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22084\n",
      "[LightGBM] [Info] Number of data points in the train set: 4735593, number of used features: 154\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204132 -> initscore=-1.360665\n",
      "[LightGBM] [Info] Start training from score -1.360665\n",
      "[LightGBM] [Info] Number of positive: 966676, number of negative: 3768917\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.408033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22084\n",
      "[LightGBM] [Info] Number of data points in the train set: 4735593, number of used features: 154\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204132 -> initscore=-1.360665\n",
      "[LightGBM] [Info] Start training from score -1.360665\n",
      "[LightGBM] [Info] Number of positive: 966676, number of negative: 3768917\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.459457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22084\n",
      "[LightGBM] [Info] Number of data points in the train set: 4735593, number of used features: 154\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204132 -> initscore=-1.360665\n",
      "[LightGBM] [Info] Start training from score -1.360665\n",
      "[LightGBM] [Info] Number of positive: 966676, number of negative: 3768917\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.439217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22084\n",
      "[LightGBM] [Info] Number of data points in the train set: 4735593, number of used features: 154\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204132 -> initscore=-1.360665\n",
      "[LightGBM] [Info] Start training from score -1.360665\n"
     ]
    }
   ],
   "source": [
    "best_iter = 1789\n",
    "\n",
    "df_voting = pd.DataFrame()\n",
    "\n",
    "if respuesta == 'personalizado':\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': best_params['num_leaves'],\n",
    "        'learning_rate': best_params['learning_rate'],\n",
    "        'min_data_in_leaf': best_params['min_data_in_leaf'],\n",
    "        'feature_fraction': best_params['feature_fraction'],\n",
    "        'bagging_fraction': best_params['bagging_fraction'],\n",
    "        'seed': x,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "elif respuesta == 'default':\n",
    "    params = {}\n",
    "\n",
    "\n",
    "for x in semillas:\n",
    "                \n",
    "    model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=best_iter)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    df_voting[f'prediccion_seed_{x}'] = y_pred\n",
    "\n",
    "df_voting['prediccion'] = df_voting.mean(axis=1)\n",
    "df_voting.index = X_test.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165152, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion = pd.DataFrame({'numero_de_cliente': X_test['numero_de_cliente'], 'probabilidad': df_voting ['prediccion']}, index=X_test.index) \n",
    "prediccion.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numero_de_cliente    0\n",
       "probabilidad         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165152, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bajas = pd.DataFrame({'numero_de_cliente': X_test['numero_de_cliente'], 'clase_ternaria': df_test['clase_ternaria']}, index= X_test.index)\n",
    "bajas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numero_de_cliente    0\n",
       "clase_ternaria       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bajas.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clase_ternaria\n",
       "BAJA+2    11915\n",
       "BAJA+1       85\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion.shape\n",
    "merged_data = prediccion.merge(bajas, on='numero_de_cliente', how='inner')\n",
    "\n",
    "merged_data.columns\n",
    "merged_data_sorted = merged_data.sort_values('probabilidad', ascending=False)\n",
    "\n",
    "\n",
    "# Ordenar por probabilidad de mayor a menor\n",
    "\n",
    "# Seleccionar top clientes\n",
    "top_clients = merged_data_sorted.iloc[:12000].copy()  # Trabajar con una copia\n",
    "\n",
    "# Convertir 'clase_ternaria' a variable binaria para los top clientes\n",
    "top_clients.loc[:, 'bajas_reales'] = (top_clients['clase_ternaria'] == 'BAJA+2').astype(int)\n",
    "\n",
    "top_clients.value_counts('clase_ternaria')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bajas_reales\n",
       "1    11915\n",
       "0       85\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_clients.value_counts('bajas_reales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 333766, number of negative: 970448\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.219239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 49926\n",
      "[LightGBM] [Info] Number of data points in the train set: 1304214, number of used features: 295\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.255916 -> initscore=-1.067303\n",
      "[LightGBM] [Info] Start training from score -1.067303\n",
      "[LightGBM] [Info] Number of positive: 333766, number of negative: 970448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.803860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 49926\n",
      "[LightGBM] [Info] Number of data points in the train set: 1304214, number of used features: 295\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.255916 -> initscore=-1.067303\n",
      "[LightGBM] [Info] Start training from score -1.067303\n",
      "[LightGBM] [Info] Number of positive: 333766, number of negative: 970448\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.216134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 49926\n",
      "[LightGBM] [Info] Number of data points in the train set: 1304214, number of used features: 295\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.255916 -> initscore=-1.067303\n",
      "[LightGBM] [Info] Start training from score -1.067303\n",
      "[LightGBM] [Info] Number of positive: 333766, number of negative: 970448\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.227275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 49926\n",
      "[LightGBM] [Info] Number of data points in the train set: 1304214, number of used features: 295\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.255916 -> initscore=-1.067303\n",
      "[LightGBM] [Info] Start training from score -1.067303\n",
      "[LightGBM] [Info] Number of positive: 333766, number of negative: 970448\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.251520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 49926\n",
      "[LightGBM] [Info] Number of data points in the train set: 1304214, number of used features: 295\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.255916 -> initscore=-1.067303\n",
      "[LightGBM] [Info] Start training from score -1.067303\n"
     ]
    }
   ],
   "source": [
    "dicc_medidas = calcular_medidas(X_train, Y_train, w_train, X_test, Y_test, w_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if excel == True:\n",
    "    dicc_medidas['fecha'] = date\n",
    "    dicc_medidas['dataset'] = dataset_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clase_ternaria\n",
       "BAJA+2    164077\n",
       "BAJA+1      1075\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['clase_ternaria'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clase_ternaria\n",
       "CONTINUA    3768917\n",
       "BAJA+1       486980\n",
       "BAJA+2       479696\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['clase_ternaria'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clase_ternaria\n",
       "BAJA+2    164077\n",
       "BAJA+1      1075\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bajas['clase_ternaria'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_columnas = df_train.shape[1]\n",
    "mes_train = df_train['foto_mes'].max()\n",
    "mes_test = df_test['foto_mes'].max()\n",
    "# Agregar nota\n",
    "consideraciones = 'entrenando sólo noviembre'\n",
    "\n",
    "dicc_medidas['cantidad_columnas'] = cantidad_columnas\n",
    "dicc_medidas['mes_train'] = mes_train\n",
    "dicc_medidas['mes_test'] = mes_test\n",
    "dicc_medidas['consideraciones'] = consideraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_score': 0.9144144690555327,\n",
       " 'precision_score': 0.10829671749806151,\n",
       " 'recall_score': 0.8434826371414192,\n",
       " 'f1_score': 0.19194869151921207,\n",
       " 'roc_auc_score': 0.8793811837549762,\n",
       " 'ganancia': 142786000,\n",
       " 'fecha': '24-11-2024 17-17-52',\n",
       " 'dataset': 'dataset_10_meses.parquet',\n",
       " 'cantidad_columnas': 298,\n",
       " 'mes_train': 202106,\n",
       " 'mes_test': 202106,\n",
       " 'consideraciones': 'entrenando sólo noviembre'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicc_medidas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primera celda vacía en la fila 21\n",
      "Fila a actualizar: 21\n",
      "se actualizó fila 21 en el excel\n"
     ]
    }
   ],
   "source": [
    "if excel == True:\n",
    "    anotar_excel(path_excel, dicc_medidas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
