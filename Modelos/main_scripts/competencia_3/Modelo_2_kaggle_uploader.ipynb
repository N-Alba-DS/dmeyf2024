{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "%run \"../recurrentes.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../funciones.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "%sql duckdb:///:memory:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 - Carga del dataset. Opciones: \n",
    "# dataset_lags_clase_ternaria_l : dataset con lags y clase ternaria\n",
    "# dataset_clase_ternaria_l: dataset sin lags y clase ternaria\n",
    "\n",
    "df_train = pd.read_parquet(dataset_clase_ternaria_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4735593, 155)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del dataset para el Voting GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- Para el caso de que el dataset sea con feature engineering incluido\n",
    "if 'T_Visa_normal' in df_train.columns and 'T_Master_normal' in df_train.columns:\n",
    "    df_train['T_Visa_normal'] = df_train['T_Visa_normal'].astype(bool)\n",
    "    df_train['T_Master_normal'] = df_train['T_Master_normal'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- parametros para calcular ganancia del modelo\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "data = df_train\n",
    "data['clase_peso'] = 1.0\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "\n",
    "# 4 - binarización de la clase ternaria\n",
    "\n",
    "data['clase_binaria'] = np.where(data['clase_ternaria']=='CONTINUA', 0, 1)\n",
    "\n",
    "# 5 Especificar mes de train y test\n",
    "\n",
    "df_train = data[data['foto_mes']<=202106]\n",
    "df_test = data[data['foto_mes']==202108]\n",
    "\n",
    "\n",
    "clase_peso = df_train['clase_peso']\n",
    "X_train = df_train.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_train =df_train['clase_binaria']\n",
    "X_test = df_test.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_test =df_test['clase_binaria']\n",
    "w_train = df_train.loc[X_train.index, 'clase_peso']\n",
    "w_test = df_test.loc[X_test.index, 'clase_peso']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 Ingresar mejores parámetros optuna. Remplazar los parámetros con mejores datos de optuna corridos en VM\n",
    "best_params = {'num_leaves': 40,\n",
    " 'learning_rate': 0.022596031021514126,\n",
    " 'min_data_in_leaf': 1692,\n",
    " 'feature_fraction': 0.8060065372089812,\n",
    " 'bagging_fraction': 0.8663914349386255}\n",
    "\n",
    "# best_iter = study.best_trial.user_attrs[\"best_iter\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semillero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input data must be 2 dimensional and non empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 34\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(params,\n\u001b[0;32m     31\u001b[0m                     train_data,\n\u001b[0;32m     32\u001b[0m                     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m299\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     df_voting[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msemilla_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msemilla\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     36\u001b[0m df_voting[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpromedio\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_voting\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:4738\u001b[0m, in \u001b[0;36mBooster.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m   4736\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4737\u001b[0m         num_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 4738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictor\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m   4739\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   4740\u001b[0m     start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration,\n\u001b[0;32m   4741\u001b[0m     num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[0;32m   4742\u001b[0m     raw_score\u001b[38;5;241m=\u001b[39mraw_score,\n\u001b[0;32m   4743\u001b[0m     pred_leaf\u001b[38;5;241m=\u001b[39mpred_leaf,\n\u001b[0;32m   4744\u001b[0m     pred_contrib\u001b[38;5;241m=\u001b[39mpred_contrib,\n\u001b[0;32m   4745\u001b[0m     data_has_header\u001b[38;5;241m=\u001b[39mdata_has_header,\n\u001b[0;32m   4746\u001b[0m     validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   4747\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:1137\u001b[0m, in \u001b[0;36m_InnerPredictor.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features)\u001b[0m\n\u001b[0;32m   1128\u001b[0m     _safe_call(\n\u001b[0;32m   1129\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterValidateFeatureNames(\n\u001b[0;32m   1130\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1133\u001b[0m         )\n\u001b[0;32m   1134\u001b[0m     )\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd_DataFrame):\n\u001b[1;32m-> 1137\u001b[0m     data \u001b[38;5;241m=\u001b[39m _data_from_pandas(\n\u001b[0;32m   1138\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   1139\u001b[0m         feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1140\u001b[0m         categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1141\u001b[0m         pandas_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical,\n\u001b[0;32m   1142\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1144\u001b[0m predict_type \u001b[38;5;241m=\u001b[39m _C_API_PREDICT_NORMAL\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raw_score:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:812\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_data_from_pandas\u001b[39m(\n\u001b[0;32m    806\u001b[0m     data: pd_DataFrame,\n\u001b[0;32m    807\u001b[0m     feature_name: _LGBM_FeatureNameConfiguration,\n\u001b[0;32m    808\u001b[0m     categorical_feature: _LGBM_CategoricalFeatureConfiguration,\n\u001b[0;32m    809\u001b[0m     pandas_categorical: Optional[List[List]],\n\u001b[0;32m    810\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, List[\u001b[38;5;28mstr\u001b[39m], Union[List[\u001b[38;5;28mstr\u001b[39m], List[\u001b[38;5;28mint\u001b[39m]], List[List]]:\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 812\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput data must be 2 dimensional and non empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;66;03m# take shallow copy in case we modify categorical columns\u001b[39;00m\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;66;03m# whole column modifications don't change the original df\u001b[39;00m\n\u001b[0;32m    816\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Input data must be 2 dimensional and non empty."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_data = lgb.Dataset(X_train,\n",
    "                            label=Y_train,\n",
    "                            weight=w_train)\n",
    "\n",
    "df_voting = pd.DataFrame()\n",
    "\n",
    "for semilla in numeros_random:\n",
    "    params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': 0,\n",
    "    'learning_rate': 0,\n",
    "    'min_data_in_leaf': 0,\n",
    "    'feature_fraction': 0,\n",
    "    'bagging_fraction': 0,\n",
    "    'seed': semilla,\n",
    "    'verbose': 0\n",
    "}\n",
    "    #actualización con valores optuna\n",
    "    params.update(best_params)\n",
    "    \n",
    "    if params['num_leaves'] == 0:\n",
    "        print ('Error falta actualización de parámetros')\n",
    "        break\n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=299)\n",
    "    \n",
    "    df_voting[f'semilla_{semilla}'] = model.predict(X_test)\n",
    "\n",
    "df_voting['promedio'] = df_voting.mean(axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = df_voting['promedio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script para subida individual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado = pd.DataFrame({\n",
    "    'numero_de_cliente': X_test['numero_de_cliente'],\n",
    "    'Predicted': y_pred\n",
    "}, index = X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numero = '002'\n",
    "entrega = f'entrega_{numero}.csv'\n",
    "path = entregas_l\n",
    "archivos = glob.glob(os.path.join(path, '*'))\n",
    "archivos.sort(key=os.path.getmtime, reverse=True)\n",
    "ultimo_archivo = archivos[0] if archivos else None\n",
    "if ultimo_archivo:\n",
    "    nombre_archivo = os.path.basename(ultimo_archivo)\n",
    "    numero = ''.join(filter(str.isdigit, nombre_archivo))\n",
    "    print(f\"El último archivo entregado es: {nombre_archivo}\")\n",
    "    print(f\"El número extraído es: {numero}\")\n",
    "else:\n",
    "    print(\"No se encontraron archivos en la carpeta.\")\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# numero = '073'\n",
    "# entrega = f'entrega_{numero}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(path + entrega):\n",
    "#     print(\"El archivo ya existe\")\n",
    "# else:\n",
    "#     entrega_final = os.path.join(path, entrega)\n",
    "#     df_resultado.to_csv(entrega_final, index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cantidad_columnas = df_train.shape[1]\n",
    "# message = f\"{entrega}, cantidad de columnas en el train: {cantidad_columnas}, modelo: LGBM,  mejor iteracion: {best_iter}, archivo: {entrega_final},\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# entrega_final = os.path.join(path, entrega)\n",
    "# entrega_final\n",
    "# competition= 'dm-ey-f-2024-segunda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle.api.competition_submit(competition=competition, file_name= entrega_final, message=message, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subida en serie a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predicciones = y_pred_lgm\n",
    "\n",
    "X_test['Probabilidad'] = predicciones\n",
    "\n",
    "tb_entrega = X_test.sort_values(by='Probabilidad', ascending=False)\n",
    "\n",
    "cortes = range(9000,14000,100)\n",
    "\n",
    "num_subida_kaggle = 2\n",
    "for envios in cortes:\n",
    "    \n",
    "    tb_entrega['Predicted'] = 0\n",
    "    tb_entrega.iloc[:envios, tb_entrega.columns.get_loc('Predicted')] = 1\n",
    "    resultados = tb_entrega[[\"numero_de_cliente\", 'Predicted']].reset_index(drop=True)\n",
    "    \n",
    "    print(\"Cantidad de clientes {}\".format(envios))\n",
    "    \n",
    "    nombre_archivo = 'entrega_0{}.csv'.format(num_subida_kaggle)\n",
    "    entrega_final = os.path.join(path, nombre_archivo)\n",
    "    resultados.to_csv(entrega_final, index=False)\n",
    "    \n",
    "    \n",
    "    cantidad_columnas = df_train.shape[1]\n",
    "    message = f\"{entrega}, cantidad de columnas en el train: {cantidad_columnas}, modelo: LGBM, mejores parametros: {best_params}, mejor iteracion: {best_iter}, archivo: {entrega_final}, punto de corte: {envios}, optimizado con optuna: {study_name}\"\n",
    "    \n",
    "    num_subida_kaggle += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    entrega_final = os.path.join(path, nombre_archivo)   \n",
    "    competencia = 'dm-ey-f-2024-primera'\n",
    "    try:\n",
    "        api.competition_submit(file_name=entrega_final,message=message,competition=competencia)\n",
    "    except:\n",
    "        print(f\"Numero máximo de envios, último envio ={num_subida_kaggle}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre_modelo = 'lgbm_e_en_abril_p_en_junio_451_features.txt'\n",
    "# model.save_model(rf\"C:\\Users\\Admin\\Documents\\1_Notebook\\1_Estudio\\1_UBA_Maestria_DS\\1_Especializacion\\1_Segundo_Semestre\\DMEyF\\modelos_lgbm\\{nombre_modelo}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
