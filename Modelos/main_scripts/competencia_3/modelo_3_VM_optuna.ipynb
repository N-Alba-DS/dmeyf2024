{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precarga de librerias y funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run \"../../recurrentes.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run \"../../funciones.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "# 1 configuración de la base de datos\n",
    "\n",
    "%load_ext sql\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "%sql duckdb:///:memory:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Preseteo optuna especificar bucket y nombre del estudio\n",
    "\n",
    "\n",
    "nombre_archivo = 'optimization_tree.db'\n",
    "bucket = 'b2/'\n",
    "\n",
    "\n",
    "estudio_optuna = base_path + 'buckets/' + bucket + 'optimization_tree.db'\n",
    "\n",
    "\n",
    "# cargar estudio\n",
    "# a) competencia_02\n",
    "# b) competencia_02_lags\n",
    "# c) competencia_02_lags_y_deltas\n",
    "# b1 -- competencia_02_lags_deltas_psi_fe\n",
    "# b1 - 'competencia_02_lags_deltas_psi_fe_sorted'\n",
    "\n",
    "nombre_estudio = 'competencia_03_solo_deltas_max_div_sin_pandemia'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Cargar datos\n",
    "\n",
    "# Opciones:\n",
    "\n",
    "# a) dataset_clase_ternaria\n",
    "\n",
    "df_train = pd.read_parquet(dataset_competencia_03_lags_deltas_y_clase_ternaria)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = df_train.columns\n",
    "columnas_lags = [col for col in columnas if 'lag' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=columnas_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4901237, 320)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_num = df_train.select_dtypes(exclude=['bool','object'])\n",
    "lista_columnas_num = columnas_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['max'] = df_train[lista_columnas_num].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las variables fueron verificadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Lista de variables a verificar\n",
    "variables = [\n",
    "    'cmobile_app_trx', 'Master_cconsumos', 'ctarjeta_debito_transacciones', \n",
    "    'ctarjeta_visa_transacciones', 'ctarjeta_master_transacciones', 'cpayroll_trx', \n",
    "    'cpayroll2_trx', 'ccuenta_debitos_automaticos', 'cpagodeservicios', 'cforex', \n",
    "    'cforex_buy', 'mforex_sell', 'cextraccion_autoservicio', 'ccallcenter_transacciones', \n",
    "    'chomebanking_transacciones'\n",
    "]\n",
    "\n",
    "# Verificar si 'ctrx_quarter' existe en el DataFrame\n",
    "if 'ctrx_quarter' not in df_train.columns:\n",
    "    raise KeyError(\"La variable 'ctrx_quarter' no existe en el dataset.\")\n",
    "\n",
    "# Lista de las variables que sí están presentes en el DataFrame\n",
    "variables_presentes = [var for var in variables if var in df_train.columns]\n",
    "\n",
    "# Si hay variables presentes en el DataFrame, calcular la Power Ratio\n",
    "if variables_presentes:\n",
    "    for var in variables_presentes:\n",
    "        # Evitar división por cero reemplazando ceros en el denominador por un valor mínimo (1e-6)\n",
    "        denominator = df_train[var].replace(0, 1e-6) ** 2  # Elevar al cuadrado el denominador\n",
    "        # Crear una nueva columna con el prefijo 'power_ratio_'\n",
    "        df_train['power_ratio_' + var] = df_train['ctrx_quarter'] / denominator\n",
    "else:\n",
    "    print(\"No se encontraron variables para calcular la Power Ratio.\")\n",
    "\n",
    "# Informar sobre las variables que faltan en el DataFrame\n",
    "variables_faltantes = [var for var in variables if var not in df_train.columns]\n",
    "if variables_faltantes:\n",
    "    print(f\"Las siguientes variables no existen en el dataset y no se calcularon: {variables_faltantes}\")\n",
    "else:\n",
    "    print(\"Todas las variables fueron verificadas correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.drop(columns=dicc_psi['dataset_lags_deltas_y_clase_ternaria'], inplace= True)\n",
    "# df_train.drop(columns=dicc_psi['lista_light_gbm_feature_importance'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formateo pre modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'T_Visa_normal' in df_train.columns:\n",
    "    df_train['T_Visa_normal'] = df_train['T_Visa_normal'].astype(bool)\n",
    "if 'T_Master_normal'in df_train.columns:\n",
    "    df_train['T_Master_normal'] = df_train['T_Master_normal'].astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - parametros para modelo\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "mes_train = [201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908,\n",
    "       201909, 201910, 201911, 201912, 202010, 202011, 202012,\n",
    "       202101, 202102, 202103, 202104, 202105]\n",
    "mes_test = 202108\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tmobile_app'] = pd.to_numeric(data['tmobile_app'], errors='coerce')  # Convierte no numéricos a NaN\n",
    "data['tmobile_app'] = data['tmobile_app'].fillna(0).astype('bool')  # Llena los NaN y convierte a booleano\n",
    "\n",
    "\n",
    "\n",
    "data['cmobile_app_trx'] = pd.to_numeric(data['cmobile_app_trx'], errors='coerce')  # Convierte no numéricos a NaN\n",
    "data['cmobile_app_trx'] = data['cmobile_app_trx'].fillna(0).astype('bool')  # Llena los NaN y convierte a booleano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['clase_peso'] = 1.0\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "data['clase_binaria'] = np.where(data['clase_ternaria']=='BAJA+2', 1, 0)\n",
    "df_test = data[data['foto_mes'] == 202107]\n",
    "df_train = data[data['foto_mes'].isin(mes_train)]\n",
    "\n",
    "clase_peso = df_train['clase_peso']\n",
    "X_train = df_train.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_train =df_train['clase_binaria']\n",
    "X_test = df_test.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_test =df_test['clase_binaria']\n",
    "w_train = df_train.loc[X_train.index, 'clase_peso']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimización original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import logging\n",
    "import sys\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Configurar el logging\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "optuna.logging.set_verbosity(optuna.logging.DEBUG)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    num_leaves = trial.suggest_int('num_leaves', 8, 100)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.00005, 0.3)  # más bajo, más iteraciones necesita\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 2000)\n",
    "    feature_fraction = trial.suggest_float('feature_fraction', 0.1, 1.0)\n",
    "    bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom', \n",
    "        'boosting_type': 'gbdt',\n",
    "        \n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'min_data_in_leaf': min_data_in_leaf,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'seed': semillas[0],\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                             label=Y_train,  # elegir la clase\n",
    "                             weight=w_train)\n",
    "                             \n",
    "    cv_results = lgb.cv(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=300,  # modificar, subir y subir... y descomentar la línea inferior\n",
    "        feval=lgb_gan_eval,\n",
    "        stratified=True,\n",
    "        nfold=5,\n",
    "        seed=semillas[0]\n",
    "        \n",
    "    )\n",
    "\n",
    "    max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "    best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "    # Guardamos cuál es la mejor iteración del modelo\n",
    "    trial.set_user_attr(\"best_iter\", best_iter)\n",
    "\n",
    "    # Imprimir información de la prueba actual\n",
    "    \n",
    "\n",
    "    return max_gan * 5\n",
    "\n",
    "# Ajuste de la verbosidad de Optuna ya incluido arriba\n",
    "# optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "storage_name = rf\"sqlite:///{estudio_optuna}\"\n",
    "\n",
    "study_name = nombre_estudio\n",
    "\n",
    "# Crear el callback con 300 pruebas consecutivas sin mejora\n",
    "\n",
    "# Crear el estudio\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "# Optimizar el estudio con el callback personalizado\n",
    "study.optimize(objective, n_trials=1000, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_trial = study.best_trial.user_attrs[\"best_iter\"]\n",
    "best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimización para series temporales con TimeSeriesSplit  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimización para series temporales con TimeSeriesSplit y undersampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_iter =  study.best_trial.user_attrs[\"best_iter\"]Training until validation scores don't improve for 50 rounds\n",
    "Early stopping, best iteration is:\n",
    "[37]\tcv_agg's valid gan_eval: 3.32697e+08 + 1.02725e+07\n",
    "Training until validation scores don't improve for 50 rounds\n",
    "Early stopping, best iteration is:\n",
    "[89]\tcv_agg's valid gan_eval: 3.72505e+08 + 2.92651e+06\n",
    "Training until validation scores don't improve for 50 rounds\n",
    "Early stopping, best iteration is:\n",
    "[48]\tcv_agg's valid gan_eval: 3.43602e+08 + 8.13274e+06\n",
    "Training until validation scores don't improve for 50 rounds\n",
    "Early stopping, best iteration is:\n",
    "[41]\tcv_agg's valid gan_eval: 3.27047e+08 + 1.04825e+07\n",
    "Training until validation scores don't improve for 50 rounds\n",
    "Early stopping, best iteration is:\n",
    "[42]\tcv_agg's valid gan_eval: 3.58134e+08 + 4.73243e+06\n",
    "Training until validation scores don't improve for 50 rounds\n",
    "best_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6_ b_Optimización para series temporales con TimeSeriesSplit y undersampling\n",
    "\n",
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "folds = list(tscv.split(X_train))\n",
    "\n",
    "def objective(trial):\n",
    "    num_leaves = trial.suggest_int('num_leaves', 200, 10000)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.005, 0.3)\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 8000)\n",
    "    feature_fraction = trial.suggest_float('feature_fraction', 0.3, 1.0)\n",
    "    bagging_fraction = trial.suggest_float('bagging_fraction', 0.3, 1.0)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'min_data_in_leaf': min_data_in_leaf,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'seed': semillas[0],\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    # Asegurarse de que los datos estén ordenados cronológicamente\n",
    "    X_train_sorted = X_train.sort_index()\n",
    "    Y_train_sorted = Y_train.loc[X_train_sorted.index]\n",
    "    w_train_sorted = w_train.loc[X_train_sorted.index]\n",
    "    \n",
    "    \n",
    "\n",
    "    train_data = lgb.Dataset(\n",
    "        X_train_sorted,\n",
    "        label=Y_train_sorted,\n",
    "        weight=w_train_sorted\n",
    "    )\n",
    "\n",
    "    cv_results = lgb.cv(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=5000,   # Un número muy alto inicial\n",
    "        feval=lgb_gan_eval,\n",
    "        folds=folds,\n",
    "        stratified=False,\n",
    "        seed=semillas[0],\n",
    "        early_stopping_rounds=50  # Detenerse si no hay mejora en 50 rondas consecutivas\n",
    "    )\n",
    "    max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "    best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "    # Guardamos la mejor iteración\n",
    "    trial.set_user_attr(\"best_iter\", best_iter)\n",
    "\n",
    "    return max_gan * 5\n",
    "\n",
    "# Configurar el almacenamiento y el estudio de Optuna\n",
    "storage_name = rf\"sqlite:///{estudio_optuna}\"\n",
    "study_name = nombre_estudio\n",
    "\n",
    "# Crear el estudio\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "# Definir el callback para early stopping\n",
    "class EarlyStoppingByImprovement:\n",
    "    def __init__(self, patience: int):\n",
    "        self.patience = patience\n",
    "        self.best_value = None\n",
    "        self.no_improvement_trials = 0\n",
    "\n",
    "    def __call__(self, study, trial):\n",
    "        current_best_value = study.best_trial.value\n",
    "\n",
    "        if self.best_value is None or current_best_value > self.best_value:\n",
    "            self.best_value = current_best_value\n",
    "            self.no_improvement_trials = 0\n",
    "        else:\n",
    "            self.no_improvement_trials += 1\n",
    "\n",
    "        if self.no_improvement_trials >= self.patience:\n",
    "            print(f\"Early stopping: No hay mejora en {self.patience} pruebas consecutivas.\")\n",
    "            study.stop()\n",
    "\n",
    "# Crear el callback con paciencia de 100\n",
    "early_stopping_callback = EarlyStoppingByImprovement(patience=100)\n",
    "\n",
    "# Configurar el nivel de registro de Optuna (opcional)\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "# Optimizar el estudio con el callback personalizado\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=30000,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'num_leaves': 4259,\n",
    " 'learning_rate': 0.03459780778027798,\n",
    " 'min_data_in_leaf': 2863,\n",
    " 'feature_fraction': 0.7029328587219807,\n",
    " 'bagging_fraction': 0.7914082839316137}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo 10 meses\n",
    "# best_iter = 5\n",
    "best_params = {'num_leaves': 3545,\n",
    " 'learning_rate': 0.07959540527561224,\n",
    " 'min_data_in_leaf': 933,\n",
    " 'feature_fraction': 0.6829932939284065,\n",
    " 'bagging_fraction': 0.6251908881121132}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 - Voting promedio de modelos para reducir varianza\n",
    "numeros_random = np.random.randint(0, 100000, 15)\n",
    "train_data = lgb.Dataset(X_train,\n",
    "                            label=Y_train,\n",
    "                            weight=w_train)\n",
    "\n",
    "\n",
    "\n",
    "df_voting = pd.DataFrame()\n",
    "\n",
    "for semilla in numeros_random: \n",
    "        \n",
    "    best_iter = 5\n",
    "    df_modelos = pd.DataFrame\n",
    "    params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': best_params['num_leaves'],\n",
    "    'learning_rate': best_params['learning_rate'],\n",
    "    'min_data_in_leaf': best_params['min_data_in_leaf'],\n",
    "    'feature_fraction': best_params['feature_fraction'],\n",
    "    'bagging_fraction': best_params['bagging_fraction'],\n",
    "    'seed': semilla,\n",
    "    'verbose': 0\n",
    "    }\n",
    "        \n",
    "        \n",
    "    model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=best_iter)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    df_voting[f'pred_{semilla}'] = y_pred\n",
    "    \n",
    "df_voting['pred_mean'] = df_voting.mean(axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = df_voting['pred_mean']\n",
    "\n",
    "predicciones = y_pred\n",
    "\n",
    "X_test['Probabilidad'] = predicciones\n",
    "\n",
    "tb_entrega = X_test.sort_values(by='Probabilidad', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tb_entrega['Predicted'] = 0\n",
    "\n",
    "envios = 9730\n",
    "tb_entrega.iloc[:envios, tb_entrega.columns.get_loc('Predicted')] = 1\n",
    "\n",
    "resultados = tb_entrega[[\"numero_de_cliente\", 'Predicted']].reset_index(drop=True)\n",
    "\n",
    "print(\"Cantidad de clientes {}\".format(envios))\n",
    "num_subida_kaggle = 18\n",
    "nombre_archivo = '\\entrega_0{}.csv'.format(num_subida_kaggle)\n",
    "entrega_final = f'{entregas_l}{nombre_archivo}'\n",
    "resultados.to_csv(entrega_final, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_de_cliente = X_test['numero_de_cliente']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nombres = model.feature_name()\n",
    "df_resultado = pd.DataFrame({\n",
    "    'numero_de_cliente': numero_de_cliente,\n",
    "    'Predicted': y\n",
    "}, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrega Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ingresar el path sobre el cual se quiere ingresar el archivo a entregar\n",
    "entrega = 'entrega_kaggle'\n",
    "formato = '.csv'\n",
    "numero = rf\"\\{entrega}_002{formato}\"\n",
    "entrega_final = df_resultado.to_csv(rf\"{entregas_l}{numero}\", index=False)\n",
    "entrega_final_path = entregas_l + numero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_columnas = 298\n",
    "message = f\"{entrega}, cantidad de columnas en el train: {cantidad_columnas}, modelo: LGBM, mejores parametros: {best_params}, mejor iteracion: {best_iter}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Kaggle -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "competition= 'DMEyF-2024-Segunda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.api.competition_submit(competition=competition, file_name= entrega_final_path, message=message, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puntos de corte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicciones = y_pred_lgm\n",
    "\n",
    "X_test['Probabilidad'] = predicciones\n",
    "\n",
    "tb_entrega = X_test.sort_values(by='Probabilidad', ascending=False)\n",
    "\n",
    "cortes = range(9000,14000,100)\n",
    "\n",
    "num_subida_kaggle = 65\n",
    "for envios in cortes:\n",
    "    \n",
    "    tb_entrega['Predicted'] = 0\n",
    "    tb_entrega.iloc[:envios, tb_entrega.columns.get_loc('Predicted')] = 1\n",
    "    resultados = tb_entrega[[\"numero_de_cliente\", 'Predicted']].reset_index(drop=True)\n",
    "    \n",
    "    print(\"Cantidad de clientes {}\".format(envios))\n",
    "    \n",
    "    nombre_archivo = 'entrega_0{}.csv'.format(num_subida_kaggle)\n",
    "    entrega_final = os.path.join(path, nombre_archivo)\n",
    "    resultados.to_csv(entrega_final, index=False)\n",
    "    \n",
    "    \n",
    "    cantidad_columnas = df_train.shape[1]\n",
    "    message = f\"{entrega}, cantidad de columnas en el train: {cantidad_columnas}, modelo: LGBM, mejores parametros: {best_params}, mejor iteracion: {best_iter}, archivo: {entrega_final}, punto de corte: {envios}, optimizado con optuna: {study_name}\"\n",
    "    \n",
    "    num_subida_kaggle += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    entrega_final = os.path.join(path, nombre_archivo)   \n",
    "    competencia = 'dm-ey-f-2024-primera'\n",
    "    try:\n",
    "        api.competition_submit(file_name=entrega_final,message=message,competition=competencia)\n",
    "    except:\n",
    "        print(f\"Numero máximo de envios, último envio ={num_subida_kaggle}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre_modelo = 'lgbm_e_en_abril_p_en_junio_451_features.txt'\n",
    "# model.save_model(rf\"C:\\Users\\Admin\\Documents\\1_Notebook\\1_Estudio\\1_UBA_Maestria_DS\\1_Especializacion\\1_Segundo_Semestre\\DMEyF\\modelos_lgbm\\{nombre_modelo}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
