{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precarga de librerias y funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run \"../../recurrentes.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run \"../../funciones.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activar Excel de seguimiento de medidas? \n",
    "\n",
    "excel = True\n",
    "if excel == True:\n",
    "    # Ingresar path excel para anotar resultados\n",
    "    path_excel = base_path_l + r'\\resultados_backtesting.xlsx'\n",
    "    date = datetime.now().strftime(\"%d-%m-%Y %H-%M-%S\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Cargar datos\n",
    "# Opciones:\n",
    "# a) dataset_clase_ternaria_l\n",
    "# b) dataset_lags_clase_ternaria_l\n",
    "# c) dataset_lags_deltas_y_clase_ternaria_l\n",
    "# d) dataset_10_meses_l\n",
    "\n",
    "dataset = dataset_clase_ternaria_l\n",
    "dataset_name = os.path.basename(dataset)\n",
    "df_train = pd.read_parquet(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formateo pre modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [202011, 202012, 202101, 202102, 202103, 202104, 202105, 202106] modelo 10 meses\n",
    "\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "#Defenir mes de train y test\n",
    "\n",
    "mes_train = 202105\n",
    "mes_test = 202107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'T_Visa_normal' in df_train.columns:\n",
    "    df_train['T_Visa_normal'] = df_train['T_Visa_normal'].astype(bool)\n",
    "if 'T_Master_normal'in df_train.columns:\n",
    "    df_train['T_Master_normal'] = df_train['T_Master_normal'].astype(bool)\n",
    "    \n",
    "# Binarización de la variable target\n",
    "\n",
    "data = df_train\n",
    "data['clase_peso'] = 1.0\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "data['clase_binaria'] = np.where(data['clase_ternaria']=='CONTINUA', 0, 1)\n",
    "\n",
    "# Train-Test Split\n",
    "\n",
    "if isinstance(mes_train, list):\n",
    "    df_train = data[data['foto_mes'].isin(mes_train)]\n",
    "else: df_test = data[data['foto_mes']==mes_test]\n",
    "\n",
    "# definiendo X e Y\n",
    "\n",
    "clase_peso = df_train['clase_peso']\n",
    "X_train = df_train.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_train =df_train['clase_binaria']\n",
    "X_test = df_test.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_test =df_test['clase_binaria']\n",
    "w_train = df_train['clase_peso']\n",
    "w_test = df_test['clase_peso']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   'num_leaves': best_params['num_leaves'],\n",
    "    'learning_rate': best_params['learning_rate'],\n",
    "    'min_data_in_leaf': best_params['min_data_in_leaf'],\n",
    "    'feature_fraction': best_params['feature_fraction'],\n",
    "    'bagging_fraction': best_params['bagging_fraction']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m\n\u001b[0;32m      3\u001b[0m df_voting \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m semillas:\n\u001b[0;32m      6\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboosting_type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgbdt\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_metric_only\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboost_from_average\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_pre_filter\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_bin\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m31\u001b[39m,\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m: best_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: best_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_data_in_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m: best_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_data_in_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_fraction\u001b[39m\u001b[38;5;124m'\u001b[39m: best_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_fraction\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbagging_fraction\u001b[39m\u001b[38;5;124m'\u001b[39m: best_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbagging_fraction\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m: x,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     20\u001b[0m }\n\u001b[0;32m     23\u001b[0m     model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(params,\n\u001b[0;32m     24\u001b[0m                     train_data,\n\u001b[0;32m     25\u001b[0m                     num_boost_round\u001b[38;5;241m=\u001b[39mbest_iter)\n\u001b[0;32m     27\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_params' is not defined"
     ]
    }
   ],
   "source": [
    "best_iter = 1789\n",
    "\n",
    "df_voting = pd.DataFrame()\n",
    "\n",
    "for x in semillas:\n",
    "    params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': best_params['num_leaves'],\n",
    "    'learning_rate': best_params['learning_rate'],\n",
    "    'min_data_in_leaf': best_params['min_data_in_leaf'],\n",
    "    'feature_fraction': best_params['feature_fraction'],\n",
    "    'bagging_fraction': best_params['bagging_fraction'],\n",
    "    'seed': x,\n",
    "    'verbose': 0\n",
    "}\n",
    "        \n",
    "            \n",
    "    model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=best_iter)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    df_voting[f'prediccion_seed_{x}'] = y_pred\n",
    "\n",
    "df_voting['prediccion'] = df_voting.mean(axis=1)\n",
    "df_voting.index = X_test.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164876, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediccion = pd.DataFrame({'numero_de_cliente': X_test['numero_de_cliente'], 'probabilidad': df_voting ['prediccion']}, index=X_test.index) \n",
    "prediccion.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numero_de_cliente    0\n",
       "probabilidad         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediccion.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164876, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bajas = pd.DataFrame({'numero_de_cliente': X_test['numero_de_cliente'], 'clase_ternaria': df_test['clase_ternaria']}, index= X_test.index)\n",
    "bajas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numero_de_cliente    0\n",
       "clase_ternaria       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bajas.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion.shape\n",
    "merged_data = prediccion.merge(bajas, on='numero_de_cliente', how='inner')\n",
    "\n",
    "merged_data.columns\n",
    "merged_data_sorted = merged_data.sort_values('probabilidad', ascending=False)\n",
    "\n",
    "\n",
    "# Ordenar por probabilidad de mayor a menor\n",
    "\n",
    "# Seleccionar top clientes\n",
    "top_clients = merged_data_sorted.iloc[:12000].copy()  # Trabajar con una copia\n",
    "\n",
    "# Convertir 'clase_ternaria' a variable binaria para los top clientes\n",
    "top_clients.loc[:, 'bajas_reales'] = (top_clients['clase_ternaria'] == 'BAJA+2').astype(int)\n",
    "\n",
    "top_clients.value_counts('clase_ternaria')\n",
    "top_clients.value_counts('bajas_reales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 333766, number of negative: 970448\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.219239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 49926\n",
      "[LightGBM] [Info] Number of data points in the train set: 1304214, number of used features: 295\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.255916 -> initscore=-1.067303\n",
      "[LightGBM] [Info] Start training from score -1.067303\n",
      "[LightGBM] [Info] Number of positive: 333766, number of negative: 970448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.803860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 49926\n",
      "[LightGBM] [Info] Number of data points in the train set: 1304214, number of used features: 295\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.255916 -> initscore=-1.067303\n",
      "[LightGBM] [Info] Start training from score -1.067303\n",
      "[LightGBM] [Info] Number of positive: 333766, number of negative: 970448\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.216134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 49926\n",
      "[LightGBM] [Info] Number of data points in the train set: 1304214, number of used features: 295\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.255916 -> initscore=-1.067303\n",
      "[LightGBM] [Info] Start training from score -1.067303\n",
      "[LightGBM] [Info] Number of positive: 333766, number of negative: 970448\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.227275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 49926\n",
      "[LightGBM] [Info] Number of data points in the train set: 1304214, number of used features: 295\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.255916 -> initscore=-1.067303\n",
      "[LightGBM] [Info] Start training from score -1.067303\n",
      "[LightGBM] [Info] Number of positive: 333766, number of negative: 970448\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.251520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 49926\n",
      "[LightGBM] [Info] Number of data points in the train set: 1304214, number of used features: 295\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.255916 -> initscore=-1.067303\n",
      "[LightGBM] [Info] Start training from score -1.067303\n"
     ]
    }
   ],
   "source": [
    "dicc_medidas = calcular_medidas(X_train, Y_train, w_train, X_test, Y_test, w_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if excel == True:\n",
    "    dicc_medidas['fecha'] = date\n",
    "    dicc_medidas['dataset'] = dataset_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_columnas = df_train.shape[1]\n",
    "mes_train = df_train['foto_mes'].max()\n",
    "mes_test = df_test['foto_mes'].max()\n",
    "# Agregar nota\n",
    "consideraciones = 'entrenando sólo noviembre'\n",
    "\n",
    "dicc_medidas['cantidad_columnas'] = cantidad_columnas\n",
    "dicc_medidas['mes_train'] = mes_train\n",
    "dicc_medidas['mes_test'] = mes_test\n",
    "dicc_medidas['consideraciones'] = consideraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_score': 0.9144144690555327,\n",
       " 'precision_score': 0.10829671749806151,\n",
       " 'recall_score': 0.8434826371414192,\n",
       " 'f1_score': 0.19194869151921207,\n",
       " 'roc_auc_score': 0.8793811837549762,\n",
       " 'ganancia': 142786000,\n",
       " 'fecha': '24-11-2024 17-17-52',\n",
       " 'dataset': 'dataset_10_meses.parquet',\n",
       " 'cantidad_columnas': 298,\n",
       " 'mes_train': 202106,\n",
       " 'mes_test': 202106,\n",
       " 'consideraciones': 'entrenando sólo noviembre'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicc_medidas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primera celda vacía en la fila 21\n",
      "Fila a actualizar: 21\n",
      "se actualizó fila 21 en el excel\n"
     ]
    }
   ],
   "source": [
    "if excel == True:\n",
    "    anotar_excel(path_excel, dicc_medidas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
