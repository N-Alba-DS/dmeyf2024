{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precarga de librerias y funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../recurrentes.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../funciones.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preseteo optuna especificar bucket y nombre del estudio\n",
    "\n",
    "\n",
    "# nombre_archivo = 'optimization_tree.db'\n",
    "# bucket = 'b2/'\n",
    "\n",
    "\n",
    "# estudio_optuna = base_path + 'buckets/' + bucket + 'optimization_tree.db'\n",
    "\n",
    "\n",
    "# # cargar estudio\n",
    "# # a) competencia_02\n",
    "# # b) competencia_02_lags\n",
    "# # c) competencia_02_lags_y_deltas\n",
    "\n",
    "# nombre_estudio = 'competencia_02_lags'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Cargar datos\n",
    "# Opciones:\n",
    "# a) dataset_clase_ternaria_l\n",
    "# b) dataset_lags_clase_ternaria_l\n",
    "# c) dataset_lags_deltas_y_clase_ternaria_l\n",
    "\n",
    "# df_train = pd.read_parquet(dataset_clase_ternaria_l)\n",
    "df_train = pd.read_parquet(dataset_lags_clase_ternaria_l)\n",
    "# df_lag_delta = pd.read_parquet(dataset_lags_deltas_y_clase_ternaria_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formateo pre modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'T_Visa_normal' in df_train.columns:\n",
    "    df_train['T_Visa_normal'] = df_train['T_Visa_normal'].astype(bool)\n",
    "if 'T_Master_normal'in df_train.columns:\n",
    "    df_train['T_Master_normal'] = df_train['T_Master_normal'].astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - parametros para modelo\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "mes_train = 202104\n",
    "mes_test = 202108\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4735593, 378)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['clase_peso'] = 1.0\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clase_binaria'] = np.where(data['clase_ternaria']=='CONTINUA', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificar mes de train y test\n",
    "\n",
    "df_train = data[data['foto_mes']<=202104]\n",
    "df_test = data[data['foto_mes']==202106]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4735593, 380)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4735593 entries, 0 to 4735592\n",
      "Columns: 380 entries, numero_de_cliente to clase_binaria\n",
      "dtypes: bool(2), float64(313), int32(1), int64(63), object(1)\n",
      "memory usage: 13.6 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)  # Número de filas y columnas\n",
    "print(data.info(memory_usage='deep'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_peso = df_train['clase_peso']\n",
    "X_train = df_train.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_train =df_train['clase_binaria']\n",
    "X_test = df_test.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_test =df_test['clase_binaria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train = df_train.loc[X_train.index, 'clase_peso']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar entradas en df_train en base a la columna foto_mes de meses más antiguos a más recientes\n",
    "X_train = X_train.sort_values('foto_mes', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 11.4 GiB for an array with shape (4075500, 377) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 17\u001b[0m\n\u001b[0;32m     11\u001b[0m train_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_train, label\u001b[38;5;241m=\u001b[39mY_train, weight\u001b[38;5;241m=\u001b[39mw_train)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Pasar las divisiones a lgb.cv\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mcv(\n\u001b[0;32m     18\u001b[0m     params,\n\u001b[0;32m     19\u001b[0m     train_data,\n\u001b[0;32m     20\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m,\n\u001b[0;32m     21\u001b[0m     feval\u001b[38;5;241m=\u001b[39mlgb_gan_eval,\n\u001b[0;32m     22\u001b[0m     folds\u001b[38;5;241m=\u001b[39mfolds,  \u001b[38;5;66;03m# Aquí especificamos las divisiones temporales\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     seed\u001b[38;5;241m=\u001b[39msemillas[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     26\u001b[0m cv_results\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\engine.py:774\u001b[0m, in \u001b[0;36mcv\u001b[1;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, feval, init_model, feature_name, categorical_feature, fpreproc, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[0m\n\u001b[0;32m    769\u001b[0m train_set\u001b[38;5;241m.\u001b[39m_update_params(params)\u001b[38;5;241m.\u001b[39m_set_predictor(predictor)\u001b[38;5;241m.\u001b[39mset_feature_name(feature_name)\u001b[38;5;241m.\u001b[39mset_categorical_feature(\n\u001b[0;32m    770\u001b[0m     categorical_feature\n\u001b[0;32m    771\u001b[0m )\n\u001b[0;32m    773\u001b[0m results \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m--> 774\u001b[0m cvfolds \u001b[38;5;241m=\u001b[39m _make_n_folds(\n\u001b[0;32m    775\u001b[0m     full_data\u001b[38;5;241m=\u001b[39mtrain_set,\n\u001b[0;32m    776\u001b[0m     folds\u001b[38;5;241m=\u001b[39mfolds,\n\u001b[0;32m    777\u001b[0m     nfold\u001b[38;5;241m=\u001b[39mnfold,\n\u001b[0;32m    778\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    779\u001b[0m     seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m    780\u001b[0m     fpreproc\u001b[38;5;241m=\u001b[39mfpreproc,\n\u001b[0;32m    781\u001b[0m     stratified\u001b[38;5;241m=\u001b[39mstratified,\n\u001b[0;32m    782\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m    783\u001b[0m     eval_train_metric\u001b[38;5;241m=\u001b[39meval_train_metric,\n\u001b[0;32m    784\u001b[0m )\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# setup callbacks\u001b[39;00m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\engine.py:504\u001b[0m, in \u001b[0;36m_make_n_folds\u001b[1;34m(full_data, folds, nfold, params, seed, fpreproc, stratified, shuffle, eval_train_metric)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_n_folds\u001b[39m(\n\u001b[0;32m    493\u001b[0m     full_data: Dataset,\n\u001b[0;32m    494\u001b[0m     folds: Optional[Union[Iterable[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mndarray]], _LGBMBaseCrossValidator]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    501\u001b[0m     eval_train_metric: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m    502\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CVBooster:\n\u001b[0;32m    503\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Make a n-fold list of Booster from random indices.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     full_data \u001b[38;5;241m=\u001b[39m full_data\u001b[38;5;241m.\u001b[39mconstruct()\n\u001b[0;32m    505\u001b[0m     num_data \u001b[38;5;241m=\u001b[39m full_data\u001b[38;5;241m.\u001b[39mnum_data()\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m folds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:2566\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2561\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\n\u001b[0;32m   2562\u001b[0m                 predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, used_indices\u001b[38;5;241m=\u001b[39mused_indices\n\u001b[0;32m   2563\u001b[0m             )\n\u001b[0;32m   2564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2565\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[1;32m-> 2566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(\n\u001b[0;32m   2567\u001b[0m         data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m   2568\u001b[0m         label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel,\n\u001b[0;32m   2569\u001b[0m         reference\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2570\u001b[0m         weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m   2571\u001b[0m         group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup,\n\u001b[0;32m   2572\u001b[0m         init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_score,\n\u001b[0;32m   2573\u001b[0m         predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor,\n\u001b[0;32m   2574\u001b[0m         feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_name,\n\u001b[0;32m   2575\u001b[0m         categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_feature,\n\u001b[0;32m   2576\u001b[0m         params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams,\n\u001b[0;32m   2577\u001b[0m         position\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition,\n\u001b[0;32m   2578\u001b[0m     )\n\u001b[0;32m   2579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[0;32m   2580\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:2158\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[0;32m   2156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__init_from_csc(data, params_str, ref_dataset)\n\u001b[0;32m   2157\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m-> 2158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__init_from_np2d(data, params_str, ref_dataset)\n\u001b[0;32m   2159\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_pyarrow_table(data):\n\u001b[0;32m   2160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__init_from_pyarrow_table(data, params_str, ref_dataset)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:2288\u001b[0m, in \u001b[0;36mDataset.__init_from_np2d\u001b[1;34m(self, mat, params_str, ref_dataset)\u001b[0m\n\u001b[0;32m   2286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_void_p()\n\u001b[0;32m   2287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mat\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32 \u001b[38;5;129;01mor\u001b[39;00m mat\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64:\n\u001b[1;32m-> 2288\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(mat\u001b[38;5;241m.\u001b[39mreshape(mat\u001b[38;5;241m.\u001b[39msize), dtype\u001b[38;5;241m=\u001b[39mmat\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# change non-float data to float data, need to copy\u001b[39;00m\n\u001b[0;32m   2290\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(mat\u001b[38;5;241m.\u001b[39mreshape(mat\u001b[38;5;241m.\u001b[39msize), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 11.4 GiB for an array with shape (4075500, 377) and data type float64"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "folds = tscv.split(X_train)\n",
    "\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',  # Puedes cambiar esto si tu problema es multiclase u otro tipo\n",
    "    'metric': 'binary_logloss',  # Cambia el metric si es necesario\n",
    "    }\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pasar las divisiones a lgb.cv\n",
    "cv_results = lgb.cv(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=300,\n",
    "    feval=lgb_gan_eval,\n",
    "    folds=folds,  # Aquí especificamos las divisiones temporales\n",
    "    seed=semillas[0],\n",
    ")\n",
    "\n",
    "cv_results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476000.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "final =  max_gan * 5\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTADOS:\n",
    "# 1. Modelo Base = 10737406704.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 11:24:00,504] Using an existing study with name 'competencia_02' instead of creating a new one.\n",
      "[I 2024-11-08 11:24:00,548] Using an existing study with name 'competencia_02' instead of creating a new one.\n",
      "[I 2024-11-08 11:25:26,175] Trial 1 finished with value: 484022000.0 and parameters: {'num_leaves': 73, 'learning_rate': 0.048381168713106194, 'min_data_in_leaf': 1888, 'feature_fraction': 0.9611290073992866, 'bagging_fraction': 0.5702627562564301}. Best is trial 1 with value: 484022000.0.\n",
      "[I 2024-11-08 11:26:34,198] Trial 2 finished with value: 454993000.0 and parameters: {'num_leaves': 28, 'learning_rate': 0.03703877249854557, 'min_data_in_leaf': 393, 'feature_fraction': 0.2450786254076267, 'bagging_fraction': 0.23471371488088055}. Best is trial 1 with value: 484022000.0.\n",
      "[I 2024-11-08 11:28:04,561] Trial 3 finished with value: 489223000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.05486123634370735, 'min_data_in_leaf': 1380, 'feature_fraction': 0.6184913544411021, 'bagging_fraction': 0.4808902093417563}. Best is trial 3 with value: 489223000.0.\n",
      "[W 2024-11-08 11:28:09,636] Trial 4 failed with parameters: {'num_leaves': 70, 'learning_rate': 0.09504714430284956, 'min_data_in_leaf': 1329, 'feature_fraction': 0.6429553572890628, 'bagging_fraction': 0.8918113531122719} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2908\\754118112.py\", line 33, in objective\n",
      "    cv_results = lgb.cv(\n",
      "                 ^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\engine.py\", line 827, in cv\n",
      "    res = _agg_cv_result(cvfolds.eval_valid(feval))  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\engine.py\", line 402, in handler_function\n",
      "    ret.append(getattr(booster, name)(*args, **kwargs))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py\", line 4413, in eval_valid\n",
      "    return [\n",
      "           ^\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py\", line 4416, in <listcomp>\n",
      "    for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py\", line 5177, in __inner_eval\n",
      "    feval_ret = eval_function(self.__inner_predict(data_idx), cur_data)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2908\\3141376051.py\", line 4, in lgb_gan_eval\n",
      "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
      "                        ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 1133, in argsort\n",
      "    return _wrapfunc(a, 'argsort', axis=axis, kind=kind, order=order)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 59, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-11-08 11:28:09,640] Trial 4 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 105\u001b[0m\n\u001b[0;32m     97\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[0;32m     98\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     99\u001b[0m     study_name\u001b[38;5;241m=\u001b[39mstudy_name,\n\u001b[0;32m    100\u001b[0m     storage\u001b[38;5;241m=\u001b[39mstorage_name,\n\u001b[0;32m    101\u001b[0m     load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    102\u001b[0m )\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Optimizar el estudio con el callback personalizado\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30000\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         _optimize_sequential(\n\u001b[0;32m     63\u001b[0m             study,\n\u001b[0;32m     64\u001b[0m             func,\n\u001b[0;32m     65\u001b[0m             n_trials,\n\u001b[0;32m     66\u001b[0m             timeout,\n\u001b[0;32m     67\u001b[0m             catch,\n\u001b[0;32m     68\u001b[0m             callbacks,\n\u001b[0;32m     69\u001b[0m             gc_after_trial,\n\u001b[0;32m     70\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     71\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[105], line 33\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      8\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     27\u001b[0m }\n\u001b[0;32m     29\u001b[0m train_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_train,\n\u001b[0;32m     30\u001b[0m                          label\u001b[38;5;241m=\u001b[39mY_train,  \u001b[38;5;66;03m# elegir la clase\u001b[39;00m\n\u001b[0;32m     31\u001b[0m                          weight\u001b[38;5;241m=\u001b[39mw_train)\n\u001b[1;32m---> 33\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mcv(\n\u001b[0;32m     34\u001b[0m     params,\n\u001b[0;32m     35\u001b[0m     train_data,\n\u001b[0;32m     36\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m,  \u001b[38;5;66;03m# modificar, subir y subir... y descomentar la línea inferior\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \n\u001b[0;32m     38\u001b[0m     feval\u001b[38;5;241m=\u001b[39mlgb_gan_eval,\n\u001b[0;32m     39\u001b[0m     stratified\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     40\u001b[0m     nfold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     41\u001b[0m     seed\u001b[38;5;241m=\u001b[39msemillas[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     44\u001b[0m max_gan \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid gan_eval-mean\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     45\u001b[0m best_iter \u001b[38;5;241m=\u001b[39m cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid gan_eval-mean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mindex(max_gan) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\engine.py:827\u001b[0m, in \u001b[0;36mcv\u001b[1;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, feval, init_model, feature_name, categorical_feature, fpreproc, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[0m\n\u001b[0;32m    816\u001b[0m     cb(\n\u001b[0;32m    817\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[0;32m    818\u001b[0m             model\u001b[38;5;241m=\u001b[39mcvfolds,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    824\u001b[0m         )\n\u001b[0;32m    825\u001b[0m     )\n\u001b[0;32m    826\u001b[0m cvfolds\u001b[38;5;241m.\u001b[39mupdate(fobj\u001b[38;5;241m=\u001b[39mfobj)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 827\u001b[0m res \u001b[38;5;241m=\u001b[39m _agg_cv_result(cvfolds\u001b[38;5;241m.\u001b[39meval_valid(feval))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, key, mean, _, std \u001b[38;5;129;01min\u001b[39;00m res:\n\u001b[0;32m    829\u001b[0m     results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-mean\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(mean)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\engine.py:402\u001b[0m, in \u001b[0;36mCVBooster.__getattr__.<locals>.handler_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m booster \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboosters:\n\u001b[1;32m--> 402\u001b[0m     ret\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mgetattr\u001b[39m(booster, name)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:4413\u001b[0m, in \u001b[0;36mBooster.eval_valid\u001b[1;34m(self, feval)\u001b[0m\n\u001b[0;32m   4381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_valid\u001b[39m(\n\u001b[0;32m   4382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4383\u001b[0m     feval: Optional[Union[_LGBM_CustomEvalFunction, List[_LGBM_CustomEvalFunction]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4384\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[_LGBM_BoosterEvalMethodResultType]:\n\u001b[0;32m   4385\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate for validation data.\u001b[39;00m\n\u001b[0;32m   4386\u001b[0m \n\u001b[0;32m   4387\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4411\u001b[0m \u001b[38;5;124;03m        List with (validation_dataset_name, eval_name, eval_result, is_higher_better) tuples.\u001b[39;00m\n\u001b[0;32m   4412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m   4414\u001b[0m         item\n\u001b[0;32m   4415\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)\n\u001b[0;32m   4416\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__inner_eval(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_valid_sets[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], i, feval)\n\u001b[0;32m   4417\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:4416\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   4381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_valid\u001b[39m(\n\u001b[0;32m   4382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4383\u001b[0m     feval: Optional[Union[_LGBM_CustomEvalFunction, List[_LGBM_CustomEvalFunction]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4384\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[_LGBM_BoosterEvalMethodResultType]:\n\u001b[0;32m   4385\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate for validation data.\u001b[39;00m\n\u001b[0;32m   4386\u001b[0m \n\u001b[0;32m   4387\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4411\u001b[0m \u001b[38;5;124;03m        List with (validation_dataset_name, eval_name, eval_result, is_higher_better) tuples.\u001b[39;00m\n\u001b[0;32m   4412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m   4414\u001b[0m         item\n\u001b[0;32m   4415\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)\n\u001b[1;32m-> 4416\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__inner_eval(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_valid_sets[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], i, feval)\n\u001b[0;32m   4417\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:5177\u001b[0m, in \u001b[0;36mBooster.__inner_eval\u001b[1;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[0;32m   5175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5176\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m-> 5177\u001b[0m feval_ret \u001b[38;5;241m=\u001b[39m eval_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__inner_predict(data_idx), cur_data)\n\u001b[0;32m   5178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feval_ret, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m   5179\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m eval_name, val, is_higher_better \u001b[38;5;129;01min\u001b[39;00m feval_ret:\n",
      "Cell \u001b[1;32mIn[45], line 4\u001b[0m, in \u001b[0;36mlgb_gan_eval\u001b[1;34m(y_pred, data)\u001b[0m\n\u001b[0;32m      2\u001b[0m weight \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget_weight()\n\u001b[0;32m      3\u001b[0m ganancia \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.00002\u001b[39m, ganancia_acierto, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(weight \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1.00002\u001b[39m, costo_estimulo, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m ganancia \u001b[38;5;241m=\u001b[39m ganancia[np\u001b[38;5;241m.\u001b[39margsort(y_pred)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m      5\u001b[0m ganancia \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(ganancia)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgan_eval\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmax(ganancia) , \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1133\u001b[0m, in \u001b[0;36margsort\u001b[1;34m(a, axis, kind, order)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margsort\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \n\u001b[0;32m   1132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margsort\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, kind\u001b[38;5;241m=\u001b[39mkind, order\u001b[38;5;241m=\u001b[39morder)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 4 - Optimizacion\n",
    "\n",
    "def objective(trial):\n",
    "    num_leaves = trial.suggest_int('num_leaves', 8, 100)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.00005, 0.3)  # mas bajo, más iteraciones necesita\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 2000)\n",
    "    feature_fraction = trial.suggest_float('feature_fraction', 0.1, 1.0)\n",
    "    bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'min_data_in_leaf': min_data_in_leaf,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'seed': semillas[0],\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                             label=Y_train,  # elegir la clase\n",
    "                             weight=w_train)\n",
    "                             \n",
    "    cv_results = lgb.cv(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=300,  # modificar, subir y subir... y descomentar la línea inferior\n",
    "        \n",
    "        feval=lgb_gan_eval,\n",
    "        stratified=True,\n",
    "        nfold=5,\n",
    "        seed=semillas[0]\n",
    "    )\n",
    "\n",
    "    max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "    best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "    # Guardamos cual es la mejor iteración del modelo\n",
    "    trial.set_user_attr(\"best_iter\", best_iter)\n",
    "\n",
    "    return max_gan * 5\n",
    "\n",
    "storage_name = rf\"sqlite:///{estudio_optuna}\"\n",
    "\n",
    "study_name = nombre_estudio\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "import optuna\n",
    "\n",
    "class EarlyStoppingByImprovement:\n",
    "    def __init__(self, patience: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Número de pruebas consecutivas sin mejora antes de detener la optimización.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.best_value = None\n",
    "        self.no_improvement_trials = 0\n",
    "\n",
    "    def __call__(self, study, trial):\n",
    "        current_best_value = study.best_trial.value\n",
    "\n",
    "        # Si la métrica mejora, reseteamos el contador\n",
    "        if self.best_value is None or current_best_value > self.best_value:\n",
    "            self.best_value = current_best_value\n",
    "            self.no_improvement_trials = 0\n",
    "        else:\n",
    "            # Si no hay mejora, incrementamos el contador\n",
    "            self.no_improvement_trials += 1\n",
    "\n",
    "        # Detener si no ha habido mejora en 'self.patience' pruebas consecutivas\n",
    "        if self.no_improvement_trials >= self.patience:\n",
    "            print(f\"Early stopping: No hay mejora en {self.patience} pruebas consecutivas.\")\n",
    "            study.stop()\n",
    "\n",
    "# Crear el callback con 100 pruebas consecutivas sin mejora\n",
    "early_stopping_callback = EarlyStoppingByImprovement(patience=100)\n",
    "\n",
    "# Crear el estudio\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "# Optimizar el estudio con el callback personalizado\n",
    "study.optimize(objective, n_trials=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor cantidad de árboles para el mejor model 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2908\\1798680220.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_voting['promedio'] = df_voting.mean(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# 6 - Voting promedio de modelos para reducir varianza\n",
    "\n",
    "best_iter = study.best_trial.user_attrs[\"best_iter\"]\n",
    "print(f\"Mejor cantidad de árboles para el mejor model {best_iter}\")\n",
    "\n",
    "train_data = lgb.Dataset(X_train,\n",
    "                            label=Y_train,\n",
    "                            weight=w_train)\n",
    "\n",
    "df_voting = pd.DataFrame()\n",
    "\n",
    "for semilla in numeros_random:\n",
    "    params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': study.best_params['num_leaves'],\n",
    "    'learning_rate': study.best_params['learning_rate'],\n",
    "    'min_data_in_leaf': study.best_params['min_data_in_leaf'],\n",
    "    'feature_fraction': study.best_params['feature_fraction'],\n",
    "    'bagging_fraction': study.best_params['bagging_fraction'],\n",
    "    'seed': semilla,\n",
    "    'verbose': 0\n",
    "}\n",
    "    \n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=best_iter)\n",
    "    \n",
    "    df_voting[f'semilla_{semilla}'] = model.predict(X_test)\n",
    "\n",
    "df_voting['promedio'] = df_voting.mean(axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 - Predicción del modelo \n",
    "\n",
    "y_pred_lgm = df_voting['promedio']\n",
    "y_pred_labels = (y_pred_lgm > 0.025).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 - Dataframe con las variables más importantes\n",
    "importancias = model.feature_importance()\n",
    "nombres = model.feature_name()\n",
    "df_resultado = pd.DataFrame({\n",
    "    'numero_de_cliente': X_test['numero_de_cliente'],\n",
    "    'Predicted': y_pred_labels\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrega Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ingresar el path sobre el cual se quiere ingresar el archivo a entregar\n",
    "entrega = 'entrega_kaggle'\n",
    "formato = '.csv'\n",
    "numero = entrega+'_001'+formato\n",
    "entrega_final = df_resultado.to_csv(rf\"{save_path}{numero}}\", index=False)\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_columnas = df_gbm.shape[1]\n",
    "message = f\"{entrega}, cantidad de columnas en el train: {cantidad_columnas}, modelo: LGBM, mejores parametros: {best_params}, mejor iteracion: {best_iter}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Kaggle -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "competition= 'DMEyF-2024-Segunda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.api.competition_submit(competition=competition, file_name= numero, message=message, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puntos de corte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predicciones = y_pred_lgm\n",
    "\n",
    "# X_test['Probabilidad'] = predicciones\n",
    "\n",
    "# tb_entrega = X_test.sort_values(by='Probabilidad', ascending=False)\n",
    "\n",
    "# cortes = range(9000,14000,100)\n",
    "\n",
    "# num_subida_kaggle = 65\n",
    "# for envios in cortes:\n",
    "    \n",
    "#     tb_entrega['Predicted'] = 0\n",
    "#     tb_entrega.iloc[:envios, tb_entrega.columns.get_loc('Predicted')] = 1\n",
    "#     resultados = tb_entrega[[\"numero_de_cliente\", 'Predicted']].reset_index(drop=True)\n",
    "    \n",
    "#     print(\"Cantidad de clientes {}\".format(envios))\n",
    "    \n",
    "#     nombre_archivo = 'entrega_0{}.csv'.format(num_subida_kaggle)\n",
    "#     entrega_final = os.path.join(path, nombre_archivo)\n",
    "#     resultados.to_csv(entrega_final, index=False)\n",
    "    \n",
    "    \n",
    "#     cantidad_columnas = df_train.shape[1]\n",
    "#     message = f\"{entrega}, cantidad de columnas en el train: {cantidad_columnas}, modelo: LGBM, mejores parametros: {best_params}, mejor iteracion: {best_iter}, archivo: {entrega_final}, punto de corte: {envios}, optimizado con optuna: {study_name}\"\n",
    "    \n",
    "#     num_subida_kaggle += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "#     entrega_final = os.path.join(path, nombre_archivo)   \n",
    "#     competencia = 'dm-ey-f-2024-primera'\n",
    "#     try:\n",
    "#         api.competition_submit(file_name=entrega_final,message=message,competition=competencia)\n",
    "#     except:\n",
    "#         print(f\"Numero máximo de envios, último envio ={num_subida_kaggle}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre_modelo = 'lgbm_e_en_abril_p_en_junio_451_features.txt'\n",
    "# model.save_model(rf\"C:\\Users\\Admin\\Documents\\1_Notebook\\1_Estudio\\1_UBA_Maestria_DS\\1_Especializacion\\1_Segundo_Semestre\\DMEyF\\modelos_lgbm\\{nombre_modelo}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
