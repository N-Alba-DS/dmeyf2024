{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precarga de librerias y funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imblearn) (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "%run \"../recurrentes.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../funciones.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activar Excel de seguimiento de medidas? \n",
    "\n",
    "excel = True\n",
    "if excel == True:\n",
    "    # Ingresar path excel para anotar resultados\n",
    "    path_excel = base_path_l + r'\\resultados_backtesting.xlsx'\n",
    "    date = datetime.now().strftime(\"%d-%m-%Y %H-%M-%S\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Cargar datos\n",
    "# Opciones:\n",
    "# a) dataset_clase_ternaria_l\n",
    "# b) dataset_lags_clase_ternaria_l\n",
    "# c) dataset_lags_deltas_y_clase_ternaria_l\n",
    "\n",
    "\n",
    "dataset = dataset_clase_ternaria_l\n",
    "dataset_name = os.path.basename(dataset)\n",
    "df_train = pd.read_parquet(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formateo pre modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'T_Visa_normal' in df_train.columns:\n",
    "    df_train['T_Visa_normal'] = df_train['T_Visa_normal'].astype(bool)\n",
    "if 'T_Master_normal'in df_train.columns:\n",
    "    df_train['T_Master_normal'] = df_train['T_Master_normal'].astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - parametros para modelo\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "mes_train = 202104\n",
    "mes_test = 202106\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4735593, 155)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df_train\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['clase_peso'] = 1.0\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clase_binaria'] = np.where(data['clase_ternaria']=='CONTINUA', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908,\n",
       "       201909, 201910, 201911, 201912, 202001, 202002, 202003, 202004,\n",
       "       202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
       "       202101, 202102, 202103, 202104, 202105, 202106, 202107, 202108],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['foto_mes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificar mes de train y test\n",
    "\n",
    "df_train = data[data['foto_mes']<=mes_train]\n",
    "df_test = data[data['foto_mes']==mes_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4735593, 157)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4735593 entries, 0 to 4735592\n",
      "Columns: 157 entries, numero_de_cliente to clase_binaria\n",
      "dtypes: float64(92), int32(1), int64(63), object(1)\n",
      "memory usage: 5.8 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)  # Número de filas y columnas\n",
    "print(data.info(memory_usage='deep'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_peso = df_train['clase_peso']\n",
    "X_train = df_train.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_train =df_train['clase_binaria']\n",
    "X_test = df_test.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_test =df_test['clase_binaria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train = df_train.loc[X_train.index, 'clase_peso']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero_de_cliente</th>\n",
       "      <th>foto_mes</th>\n",
       "      <th>active_quarter</th>\n",
       "      <th>cliente_vip</th>\n",
       "      <th>internet</th>\n",
       "      <th>cliente_edad</th>\n",
       "      <th>cliente_antiguedad</th>\n",
       "      <th>mrentabilidad</th>\n",
       "      <th>mrentabilidad_annual</th>\n",
       "      <th>mcomisiones</th>\n",
       "      <th>...</th>\n",
       "      <th>Visa_madelantodolares</th>\n",
       "      <th>Visa_fultimo_cierre</th>\n",
       "      <th>Visa_mpagado</th>\n",
       "      <th>Visa_mpagospesos</th>\n",
       "      <th>Visa_mpagosdolares</th>\n",
       "      <th>Visa_fechaalta</th>\n",
       "      <th>Visa_mconsumototal</th>\n",
       "      <th>Visa_cconsumos</th>\n",
       "      <th>Visa_cadelantosefectivo</th>\n",
       "      <th>Visa_mpagominimo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249221109</td>\n",
       "      <td>201901</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>276</td>\n",
       "      <td>7597.55</td>\n",
       "      <td>47433.58</td>\n",
       "      <td>5654.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-44919.57</td>\n",
       "      <td>3.23</td>\n",
       "      <td>7136.0</td>\n",
       "      <td>24336.99</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1466.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>249221468</td>\n",
       "      <td>201901</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>738.16</td>\n",
       "      <td>-325.09</td>\n",
       "      <td>491.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-30184.75</td>\n",
       "      <td>15.24</td>\n",
       "      <td>393.0</td>\n",
       "      <td>16345.79</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1548.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>249223005</td>\n",
       "      <td>201901</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>178</td>\n",
       "      <td>1014.31</td>\n",
       "      <td>9434.15</td>\n",
       "      <td>417.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3730.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2755.0</td>\n",
       "      <td>1181.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3917.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>249228180</td>\n",
       "      <td>201901</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>296</td>\n",
       "      <td>1028.33</td>\n",
       "      <td>6873.80</td>\n",
       "      <td>1129.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13196.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8194.0</td>\n",
       "      <td>1892.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>249232117</td>\n",
       "      <td>201901</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>349</td>\n",
       "      <td>11617.61</td>\n",
       "      <td>43291.55</td>\n",
       "      <td>10726.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-22073.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7876.0</td>\n",
       "      <td>21902.85</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>891.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075495</th>\n",
       "      <td>1592771867</td>\n",
       "      <td>202104</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>35.79</td>\n",
       "      <td>35.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075496</th>\n",
       "      <td>1592792217</td>\n",
       "      <td>202104</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075497</th>\n",
       "      <td>1592797828</td>\n",
       "      <td>202104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>47.62</td>\n",
       "      <td>47.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075498</th>\n",
       "      <td>1592799066</td>\n",
       "      <td>202104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075499</th>\n",
       "      <td>1592802567</td>\n",
       "      <td>202104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>607.69</td>\n",
       "      <td>607.69</td>\n",
       "      <td>599.76</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4075500 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         numero_de_cliente  foto_mes  active_quarter  cliente_vip  internet  \\\n",
       "0                249221109    201901               1            0         1   \n",
       "1                249221468    201901               1            0         1   \n",
       "2                249223005    201901               1            0         1   \n",
       "3                249228180    201901               1            0         1   \n",
       "4                249232117    201901               1            0         1   \n",
       "...                    ...       ...             ...          ...       ...   \n",
       "4075495         1592771867    202104               1            0         0   \n",
       "4075496         1592792217    202104               1            0         0   \n",
       "4075497         1592797828    202104               0            0         0   \n",
       "4075498         1592799066    202104               0            0         0   \n",
       "4075499         1592802567    202104               0            0         0   \n",
       "\n",
       "         cliente_edad  cliente_antiguedad  mrentabilidad  \\\n",
       "0                  59                 276        7597.55   \n",
       "1                  51                  13         738.16   \n",
       "2                  46                 178        1014.31   \n",
       "3                  64                 296        1028.33   \n",
       "4                  77                 349       11617.61   \n",
       "...               ...                 ...            ...   \n",
       "4075495            28                   1          35.79   \n",
       "4075496            18                   1           4.85   \n",
       "4075497            36                   1          47.62   \n",
       "4075498            37                   1           0.00   \n",
       "4075499            29                   1         607.69   \n",
       "\n",
       "         mrentabilidad_annual  mcomisiones  ...  Visa_madelantodolares  \\\n",
       "0                    47433.58      5654.59  ...                    0.0   \n",
       "1                     -325.09       491.31  ...                    0.0   \n",
       "2                     9434.15       417.36  ...                    0.0   \n",
       "3                     6873.80      1129.43  ...                    0.0   \n",
       "4                    43291.55     10726.08  ...                    0.0   \n",
       "...                       ...          ...  ...                    ...   \n",
       "4075495                 35.79         0.00  ...                    NaN   \n",
       "4075496                  4.85         0.00  ...                    NaN   \n",
       "4075497                 47.62         0.00  ...                    NaN   \n",
       "4075498                  0.00         0.00  ...                    NaN   \n",
       "4075499                607.69       599.76  ...                    NaN   \n",
       "\n",
       "         Visa_fultimo_cierre  Visa_mpagado  Visa_mpagospesos  \\\n",
       "0                        1.0           0.0         -44919.57   \n",
       "1                        1.0           0.0         -30184.75   \n",
       "2                        1.0           0.0          -3730.14   \n",
       "3                        1.0           0.0         -13196.25   \n",
       "4                        1.0           0.0         -22073.65   \n",
       "...                      ...           ...               ...   \n",
       "4075495                  2.0           0.0               NaN   \n",
       "4075496                  2.0           0.0               NaN   \n",
       "4075497                  2.0           0.0               NaN   \n",
       "4075498                  2.0           0.0               NaN   \n",
       "4075499                  2.0           0.0               NaN   \n",
       "\n",
       "         Visa_mpagosdolares  Visa_fechaalta  Visa_mconsumototal  \\\n",
       "0                      3.23          7136.0            24336.99   \n",
       "1                     15.24           393.0            16345.79   \n",
       "2                      0.00          2755.0             1181.65   \n",
       "3                      0.00          8194.0             1892.04   \n",
       "4                      0.00          7876.0            21902.85   \n",
       "...                     ...             ...                 ...   \n",
       "4075495                 NaN            22.0                 NaN   \n",
       "4075496                 NaN            18.0                 NaN   \n",
       "4075497                 NaN            17.0                 NaN   \n",
       "4075498                 NaN            19.0                 NaN   \n",
       "4075499                 NaN            12.0                 NaN   \n",
       "\n",
       "         Visa_cconsumos  Visa_cadelantosefectivo  Visa_mpagominimo  \n",
       "0                  13.0                      0.0           1466.25  \n",
       "1                   8.0                      0.0           1548.36  \n",
       "2                   3.0                      0.0           3917.82  \n",
       "3                   1.0                      0.0           2017.56  \n",
       "4                   6.0                      0.0            891.48  \n",
       "...                 ...                      ...               ...  \n",
       "4075495             NaN                      NaN              0.00  \n",
       "4075496             NaN                      NaN              0.00  \n",
       "4075497             NaN                      NaN              0.00  \n",
       "4075498             NaN                      NaN              0.00  \n",
       "4075499             NaN                      NaN              0.00  \n",
       "\n",
       "[4075500 rows x 154 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13800\\1651022412.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_train.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X_train.fillna(0, inplace=True)\n",
    "Y_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# Separar train y test según 'foto_mes'\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "\n",
    "# Aplicar Tomek Links respetando las series temporales\n",
    "# Crear una ventana acumulativa para mantener la dependencia temporal\n",
    "# Inicializar las listas para almacenar los datos remuestreados\n",
    "X_resampled_list = []\n",
    "y_resampled_list = []\n",
    "\n",
    "for i in range(201901, 202106):\n",
    "    mask = df_train['foto_mes'] == i\n",
    "    X_window = X_train[mask].copy()\n",
    "    y_window = Y_train[mask].copy()\n",
    "    \n",
    "    # Verificar si y_window tiene más de una clase\n",
    "    if y_window.nunique() > 1:\n",
    "        # Aplicar Tomek Links\n",
    "        cc = ClusterCentroids(random_state=0)\n",
    "        X_resampled, y_resampled = cc.fit_resample(X_train, Y_train)\n",
    "    else:\n",
    "        # Si solo hay una clase, conservar los datos originales\n",
    "        X_resampled_window = X_window\n",
    "        y_resampled_window = y_window\n",
    "    \n",
    "    # Almacenar los datos resampleados\n",
    "    X_resampled_list.append(X_resampled_window)\n",
    "    y_resampled_list.append(y_resampled_window)\n",
    "\n",
    "# Concatenar los datos resampleados\n",
    "X_resampled = pd.concat(X_resampled_list)\n",
    "y_resampled = pd.concat(y_resampled_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_resampled \n",
    "Y_train = y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train = df_train.loc[X_train.index, 'clase_peso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1.0\n",
       "1         1.0\n",
       "2         1.0\n",
       "3         1.0\n",
       "4         1.0\n",
       "         ... \n",
       "163095    1.0\n",
       "163096    1.0\n",
       "163097    1.0\n",
       "163098    1.0\n",
       "163099    1.0\n",
       "Name: clase_peso, Length: 4062281, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x17f9c9c36d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_test = df_test.loc[Y_test.index, 'clase_peso']\n",
    "test_data = lgb.Dataset(X_test, label=Y_test, weight=w_test)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar entradas en df_train en base a la columna foto_mes de meses más antiguos a más recientes\n",
    "X_train = X_train.sort_values('foto_mes', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[400009, 500009, 500011, 500021, 600009]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7210, number of negative: 672040\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 679250, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 76290, number of negative: 1282210\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.134004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 1358500, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 294796, number of negative: 1742954\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.683766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2037750, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 299732, number of negative: 2417268\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.247461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2717000, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 597781, number of negative: 2798469\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.291444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 3396250, number of used features: 154\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010615 -> initscore=-4.534834\n",
      "[LightGBM] [Info] Start training from score -4.534834\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.056159 -> initscore=-2.821779\n",
      "[LightGBM] [Info] Start training from score -2.821779\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.144669 -> initscore=-1.777038\n",
      "[LightGBM] [Info] Start training from score -1.777038\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.110319 -> initscore=-2.087490\n",
      "[LightGBM] [Info] Start training from score -2.087490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.176014 -> initscore=-1.543588\n",
      "[LightGBM] [Info] Start training from score -1.543588\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "folds = tscv.split(X_train)\n",
    "\n",
    "lista_cv = []\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',  # Puedes cambiar esto si tu problema es multiclase u otro tipo\n",
    "    'metric': 'binary_logloss',  # Cambia el metric si es necesario\n",
    "    }\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pasar las divisiones a lgb.cv\n",
    "cv_results = lgb.cv(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=300,\n",
    "    feval=lgb_gan_eval,\n",
    "    folds=folds,  # Aquí especificamos las divisiones temporales\n",
    "    seed=s,\n",
    ")\n",
    "\n",
    "cv_results\n",
    "\n",
    "max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "final =  max_gan * 5\n",
    "lista_cv.append(final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7210, number of negative: 672040\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 679250, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 76290, number of negative: 1282210\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.130294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 1358500, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 294796, number of negative: 1742954\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.721174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2037750, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 299732, number of negative: 2417268\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.278071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2717000, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 597781, number of negative: 2798469\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.007719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 3396250, number of used features: 154\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010615 -> initscore=-4.534834\n",
      "[LightGBM] [Info] Start training from score -4.534834\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.056159 -> initscore=-2.821779\n",
      "[LightGBM] [Info] Start training from score -2.821779\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.144669 -> initscore=-1.777038\n",
      "[LightGBM] [Info] Start training from score -1.777038\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.110319 -> initscore=-2.087490\n",
      "[LightGBM] [Info] Start training from score -2.087490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.176014 -> initscore=-1.543588\n",
      "[LightGBM] [Info] Start training from score -1.543588\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "folds = tscv.split(X_train)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',  # Puedes cambiar esto si tu problema es multiclase u otro tipo\n",
    "    'metric': 'binary_logloss',  # Cambia el metric si es necesario\n",
    "    }\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pasar las divisiones a lgb.cv\n",
    "cv_results = lgb.cv(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=300,\n",
    "    feval=lgb_gan_eval,\n",
    "    folds=folds,  # Aquí especificamos las divisiones temporales\n",
    "    seed=semillas[1],\n",
    ")\n",
    "\n",
    "cv_results\n",
    "\n",
    "max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "final_1 =  max_gan * 5\n",
    "lista_cv.append(final_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7210, number of negative: 672040\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 679250, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 76290, number of negative: 1282210\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.129290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 1358500, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 294796, number of negative: 1742954\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.194033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2037750, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 299732, number of negative: 2417268\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.278097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2717000, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 597781, number of negative: 2798469\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.295693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 3396250, number of used features: 154\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010615 -> initscore=-4.534834\n",
      "[LightGBM] [Info] Start training from score -4.534834\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.056159 -> initscore=-2.821779\n",
      "[LightGBM] [Info] Start training from score -2.821779\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.144669 -> initscore=-1.777038\n",
      "[LightGBM] [Info] Start training from score -1.777038\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.110319 -> initscore=-2.087490\n",
      "[LightGBM] [Info] Start training from score -2.087490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.176014 -> initscore=-1.543588\n",
      "[LightGBM] [Info] Start training from score -1.543588\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "folds = tscv.split(X_train)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',  # Puedes cambiar esto si tu problema es multiclase u otro tipo\n",
    "    'metric': 'binary_logloss',  # Cambia el metric si es necesario\n",
    "    }\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pasar las divisiones a lgb.cv\n",
    "cv_results = lgb.cv(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=300,\n",
    "    feval=lgb_gan_eval,\n",
    "    folds=folds,  # Aquí especificamos las divisiones temporales\n",
    "    seed=semillas[2],\n",
    ")\n",
    "\n",
    "cv_results\n",
    "\n",
    "max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "final_2 =  max_gan * 5\n",
    "lista_cv.append(final_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7210, number of negative: 672040\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 679250, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 76290, number of negative: 1282210\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.156746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 1358500, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 294796, number of negative: 1742954\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.214265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2037750, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 299732, number of negative: 2417268\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.242960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2717000, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 597781, number of negative: 2798469\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.334603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 3396250, number of used features: 154\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010615 -> initscore=-4.534834\n",
      "[LightGBM] [Info] Start training from score -4.534834\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.056159 -> initscore=-2.821779\n",
      "[LightGBM] [Info] Start training from score -2.821779\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.144669 -> initscore=-1.777038\n",
      "[LightGBM] [Info] Start training from score -1.777038\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.110319 -> initscore=-2.087490\n",
      "[LightGBM] [Info] Start training from score -2.087490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.176014 -> initscore=-1.543588\n",
      "[LightGBM] [Info] Start training from score -1.543588\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "folds = tscv.split(X_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',  # Puedes cambiar esto si tu problema es multiclase u otro tipo\n",
    "    'metric': 'binary_logloss',  # Cambia el metric si es necesario\n",
    "    }\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pasar las divisiones a lgb.cv\n",
    "cv_results = lgb.cv(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=300,\n",
    "    feval=lgb_gan_eval,\n",
    "    folds=folds,  # Aquí especificamos las divisiones temporales\n",
    "    seed=semillas[3],\n",
    ")\n",
    "\n",
    "cv_results\n",
    "\n",
    "max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "final_3 =  max_gan * 5\n",
    "lista_cv.append(final_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7210, number of negative: 672040\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 679250, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 76290, number of negative: 1282210\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.440371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 1358500, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 294796, number of negative: 1742954\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.191630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2037750, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 299732, number of negative: 2417268\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.282642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2717000, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 597781, number of negative: 2798469\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.115082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 3396250, number of used features: 154\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010615 -> initscore=-4.534834\n",
      "[LightGBM] [Info] Start training from score -4.534834\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.056159 -> initscore=-2.821779\n",
      "[LightGBM] [Info] Start training from score -2.821779\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.144669 -> initscore=-1.777038\n",
      "[LightGBM] [Info] Start training from score -1.777038\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.110319 -> initscore=-2.087490\n",
      "[LightGBM] [Info] Start training from score -2.087490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.176014 -> initscore=-1.543588\n",
      "[LightGBM] [Info] Start training from score -1.543588\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "folds = tscv.split(X_train)\n",
    "\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',  # Puedes cambiar esto si tu problema es multiclase u otro tipo\n",
    "    'metric': 'binary_logloss',  # Cambia el metric si es necesario\n",
    "    }\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pasar las divisiones a lgb.cv\n",
    "cv_results = lgb.cv(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=300,\n",
    "    feval=lgb_gan_eval,\n",
    "    folds=folds,  # Aquí especificamos las divisiones temporales\n",
    "    seed=semillas[4],\n",
    ")\n",
    "\n",
    "cv_results\n",
    "\n",
    "max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "final_4 =  max_gan * 5\n",
    "lista_cv.append(final_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10737406704.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalisimo =  sum(lista_cv)/ len(lista_cv)  \n",
    "finalisimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTADOS:\n",
    "# 1. Modelo Base = 10737406704.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción y scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc_medidas = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_medidas(X_train, Y_train, w_train, X_test, Y_test, w_test):\n",
    "\n",
    "    lista_medidas = [accuracy_score, precision_score, recall_score, f1_score, roc_auc_score]\n",
    "    train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "    train_data = lgb.Dataset(X_test, label=X_test, weight=w_test)\n",
    "    df_voting = pd.DataFrame()\n",
    "\n",
    "    for semilla in semillas:\n",
    "        params = {\n",
    "            'objective': 'binary',  \n",
    "            'metric': 'binary_logloss',  \n",
    "            'seed': semilla, }\n",
    "        model_default = lgb.train(params, train_data)   \n",
    "        \n",
    "        df_voting[f'semilla_{semilla}'] = model_default.predict(X_test)\n",
    "\n",
    "    df_voting['promedio'] = df_voting.mean(axis=1)\n",
    "    y_pred_default = df_voting['promedio']\n",
    "    y_pred_labels = (y_pred_default >= 0.025).astype(int)\n",
    "    dicc_medidas = {}\n",
    "    \n",
    "    for medida in lista_medidas:\n",
    "     dicc_medidas[medida.__name__] = medida(Y_test, y_pred_labels)\n",
    "    ganancia = lgb_gan_eval(y_pred_default, test_data)\n",
    "    dicc_medidas['ganancia'] = ganancia[1]\n",
    "    \n",
    "    return dicc_medidas\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Medidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_default = df_voting['promedio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if excel == True:\n",
    "    dicc_medidas['fecha'] = date\n",
    "    dicc_medidas['dataset'] = dataset_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fecha': '20-11-2024 20-35-46', 'dataset': 'competencia_02_ct.parquet', 'accuracy_score': 0.9173560736553531, 'precision_score': 0.08968483395614468, 'recall_score': 0.6401610468042275, 'f1_score': 0.15732838589981446, 'roc_auc_score': 0.7804492407495098}\n"
     ]
    }
   ],
   "source": [
    "for medida in lista_medidas:\n",
    "     dicc_medidas[medida.__name__] = medida(Y_test, y_pred_labels)\n",
    "print(dicc_medidas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganancia = lgb_gan_eval(y_pred_default, test_data)\n",
    "dicc_medidas['ganancia'] = ganancia[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_columnas = df_train.shape[1]\n",
    "mes_train = df_train['foto_mes'].max()\n",
    "mes_test = df_test['foto_mes'].max()\n",
    "# Agregar nota\n",
    "consideraciones = 'undersampling con Tomek Links'\n",
    "\n",
    "dicc_medidas['cantidad_columnas'] = cantidad_columnas\n",
    "dicc_medidas['mes_train'] = mes_train\n",
    "dicc_medidas['mes_test'] = mes_test\n",
    "dicc_medidas['consideraciones'] = consideraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fecha': '20-11-2024 20-35-46',\n",
       " 'dataset': 'competencia_02_ct.parquet',\n",
       " 'accuracy_score': 0.9173560736553531,\n",
       " 'precision_score': 0.08968483395614468,\n",
       " 'recall_score': 0.6401610468042275,\n",
       " 'f1_score': 0.15732838589981446,\n",
       " 'roc_auc_score': 0.7804492407495098,\n",
       " 'ganancia': 75285000,\n",
       " 'cantidad_columnas': 157,\n",
       " 'mes_train': 202104,\n",
       " 'mes_test': 202106,\n",
       " 'consideraciones': 'undersampling con Tomek Links'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicc_medidas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapeo de columnas: {'fecha': 1, 'dataset': 2, 'mes_train': 3, 'mes_test': 4, 'consideraciones': 5, 'ganancia': 6, 'accuracy_score': 7, 'precision_score': 8, 'recall_score': 9, 'f1_score': 10, None: 13, 'cantidad_columnas': 12}\n",
      "Primera celda vacía en la fila 20\n",
      "Fila a actualizar: 20\n"
     ]
    }
   ],
   "source": [
    "if excel == True:\n",
    "    \n",
    "    wb = load_workbook(path_excel)\n",
    "    ws = wb.active\n",
    "\n",
    "    header_row = 1  \n",
    "    column_mapping = {cell.value: cell.column for cell in ws[header_row]}\n",
    "\n",
    "    # Verificar el mapeo de columnas\n",
    "    print(\"Mapeo de columnas:\", column_mapping)\n",
    "    \n",
    "row_to_update = None\n",
    "\n",
    "for row in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=1, max_col=1):\n",
    "    cell = row[0]  # La primera celda de la fila\n",
    "    if cell.value is None:  # Si el valor de la celda está vacía\n",
    "        print(f\"Primera celda vacía en la fila {cell.row}\")\n",
    "        row_to_update = cell.row\n",
    "        break\n",
    "\n",
    "# Si no se encontró ninguna celda vacía, agregar al final\n",
    "if row_to_update is None:\n",
    "    print(\"No se encontro celda vacía, agregando al final\")\n",
    "    row_to_update = ws.max_row + 1  # Agregar en una nueva fila al final\n",
    "\n",
    "print(f\"Fila a actualizar: {row_to_update}\")\n",
    "fila_actualizar = row_to_update  # Fila donde escribir los datos\n",
    "\n",
    "for col_name, value in dicc_medidas.items():\n",
    "    if col_name in column_mapping:  # Asegurarse de que la columna existe\n",
    "        col_idx = column_mapping[col_name]\n",
    "        ws.cell(row=fila_actualizar, column=col_idx, value=value)\n",
    "\n",
    "# Guardar los cambios\n",
    "wb.save(path_excel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
