{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precarga de librerias y funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: shap in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "%run \"../recurrentes.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../funciones.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preseteo optuna especificar bucket y nombre del estudio\n",
    "\n",
    "\n",
    "# nombre_archivo = 'optimization_tree.db'\n",
    "# bucket = 'b2/'\n",
    "\n",
    "\n",
    "# estudio_optuna = base_path + 'buckets/' + bucket + 'optimization_tree.db'\n",
    "\n",
    "\n",
    "# # cargar estudio\n",
    "# # a) competencia_02\n",
    "# # b) competencia_02_lags\n",
    "# # c) competencia_02_lags_y_deltas\n",
    "\n",
    "# nombre_estudio = 'competencia_02_lags'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activar Excel de seguimiento de medidas? \n",
    "\n",
    "excel = True\n",
    "if excel == True:\n",
    "    # Ingresar path excel para anotar resultados\n",
    "    path_excel = base_path_l + r'\\resultados_backtesting.xlsx'\n",
    "    date = datetime.now().strftime(\"%d-%m-%Y %H-%M-%S\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Cargar datos\n",
    "# Opciones:\n",
    "# a) dataset_clase_ternaria_l\n",
    "# b) dataset_lags_clase_ternaria_l\n",
    "# c) dataset_lags_deltas_y_clase_ternaria_l\n",
    "\n",
    "\n",
    "dataset = dataset_lags_clase_ternaria_l\n",
    "dataset_name = os.path.basename(dataset)\n",
    "df_train = pd.read_parquet(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_pci_lags = ['Master_fultimo_cierre_lag_1',\n",
    " 'Visa_fultimo_cierre_lag_1',\n",
    " 'Visa_Finiciomora_lag_2',\n",
    " 'Master_Finiciomora',\n",
    " 'mcomisiones_mantenimiento_lag_2',\n",
    " 'Master_fultimo_cierre',\n",
    " 'Visa_fultimo_cierre_lag_2',\n",
    " 'Visa_Finiciomora_lag_1',\n",
    " 'Master_fultimo_cierre_lag_2',\n",
    " 'Visa_fultimo_cierre',\n",
    " 'mcomisiones_mantenimiento_lag_1',\n",
    " 'mpayroll_lag_2',\n",
    " 'mcomisiones_mantenimiento',\n",
    " 'Master_Fvencimiento_lag_2',\n",
    " 'Master_Fvencimiento_lag_1',\n",
    " 'mcomisiones_otras_lag_2',\n",
    " 'Master_Fvencimiento',\n",
    " 'mcomisiones_otras_lag_1',\n",
    " 'ccomisiones_otras_lag_2',\n",
    " 'mtransferencias_recibidas_lag_2',\n",
    " 'mautoservicio_lag_1',\n",
    " 'mcomisiones',\n",
    " 'mcomisiones_otras',\n",
    " 'mrentabilidad_annual_lag_2',\n",
    " 'mautoservicio_lag_2',\n",
    " 'ctransferencias_recibidas_lag_2',\n",
    " 'mtransferencias_recibidas_lag_1',\n",
    " 'mtarjeta_visa_consumo_lag_2',\n",
    " 'mrentabilidad_lag_2',\n",
    " 'mrentabilidad_annual_lag_1',\n",
    " 'ccomisiones_otras_lag_1',\n",
    " 'mtransferencias_emitidas_lag_2',\n",
    " 'cpayroll_trx_lag_2',\n",
    " 'chomebanking_transacciones_lag_2',\n",
    " 'ctransferencias_emitidas_lag_2',\n",
    " 'mpayroll_lag_1',\n",
    " 'ctransferencias_recibidas_lag_1',\n",
    " 'mextraccion_autoservicio_lag_2',\n",
    " 'mrentabilidad_lag_1',\n",
    " 'mautoservicio',\n",
    " 'mextraccion_autoservicio_lag_1',\n",
    " 'Visa_mpagospesos_lag_1',\n",
    " 'matm_lag_2',\n",
    " 'Visa_mpagominimo_lag_2',\n",
    " 'mtransferencias_recibidas',\n",
    " 'mcaja_ahorro_lag_1',\n",
    " 'mtransferencias_emitidas_lag_1',\n",
    " 'mcuentas_saldo_lag_2',\n",
    " 'Visa_msaldopesos_lag_2',\n",
    " 'mtarjeta_visa_consumo_lag_1',\n",
    " 'mrentabilidad_annual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=lista_pci_lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formateo pre modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'T_Visa_normal' in df_train.columns:\n",
    "    df_train['T_Visa_normal'] = df_train['T_Visa_normal'].astype(bool)\n",
    "if 'T_Master_normal'in df_train.columns:\n",
    "    df_train['T_Master_normal'] = df_train['T_Master_normal'].astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - parametros para modelo\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "mes_train = 202104\n",
    "mes_test = 202106\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4735593, 327)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df_train\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['clase_peso'] = 1.0\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clase_binaria'] = np.where(data['clase_ternaria']=='CONTINUA', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificar mes de train y test\n",
    "\n",
    "df_train = data[data['foto_mes']<=mes_train]\n",
    "df_test = data[data['foto_mes']==mes_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4735593, 329)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4735593 entries, 0 to 4735592\n",
      "Columns: 329 entries, numero_de_cliente to clase_binaria\n",
      "dtypes: bool(2), float64(262), int32(1), int64(63), object(1)\n",
      "memory usage: 11.8 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)  # Número de filas y columnas\n",
    "print(data.info(memory_usage='deep'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_peso = df_train['clase_peso']\n",
    "X_train = df_train.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_train =df_train['clase_binaria']\n",
    "X_test = df_test.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_test =df_test['clase_binaria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x1afe1605a50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_test = df_test.loc[Y_test.index, 'clase_peso']\n",
    "test_data = lgb.Dataset(X_test, label=Y_test, weight=w_test)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train = df_train.loc[X_train.index, 'clase_peso']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar entradas en df_train en base a la columna foto_mes de meses más antiguos a más recientes\n",
    "X_train = X_train.sort_values('foto_mes', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[400009, 500009, 500011, 500021, 600009]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7210, number of negative: 672040\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 679250, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 76290, number of negative: 1282210\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.134004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 1358500, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 294796, number of negative: 1742954\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.683766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2037750, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 299732, number of negative: 2417268\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.247461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2717000, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 597781, number of negative: 2798469\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.291444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 3396250, number of used features: 154\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010615 -> initscore=-4.534834\n",
      "[LightGBM] [Info] Start training from score -4.534834\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.056159 -> initscore=-2.821779\n",
      "[LightGBM] [Info] Start training from score -2.821779\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.144669 -> initscore=-1.777038\n",
      "[LightGBM] [Info] Start training from score -1.777038\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.110319 -> initscore=-2.087490\n",
      "[LightGBM] [Info] Start training from score -2.087490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.176014 -> initscore=-1.543588\n",
      "[LightGBM] [Info] Start training from score -1.543588\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "folds = tscv.split(X_train)\n",
    "\n",
    "lista_cv = []\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',  # Puedes cambiar esto si tu problema es multiclase u otro tipo\n",
    "    'metric': 'binary_logloss',  # Cambia el metric si es necesario\n",
    "    }\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pasar las divisiones a lgb.cv\n",
    "cv_results = lgb.cv(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=300,\n",
    "    feval=lgb_gan_eval,\n",
    "    folds=folds,  # Aquí especificamos las divisiones temporales\n",
    "    seed=s,\n",
    ")\n",
    "\n",
    "cv_results\n",
    "\n",
    "max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "final =  max_gan * 5\n",
    "lista_cv.append(final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7210, number of negative: 672040\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 679250, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 76290, number of negative: 1282210\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.130294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 1358500, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 294796, number of negative: 1742954\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.721174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2037750, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 299732, number of negative: 2417268\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.278071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2717000, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 597781, number of negative: 2798469\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.007719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 3396250, number of used features: 154\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010615 -> initscore=-4.534834\n",
      "[LightGBM] [Info] Start training from score -4.534834\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.056159 -> initscore=-2.821779\n",
      "[LightGBM] [Info] Start training from score -2.821779\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.144669 -> initscore=-1.777038\n",
      "[LightGBM] [Info] Start training from score -1.777038\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.110319 -> initscore=-2.087490\n",
      "[LightGBM] [Info] Start training from score -2.087490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.176014 -> initscore=-1.543588\n",
      "[LightGBM] [Info] Start training from score -1.543588\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "folds = tscv.split(X_train)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',  # Puedes cambiar esto si tu problema es multiclase u otro tipo\n",
    "    'metric': 'binary_logloss',  # Cambia el metric si es necesario\n",
    "    }\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pasar las divisiones a lgb.cv\n",
    "cv_results = lgb.cv(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=300,\n",
    "    feval=lgb_gan_eval,\n",
    "    folds=folds,  # Aquí especificamos las divisiones temporales\n",
    "    seed=semillas[1],\n",
    ")\n",
    "\n",
    "cv_results\n",
    "\n",
    "max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "final_1 =  max_gan * 5\n",
    "lista_cv.append(final_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7210, number of negative: 672040\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 679250, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 76290, number of negative: 1282210\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.129290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 1358500, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 294796, number of negative: 1742954\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.194033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2037750, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 299732, number of negative: 2417268\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.278097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2717000, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 597781, number of negative: 2798469\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.295693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 3396250, number of used features: 154\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010615 -> initscore=-4.534834\n",
      "[LightGBM] [Info] Start training from score -4.534834\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.056159 -> initscore=-2.821779\n",
      "[LightGBM] [Info] Start training from score -2.821779\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.144669 -> initscore=-1.777038\n",
      "[LightGBM] [Info] Start training from score -1.777038\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.110319 -> initscore=-2.087490\n",
      "[LightGBM] [Info] Start training from score -2.087490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.176014 -> initscore=-1.543588\n",
      "[LightGBM] [Info] Start training from score -1.543588\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "folds = tscv.split(X_train)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',  # Puedes cambiar esto si tu problema es multiclase u otro tipo\n",
    "    'metric': 'binary_logloss',  # Cambia el metric si es necesario\n",
    "    }\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pasar las divisiones a lgb.cv\n",
    "cv_results = lgb.cv(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=300,\n",
    "    feval=lgb_gan_eval,\n",
    "    folds=folds,  # Aquí especificamos las divisiones temporales\n",
    "    seed=semillas[2],\n",
    ")\n",
    "\n",
    "cv_results\n",
    "\n",
    "max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "final_2 =  max_gan * 5\n",
    "lista_cv.append(final_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7210, number of negative: 672040\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 679250, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 76290, number of negative: 1282210\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.156746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 1358500, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 294796, number of negative: 1742954\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.214265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2037750, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 299732, number of negative: 2417268\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.242960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2717000, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 597781, number of negative: 2798469\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.334603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 3396250, number of used features: 154\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010615 -> initscore=-4.534834\n",
      "[LightGBM] [Info] Start training from score -4.534834\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.056159 -> initscore=-2.821779\n",
      "[LightGBM] [Info] Start training from score -2.821779\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.144669 -> initscore=-1.777038\n",
      "[LightGBM] [Info] Start training from score -1.777038\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.110319 -> initscore=-2.087490\n",
      "[LightGBM] [Info] Start training from score -2.087490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.176014 -> initscore=-1.543588\n",
      "[LightGBM] [Info] Start training from score -1.543588\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "folds = tscv.split(X_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',  # Puedes cambiar esto si tu problema es multiclase u otro tipo\n",
    "    'metric': 'binary_logloss',  # Cambia el metric si es necesario\n",
    "    }\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pasar las divisiones a lgb.cv\n",
    "cv_results = lgb.cv(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=300,\n",
    "    feval=lgb_gan_eval,\n",
    "    folds=folds,  # Aquí especificamos las divisiones temporales\n",
    "    seed=semillas[3],\n",
    ")\n",
    "\n",
    "cv_results\n",
    "\n",
    "max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "final_3 =  max_gan * 5\n",
    "lista_cv.append(final_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7210, number of negative: 672040\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 679250, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 76290, number of negative: 1282210\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.440371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 1358500, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 294796, number of negative: 1742954\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.191630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2037750, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 299732, number of negative: 2417268\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.282642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 2717000, number of used features: 154\n",
      "[LightGBM] [Info] Number of positive: 597781, number of negative: 2798469\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.115082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22081\n",
      "[LightGBM] [Info] Number of data points in the train set: 3396250, number of used features: 154\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010615 -> initscore=-4.534834\n",
      "[LightGBM] [Info] Start training from score -4.534834\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.056159 -> initscore=-2.821779\n",
      "[LightGBM] [Info] Start training from score -2.821779\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.144669 -> initscore=-1.777038\n",
      "[LightGBM] [Info] Start training from score -1.777038\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.110319 -> initscore=-2.087490\n",
      "[LightGBM] [Info] Start training from score -2.087490\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.176014 -> initscore=-1.543588\n",
      "[LightGBM] [Info] Start training from score -1.543588\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "folds = tscv.split(X_train)\n",
    "\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',  # Puedes cambiar esto si tu problema es multiclase u otro tipo\n",
    "    'metric': 'binary_logloss',  # Cambia el metric si es necesario\n",
    "    }\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pasar las divisiones a lgb.cv\n",
    "cv_results = lgb.cv(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=300,\n",
    "    feval=lgb_gan_eval,\n",
    "    folds=folds,  # Aquí especificamos las divisiones temporales\n",
    "    seed=semillas[4],\n",
    ")\n",
    "\n",
    "cv_results\n",
    "\n",
    "max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "final_4 =  max_gan * 5\n",
    "lista_cv.append(final_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10737406704.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalisimo =  sum(lista_cv)/ len(lista_cv)  \n",
    "finalisimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTADOS:\n",
    "# 1. Modelo Base = 10737406704.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción y scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_medidas = [accuracy_score, precision_score, recall_score, f1_score, roc_auc_score]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label=Y_train, weight=w_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 631992, number of negative: 3443508\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.053861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 47835\n",
      "[LightGBM] [Info] Number of data points in the train set: 4075500, number of used features: 326\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.155073 -> initscore=-1.695354\n",
      "[LightGBM] [Info] Start training from score -1.695354\n"
     ]
    }
   ],
   "source": [
    "#Modelo utilizado para back testing utilizando parametros default si la diferencia en CV es mínima intentar optuna y luego \n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',  \n",
    "    'metric': 'binary_logloss',  \n",
    "    'seed': semillas[0], }\n",
    "model_default = lgb.train(params, train_data)    \n",
    "y_pred_default = model_default.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Medidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc_medidas = {}\n",
    "if excel == True:\n",
    "    dicc_medidas['fecha'] = date\n",
    "    dicc_medidas['dataset'] = dataset_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_labels = (y_pred_default >= 0.025).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fecha': '18-11-2024 20-30-02', 'dataset': 'competencia_02_lags_y_clase_ternaria.parquet', 'accuracy_score': 0.9245190324850191, 'precision_score': 0.09665226781857451, 'recall_score': 0.6305988928032209, 'f1_score': 0.16761420640759814, 'roc_auc_score': 0.7793516537329833}\n"
     ]
    }
   ],
   "source": [
    "for medida in lista_medidas:\n",
    "     dicc_medidas[medida.__name__] = medida(Y_test, y_pred_labels)\n",
    "print(dicc_medidas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganancia = lgb_gan_eval(y_pred_default, test_data)\n",
    "dicc_medidas['ganancia'] = ganancia[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_columnas = df_train.shape[1]\n",
    "mes_train = df_train['foto_mes'].max()\n",
    "mes_test = df_test['foto_mes'].max()\n",
    "# Agregar nota\n",
    "consideraciones = ''\n",
    "\n",
    "dicc_medidas['cantidad_columnas'] = cantidad_columnas\n",
    "dicc_medidas['mes_train'] = mes_train\n",
    "dicc_medidas['mes_test'] = mes_test\n",
    "dicc_medidas['consideraciones'] = consideraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc_medidas = {'accuracy_score': 0.9261808874548145,\n",
    " 'precision_score': np.float64(0.09791535060012634),\n",
    " 'recall_score': np.float64(0.6240563663814797),\n",
    " 'f1_score': np.float64(0.16927172206675312),\n",
    " 'roc_auc_score': np.float64(0.7769613585432806),\n",
    " 'ganancia': np.int64(81116000),\n",
    " 'cantidad_columnas': 510,\n",
    " 'mes_train': np.int64(202104),\n",
    " 'mes_test': np.int64(202106)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapeo de columnas: {'fecha': 1, 'dataset': 2, 'mes_train': 3, 'mes_test': 4, 'consideraciones': 5, 'ganancia': 6, 'accuracy_score': 7, 'precision_score': 8, 'recall_score': 9, 'f1_score': 10, None: 13, 'cantidad_columnas': 12}\n",
      "No se encontro celda vacía, agregando al final\n",
      "Fila a actualizar: 7\n"
     ]
    }
   ],
   "source": [
    "if excel == True:\n",
    "    \n",
    "    wb = load_workbook(path_excel)\n",
    "    ws = wb.active\n",
    "\n",
    "    header_row = 1  \n",
    "    column_mapping = {cell.value: cell.column for cell in ws[header_row]}\n",
    "\n",
    "    # Verificar el mapeo de columnas\n",
    "    print(\"Mapeo de columnas:\", column_mapping)\n",
    "    \n",
    "row_to_update = None\n",
    "\n",
    "for row in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=1, max_col=1):\n",
    "    cell = row[0]  # La primera celda de la fila\n",
    "    if cell.value is None:  # Si el valor de la celda está vacía\n",
    "        print(f\"Primera celda vacía en la fila {cell.row}\")\n",
    "        row_to_update = cell.row\n",
    "        break\n",
    "\n",
    "# Si no se encontró ninguna celda vacía, agregar al final\n",
    "if row_to_update is None:\n",
    "    print(\"No se encontro celda vacía, agregando al final\")\n",
    "    row_to_update = ws.max_row + 1  # Agregar en una nueva fila al final\n",
    "\n",
    "print(f\"Fila a actualizar: {row_to_update}\")\n",
    "fila_actualizar = row_to_update  # Fila donde escribir los datos\n",
    "\n",
    "for col_name, value in dicc_medidas.items():\n",
    "    if col_name in column_mapping:  # Asegurarse de que la columna existe\n",
    "        col_idx = column_mapping[col_name]\n",
    "        ws.cell(row=fila_actualizar, column=col_idx, value=value)\n",
    "\n",
    "# Guardar los cambios\n",
    "wb.save(path_excel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
