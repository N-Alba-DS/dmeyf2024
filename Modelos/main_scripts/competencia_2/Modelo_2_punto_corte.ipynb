{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precarga de librerias y funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imblearn) (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: shap in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.46.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "%run \"../../recurrentes.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imblearn) (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "%run \"../../recurrentes.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Cargar datos\n",
    "# Opciones:\n",
    "# a) dataset_clase_ternaria_l\n",
    "# b) dataset_lags_clase_ternaria_l\n",
    "# c) dataset_lags_deltas_y_clase_ternaria_l\n",
    "# d) dataset_10_meses_l\n",
    "# \n",
    "df_train = pd.read_parquet(dataset_lags_deltas_y_clase_ternaria_l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=dicc_psi['dataset_lags_deltas_y_clase_ternaria'], inplace = True)\n",
    "df_train.drop(columns=dicc_psi['lista_light_gbm_feature_importance'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4735593, 296)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formateo pre modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'T_Visa_normal' in df_train.columns:\n",
    "    df_train['T_Visa_normal'] = df_train['T_Visa_normal'].astype(bool)\n",
    "if 'T_Master_normal'in df_train.columns:\n",
    "    df_train['T_Master_normal'] = df_train['T_Master_normal'].astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - parametros para modelo\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "mes_train = 202106\n",
    "mes_test = 202108\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908,\n",
       "       201909, 201910, 201911, 201912, 202001, 202002, 202003, 202004,\n",
       "       202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
       "       202101, 202102, 202103, 202104, 202105, 202106], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data['clase_peso'] = 1.0\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "data['clase_binaria'] = np.where(data['clase_ternaria']=='CONTINUA', 0, 1)\n",
    "data['foto_mes'].unique()\n",
    "meses = [202011, 202012, 202101, 202102, 202103, 202104,202105,202106]\n",
    "\n",
    "\n",
    "df_train = data[data['foto_mes']<=mes_train]\n",
    "df_test = data[data['foto_mes']==mes_test]\n",
    "clase_peso = df_train['clase_peso']\n",
    "X_train = df_train.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_train =df_train['clase_binaria']\n",
    "X_test = df_test.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_test =df_test['clase_binaria']\n",
    "w_train = df_train['clase_peso']\n",
    "w_test = df_test['clase_peso']\n",
    "df_train['foto_mes'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'num_leaves': 1796,\n",
    " 'learning_rate': 0.049283676079631966,\n",
    " 'min_data_in_leaf': 9,\n",
    " 'feature_fraction': 0.44425115760554584,\n",
    " 'bagging_fraction': 0.40692971865213867}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = {'num_leaves': 3545,\n",
    "#  'learning_rate': 0.07959540527561224,\n",
    "#  'min_data_in_leaf': 933,\n",
    "#  'feature_fraction': 0.6829932939284065,\n",
    "#  'bagging_fraction': 0.6251908881121132}\n",
    "# best_iter = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeros_random = np.random.randint(0, 100000, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.68 GiB for an array with shape (4404999, 295) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 26\u001b[0m\n\u001b[0;32m      8\u001b[0m df_modelos \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\n\u001b[0;32m      9\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboosting_type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgbdt\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     23\u001b[0m }\n\u001b[1;32m---> 26\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(params,\n\u001b[0;32m     27\u001b[0m                 train_data,\n\u001b[0;32m     28\u001b[0m                 num_boost_round\u001b[38;5;241m=\u001b[39mbest_iter)\n\u001b[0;32m     30\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\engine.py:282\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 282\u001b[0m     booster \u001b[38;5;241m=\u001b[39m Booster(params\u001b[38;5;241m=\u001b[39mparams, train_set\u001b[38;5;241m=\u001b[39mtrain_set)\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    284\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32m~\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:3627\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[0;32m   3620\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[0;32m   3621\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[0;32m   3622\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   3623\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[0;32m   3624\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   3625\u001b[0m     )\n\u001b[0;32m   3626\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 3627\u001b[0m train_set\u001b[38;5;241m.\u001b[39mconstruct()\n\u001b[0;32m   3628\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   3629\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n",
      "File \u001b[1;32m~\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:2566\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2561\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\n\u001b[0;32m   2562\u001b[0m                 predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, used_indices\u001b[38;5;241m=\u001b[39mused_indices\n\u001b[0;32m   2563\u001b[0m             )\n\u001b[0;32m   2564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2565\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[1;32m-> 2566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(\n\u001b[0;32m   2567\u001b[0m         data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m   2568\u001b[0m         label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel,\n\u001b[0;32m   2569\u001b[0m         reference\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2570\u001b[0m         weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m   2571\u001b[0m         group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup,\n\u001b[0;32m   2572\u001b[0m         init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_score,\n\u001b[0;32m   2573\u001b[0m         predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor,\n\u001b[0;32m   2574\u001b[0m         feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_name,\n\u001b[0;32m   2575\u001b[0m         categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_feature,\n\u001b[0;32m   2576\u001b[0m         params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams,\n\u001b[0;32m   2577\u001b[0m         position\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition,\n\u001b[0;32m   2578\u001b[0m     )\n\u001b[0;32m   2579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[0;32m   2580\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:2158\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[0;32m   2156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__init_from_csc(data, params_str, ref_dataset)\n\u001b[0;32m   2157\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m-> 2158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__init_from_np2d(data, params_str, ref_dataset)\n\u001b[0;32m   2159\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_pyarrow_table(data):\n\u001b[0;32m   2160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__init_from_pyarrow_table(data, params_str, ref_dataset)\n",
      "File \u001b[1;32m~\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:2288\u001b[0m, in \u001b[0;36mDataset.__init_from_np2d\u001b[1;34m(self, mat, params_str, ref_dataset)\u001b[0m\n\u001b[0;32m   2286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_void_p()\n\u001b[0;32m   2287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mat\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32 \u001b[38;5;129;01mor\u001b[39;00m mat\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64:\n\u001b[1;32m-> 2288\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(mat\u001b[38;5;241m.\u001b[39mreshape(mat\u001b[38;5;241m.\u001b[39msize), dtype\u001b[38;5;241m=\u001b[39mmat\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# change non-float data to float data, need to copy\u001b[39;00m\n\u001b[0;32m   2290\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(mat\u001b[38;5;241m.\u001b[39mreshape(mat\u001b[38;5;241m.\u001b[39msize), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 9.68 GiB for an array with shape (4404999, 295) and data type float64"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_data = lgb.Dataset(X_train,\n",
    "                            label=Y_train,\n",
    "                            weight=w_train)\n",
    "\n",
    "\n",
    "\n",
    "best_iter = 1789\n",
    "df_modelos = pd.DataFrame\n",
    "params = {\n",
    "'objective': 'binary',\n",
    "'boosting_type': 'gbdt',\n",
    "'first_metric_only': True,\n",
    "'boost_from_average': True,\n",
    "'feature_pre_filter': False,\n",
    "'max_bin': 31,\n",
    "'num_leaves': best_params['num_leaves'],\n",
    "'learning_rate': best_params['learning_rate'],\n",
    "'min_data_in_leaf': best_params['min_data_in_leaf'],\n",
    "'feature_fraction': best_params['feature_fraction'],\n",
    "'bagging_fraction': best_params['bagging_fraction'],\n",
    "'seed': semillas[0],\n",
    "'verbose': 0\n",
    "}\n",
    "        \n",
    "        \n",
    "model = lgb.train(params,\n",
    "                train_data,\n",
    "                num_boost_round=best_iter)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de clientes 14100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test['Probabilidad'] = y_pred\n",
    "\n",
    "tb_entrega = X_test.sort_values(by='Probabilidad', ascending=False)\n",
    "\n",
    "tb_entrega['Predicted'] = 0\n",
    "\n",
    "envios = 12300\n",
    "tb_entrega.iloc[:envios, tb_entrega.columns.get_loc('Predicted')] = 1\n",
    "\n",
    "resultados = tb_entrega[[\"numero_de_cliente\", 'Predicted']].reset_index(drop=True)\n",
    "\n",
    "print(\"Cantidad de clientes {}\".format(envios))\n",
    "num_subida_kaggle = 27\n",
    "nombre_archivo = '\\entrega_0{}.csv'.format(num_subida_kaggle)\n",
    "entrega_final = f'{save_path}{nombre_archivo}'\n",
    "resultados.to_csv(entrega_final, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bajas = pd.DataFrame({'numero_de_cliente': X_test['numero_de_cliente'], 'clase_ternaria': df_test['clase_ternaria']}, index= X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numero_de_cliente    0\n",
       "Probabilidad         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediccion.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto de corte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data = prediccion.merge(bajas, on='numero_de_cliente', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data_sorted = merged_data.sort_values('Probabilidad', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clase_ternaria\n",
       "BAJA+1    15000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# # Ordenar por probabilidad de mayor a menor\n",
    "\n",
    "# # Seleccionar top clientes\n",
    "# top_clients = merged_data_sorted.iloc[:15000].copy()  # Trabajar con una copia\n",
    "\n",
    "# # Convertir 'clase_ternaria' a variable binaria para los top clientes\n",
    "# top_clients.loc[:, 'bajas_reales'] = (top_clients['clase_ternaria'] == 'BAJA+2').astype(int)\n",
    "\n",
    "# top_clients.value_counts('clase_ternaria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculoGanancia(bajas,prediccion,corte):\n",
    "#     ''' \n",
    "#     Calcula la ganancia para una semilla específica.\n",
    "    \n",
    "#     Parámetros:\n",
    "#     bajas: DataFrame con columnas \"numero_de_cliente\" y \"clase_ternaria\".\n",
    "#     prediccion: DataFrame con columnas \"numero_de_cliente\" y \"Probabilidad\".\n",
    "#     corte: int, cantidad de estímulos.\n",
    "#     random_state: int, semilla para train_test_split.\n",
    "    \n",
    "#     Retorna:\n",
    "#     ganancia_publico: Ganancia para el público.\n",
    "#     ganancia_privado: Ganancia para el privado.\n",
    "#     '''\n",
    "#     # Realizar el split en público y privado\n",
    "#     Publico, Privado = train_test_split(\n",
    "#         bajas,\n",
    "#         test_size=0.7,\n",
    "#         stratify=bajas['clase_ternaria'],\n",
    "#         random_state=123\n",
    "#     )\n",
    "\n",
    "#     # Clientes que decido estimular\n",
    "#     estimulos = prediccion.iloc[:corte] \n",
    "\n",
    "#     # Obtener los estímulos en el conjunto público y privado\n",
    "#     estimulos_publico = pd.merge(estimulos, Publico, on='numero_de_cliente', how='inner')\n",
    "#     estimulos_privado = pd.merge(estimulos, Privado, on='numero_de_cliente', how='inner')\n",
    "\n",
    "#     # Calcular los verdaderos positivos en cada conjunto\n",
    "#     TP_publico = estimulos_publico[estimulos_publico['clase_ternaria'] == 'BAJA+2']\n",
    "#     TP_privado = estimulos_privado[estimulos_privado['clase_ternaria'] == 'BAJA+2']\n",
    "\n",
    "#     # 5. Calcular la ganancia para cada conjunto con normalización\n",
    "#     # Primero, calculamos la ganancia en cada conjunto\n",
    "#     ganancia_publico_sin_norm = (len(TP_publico) * 273000) - ((len(estimulos_publico) - len(TP_publico)) * 7000)\n",
    "#     ganancia_privado_sin_norm = (len(TP_privado) * 273000) - ((len(estimulos_privado) - len(TP_privado)) * 7000)\n",
    "\n",
    "#     # Luego, normalizamos dividiendo por el porcentaje correspondiente\n",
    "#     ganancia_publico = ganancia_publico_sin_norm / 0.3\n",
    "#     ganancia_privado = ganancia_privado_sin_norm / 0.7\n",
    "\n",
    "#     return ganancia_publico, ganancia_privado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 1.75 segundos\n"
     ]
    }
   ],
   "source": [
    "# inicio = time.time()\n",
    "\n",
    "# resultados = []\n",
    "# cortes = range(5000, 20000, 1000)\n",
    "\n",
    "\n",
    "# pred_model_sorted = prediccion.sort_values('Probabilidad', ascending=False)\n",
    "# model_name = 'LightGBM'\n",
    "\n",
    "# # Iteramos sobre cada corte\n",
    "# for corte in cortes:\n",
    "#     ganancia_publico, ganancia_privado = calculoGanancia(bajas, pred_model_sorted, corte)\n",
    "    \n",
    "#     # Almacenamos los resultados\n",
    "#     resultados.append({\n",
    "#         'Modelo': model_name,\n",
    "#         'Corte': corte,\n",
    "#         'Ganancia Público': ganancia_publico,\n",
    "#         'Ganancia Privado': ganancia_privado\n",
    "#     })\n",
    "\n",
    "# # Convertimos los resultados en un DataFrame\n",
    "# resultados = pd.DataFrame(resultados)\n",
    "\n",
    "# fin = time.time()\n",
    "# tiempo_ejecucion = fin - inicio\n",
    "\n",
    "# print(f\"Tiempo de ejecución: {tiempo_ejecucion:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corte</th>\n",
       "      <th>Ganancia Público_LightGBM</th>\n",
       "      <th>Ganancia Privado_LightGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>-3.511667e+07</td>\n",
       "      <td>-34950000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6000</td>\n",
       "      <td>-4.160333e+07</td>\n",
       "      <td>-42170000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000</td>\n",
       "      <td>-4.900000e+07</td>\n",
       "      <td>-49000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8000</td>\n",
       "      <td>-5.569667e+07</td>\n",
       "      <td>-56130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000</td>\n",
       "      <td>-6.295333e+07</td>\n",
       "      <td>-63020000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000</td>\n",
       "      <td>-6.965000e+07</td>\n",
       "      <td>-70150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11000</td>\n",
       "      <td>-7.665000e+07</td>\n",
       "      <td>-77150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12000</td>\n",
       "      <td>-8.339333e+07</td>\n",
       "      <td>-84260000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13000</td>\n",
       "      <td>-9.074333e+07</td>\n",
       "      <td>-91110000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14000</td>\n",
       "      <td>-9.783667e+07</td>\n",
       "      <td>-98070000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15000</td>\n",
       "      <td>-1.052100e+08</td>\n",
       "      <td>-104910000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16000</td>\n",
       "      <td>-1.119067e+08</td>\n",
       "      <td>-112040000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17000</td>\n",
       "      <td>-1.187433e+08</td>\n",
       "      <td>-119110000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18000</td>\n",
       "      <td>-1.264200e+08</td>\n",
       "      <td>-125820000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19000</td>\n",
       "      <td>-1.333733e+08</td>\n",
       "      <td>-132840000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Corte  Ganancia Público_LightGBM  Ganancia Privado_LightGBM\n",
       "0    5000              -3.511667e+07                -34950000.0\n",
       "1    6000              -4.160333e+07                -42170000.0\n",
       "2    7000              -4.900000e+07                -49000000.0\n",
       "3    8000              -5.569667e+07                -56130000.0\n",
       "4    9000              -6.295333e+07                -63020000.0\n",
       "5   10000              -6.965000e+07                -70150000.0\n",
       "6   11000              -7.665000e+07                -77150000.0\n",
       "7   12000              -8.339333e+07                -84260000.0\n",
       "8   13000              -9.074333e+07                -91110000.0\n",
       "9   14000              -9.783667e+07                -98070000.0\n",
       "10  15000              -1.052100e+08               -104910000.0\n",
       "11  16000              -1.119067e+08               -112040000.0\n",
       "12  17000              -1.187433e+08               -119110000.0\n",
       "13  18000              -1.264200e+08               -125820000.0\n",
       "14  19000              -1.333733e+08               -132840000.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Pivotamos el DataFrame 'resultados' para reorganizar las ganancias\n",
    "# resultados_pivot = resultados.pivot_table(\n",
    "#     index='Corte',\n",
    "#     columns='Modelo',\n",
    "#     values=['Ganancia Público', 'Ganancia Privado']\n",
    "# )\n",
    "\n",
    "# # Aplanamos las columnas para facilitar el acceso\n",
    "# resultados_pivot.columns = [f'{ganancia}_{modelo}' for ganancia, modelo in resultados_pivot.columns]\n",
    "\n",
    "# # Reordenamos las columnas alternando 'Público' y 'Privado' para cada modelo\n",
    "# # Ordenamos primero por el modelo, luego alternando entre 'Público' y 'Privado'\n",
    "# columnas_ordenadas = []\n",
    "# for modelo in resultados['Modelo'].unique():\n",
    "#     columnas_ordenadas.append(f'Ganancia Público_{modelo}')\n",
    "#     columnas_ordenadas.append(f'Ganancia Privado_{modelo}')\n",
    "\n",
    "# # Reorganizamos el DataFrame usando el nuevo orden de columnas\n",
    "# resultados_pivot = resultados_pivot[columnas_ordenadas]\n",
    "\n",
    "# # Convertimos el índice 'Corte' en una columna si prefieres tenerla como tal\n",
    "# resultados_pivot = resultados_pivot.reset_index()\n",
    "# resultados_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
