{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precarga de librerias y funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imblearn) (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "%run \"../../recurrentes.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: imblearn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imblearn) (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\.conda\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas-2.2.2.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "%run \"../../recurrentes.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Cargar datos\n",
    "# Opciones:\n",
    "# a) dataset_clase_ternaria_l\n",
    "# b) dataset_lags_clase_ternaria_l\n",
    "# c) dataset_lags_deltas_y_clase_ternaria_l\n",
    "# d) dataset_10_meses_l\n",
    "\n",
    "dataset = dataset_lags_deltas_y_clase_ternaria_l\n",
    "dataset_name = os.path.basename(dataset)\n",
    "df_train = pd.read_parquet(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=dicc_psi['dataset_lags_deltas_y_clase_ternaria'])\n",
    "df_train = df_train.drop(columns=dicc_psi['lista_light_gbm_feature_importance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formateo pre modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'T_Visa_normal' in df_train.columns:\n",
    "    df_train['T_Visa_normal'] = df_train['T_Visa_normal'].astype(bool)\n",
    "if 'T_Master_normal'in df_train.columns:\n",
    "    df_train['T_Master_normal'] = df_train['T_Master_normal'].astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - parametros para modelo\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "mes_train = 202104\n",
    "mes_test = 202106\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['clase_peso'] = 1.0\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clase_peso'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clase_binaria'] = np.where(data['clase_ternaria']=='CONTINUA', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908,\n",
       "       201909, 201910, 201911, 201912, 202001, 202002, 202003, 202004,\n",
       "       202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
       "       202101, 202102, 202103, 202104, 202105, 202106, 202107, 202108],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['foto_mes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificar mes de train y test\n",
    "meses = [202011, 202012, 202101, 202102, 202103, 202104]\n",
    "\n",
    "\n",
    "df_train = data[data['foto_mes']<=mes_train]\n",
    "df_test = data[data['foto_mes']==mes_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_peso = df_train['clase_peso']\n",
    "X_train = df_train.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_train =df_train['clase_binaria']\n",
    "X_test = df_test.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_test =df_test['clase_binaria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train = df_train['clase_peso']\n",
    "w_test = df_test['clase_peso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([201901, 201902, 201903, 201904, 201905, 201906, 201907, 201908,\n",
       "       201909, 201910, 201911, 201912, 202001, 202002, 202003, 202004,\n",
       "       202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012,\n",
       "       202101, 202102, 202103, 202104], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['foto_mes'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'num_leaves': 3545,\n",
    " 'learning_rate': 0.07959540527561224,\n",
    " 'min_data_in_leaf': 933,\n",
    " 'feature_fraction': 0.6829932939284065,\n",
    " 'bagging_fraction': 0.6251908881121132}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'num_leaves': 1796,\n",
    " 'learning_rate': 0.049283676079631966,\n",
    " 'min_data_in_leaf': 9,\n",
    " 'feature_fraction': 0.44425115760554584,\n",
    " 'bagging_fraction': 0.40692971865213867}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeros_random = np.random.randint(0, 100000, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 8.96 GiB for an array with shape (295, 4075500) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 30\u001b[0m\n\u001b[0;32m     12\u001b[0m df_modelos \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\n\u001b[0;32m     13\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboosting_type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgbdt\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     27\u001b[0m }\n\u001b[1;32m---> 30\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(params,\n\u001b[0;32m     31\u001b[0m                 train_data,\n\u001b[0;32m     32\u001b[0m                 num_boost_round\u001b[38;5;241m=\u001b[39mbest_iter)\n\u001b[0;32m     34\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     36\u001b[0m df_voting[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msemilla\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_pred\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\engine.py:282\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 282\u001b[0m     booster \u001b[38;5;241m=\u001b[39m Booster(params\u001b[38;5;241m=\u001b[39mparams, train_set\u001b[38;5;241m=\u001b[39mtrain_set)\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    284\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:3627\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[0;32m   3620\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[0;32m   3621\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[0;32m   3622\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   3623\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[0;32m   3624\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   3625\u001b[0m     )\n\u001b[0;32m   3626\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 3627\u001b[0m train_set\u001b[38;5;241m.\u001b[39mconstruct()\n\u001b[0;32m   3628\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   3629\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:2566\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2561\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\n\u001b[0;32m   2562\u001b[0m                 predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, used_indices\u001b[38;5;241m=\u001b[39mused_indices\n\u001b[0;32m   2563\u001b[0m             )\n\u001b[0;32m   2564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2565\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[1;32m-> 2566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_init(\n\u001b[0;32m   2567\u001b[0m         data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m   2568\u001b[0m         label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel,\n\u001b[0;32m   2569\u001b[0m         reference\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2570\u001b[0m         weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m   2571\u001b[0m         group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup,\n\u001b[0;32m   2572\u001b[0m         init_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_score,\n\u001b[0;32m   2573\u001b[0m         predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor,\n\u001b[0;32m   2574\u001b[0m         feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_name,\n\u001b[0;32m   2575\u001b[0m         categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_feature,\n\u001b[0;32m   2576\u001b[0m         params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams,\n\u001b[0;32m   2577\u001b[0m         position\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition,\n\u001b[0;32m   2578\u001b[0m     )\n\u001b[0;32m   2579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[0;32m   2580\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:2096\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[0;32m   2094\u001b[0m     categorical_feature \u001b[38;5;241m=\u001b[39m reference\u001b[38;5;241m.\u001b[39mcategorical_feature\n\u001b[0;32m   2095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd_DataFrame):\n\u001b[1;32m-> 2096\u001b[0m     data, feature_name, categorical_feature, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical \u001b[38;5;241m=\u001b[39m _data_from_pandas(\n\u001b[0;32m   2097\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   2098\u001b[0m         feature_name\u001b[38;5;241m=\u001b[39mfeature_name,\n\u001b[0;32m   2099\u001b[0m         categorical_feature\u001b[38;5;241m=\u001b[39mcategorical_feature,\n\u001b[0;32m   2100\u001b[0m         pandas_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical,\n\u001b[0;32m   2101\u001b[0m     )\n\u001b[0;32m   2103\u001b[0m \u001b[38;5;66;03m# process for args\u001b[39;00m\n\u001b[0;32m   2104\u001b[0m params \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m params\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:846\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    842\u001b[0m df_dtypes\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    843\u001b[0m target_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdf_dtypes)\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 846\u001b[0m     _pandas_to_numpy(data, target_dtype\u001b[38;5;241m=\u001b[39mtarget_dtype),\n\u001b[0;32m    847\u001b[0m     feature_name,\n\u001b[0;32m    848\u001b[0m     categorical_feature,\n\u001b[0;32m    849\u001b[0m     pandas_categorical,\n\u001b[0;32m    850\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:795\u001b[0m, in \u001b[0;36m_pandas_to_numpy\u001b[1;34m(data, target_dtype)\u001b[0m\n\u001b[0;32m    792\u001b[0m _check_for_bad_pandas_dtypes(data\u001b[38;5;241m.\u001b[39mdtypes)\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m     \u001b[38;5;66;03m# most common case (no nullable dtypes)\u001b[39;00m\n\u001b[1;32m--> 795\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39mtarget_dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;66;03m# 1.0 <= pd version < 1.1 and nullable dtypes, least common case\u001b[39;00m\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;66;03m# raises error because array is casted to type(pd.NA) and there's no na_value argument\u001b[39;00m\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mastype(target_dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas\\core\\frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mas_array(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, na_value\u001b[38;5;241m=\u001b[39mna_value)\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interleave(dtype\u001b[38;5;241m=\u001b[39mdtype, na_value\u001b[38;5;241m=\u001b[39mna_value)\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1727\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1724\u001b[0m \u001b[38;5;66;03m# error: Argument 1 to \"ensure_np_dtype\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1725\u001b[0m \u001b[38;5;66;03m# \"Optional[dtype[Any]]\"; expected \"Union[dtype[Any], ExtensionDtype]\"\u001b[39;00m\n\u001b[0;32m   1726\u001b[0m dtype \u001b[38;5;241m=\u001b[39m ensure_np_dtype(dtype)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m-> 1727\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1729\u001b[0m itemmask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1732\u001b[0m     \u001b[38;5;66;03m# much more performant than using to_numpy below\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.96 GiB for an array with shape (295, 4075500) and data type float64"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_data = lgb.Dataset(X_train,\n",
    "                            label=Y_train,\n",
    "                            weight=w_train)\n",
    "\n",
    "\n",
    "\n",
    "df_voting = pd.DataFrame()\n",
    "\n",
    "for semilla in numeros_random: \n",
    "        \n",
    "    best_iter = 1789\n",
    "    df_modelos = pd.DataFrame\n",
    "    params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': best_params['num_leaves'],\n",
    "    'learning_rate': best_params['learning_rate'],\n",
    "    'min_data_in_leaf': best_params['min_data_in_leaf'],\n",
    "    'feature_fraction': best_params['feature_fraction'],\n",
    "    'bagging_fraction': best_params['bagging_fraction'],\n",
    "    'seed': semilla,\n",
    "    'verbose': 0\n",
    "    }\n",
    "        \n",
    "        \n",
    "    model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=best_iter)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    df_voting[f'pred_{semilla}'] = y_pred\n",
    "    \n",
    "df_voting['pred_mean'] = df_voting.mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = df_voting['pred_mean']\n",
    "y_pred.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164876, 295)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164876, 298)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([      7,      17,      27,      37,      47,      57,      67,      77,\n",
      "            87,      97,\n",
      "       ...\n",
      "       1634709, 1634719, 1634729, 1634739, 1634749, 1634759, 1634769, 1634785,\n",
      "       1634795, 1634805],\n",
      "      dtype='int64', length=164876)\n",
      "Index([      7,      17,      27,      37,      47,      57,      67,      77,\n",
      "            87,      97,\n",
      "       ...\n",
      "       1634709, 1634719, 1634729, 1634739, 1634749, 1634759, 1634769, 1634785,\n",
      "       1634795, 1634805],\n",
      "      dtype='int64', length=164876)\n",
      "RangeIndex(start=0, stop=164876, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.index)\n",
    "print(df_test.index)\n",
    "print(df_voting.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voting.index = X_test.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = pd.DataFrame({'numero_de_cliente': X_test['numero_de_cliente'], 'Probabilidad': df_voting['pred_mean']}, index= df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = prediccion['Probabilidad']\n",
    "\n",
    "predicciones = y_pred\n",
    "\n",
    "X_test['Probabilidad'] = predicciones\n",
    "\n",
    "tb_entrega = X_test.sort_values(by='Probabilidad', ascending=False)\n",
    "\n",
    "tb_entrega['Predicted'] = 0\n",
    "\n",
    "envios = 9730\n",
    "tb_entrega.iloc[:envios, tb_entrega.columns.get_loc('Predicted')] = 1\n",
    "\n",
    "resultados = tb_entrega[[\"numero_de_cliente\", 'Predicted']].reset_index(drop=True)\n",
    "\n",
    "print(\"Cantidad de clientes {}\".format(envios))\n",
    "num_subida_kaggle = 18\n",
    "nombre_archivo = '\\entrega_0{}.csv'.format(num_subida_kaggle)\n",
    "entrega_final = f'{save_path}{nombre_archivo}'\n",
    "resultados.to_csv(entrega_final, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bajas = pd.DataFrame({'numero_de_cliente': X_test['numero_de_cliente'], 'clase_ternaria': df_test['clase_ternaria']}, index= X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numero_de_cliente    0\n",
       "Probabilidad         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto de corte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = prediccion.merge(bajas, on='numero_de_cliente', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_sorted = merged_data.sort_values('Probabilidad', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clase_ternaria\n",
       "CONTINUA    11287\n",
       "BAJA+1        377\n",
       "BAJA+2        336\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Ordenar por probabilidad de mayor a menor\n",
    "\n",
    "# Seleccionar top clientes\n",
    "top_clients = merged_data_sorted.iloc[:12000].copy()  # Trabajar con una copia\n",
    "\n",
    "# Convertir 'clase_ternaria' a variable binaria para los top clientes\n",
    "top_clients.loc[:, 'bajas_reales'] = (top_clients['clase_ternaria'] == 'BAJA+2').astype(int)\n",
    "\n",
    "top_clients.value_counts('clase_ternaria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculoGanancia(bajas,prediccion,corte):\n",
    "    ''' \n",
    "    Calcula la ganancia para una semilla específica.\n",
    "    \n",
    "    Parámetros:\n",
    "    bajas: DataFrame con columnas \"numero_de_cliente\" y \"clase_ternaria\".\n",
    "    prediccion: DataFrame con columnas \"numero_de_cliente\" y \"Probabilidad\".\n",
    "    corte: int, cantidad de estímulos.\n",
    "    random_state: int, semilla para train_test_split.\n",
    "    \n",
    "    Retorna:\n",
    "    ganancia_publico: Ganancia para el público.\n",
    "    ganancia_privado: Ganancia para el privado.\n",
    "    '''\n",
    "    # Realizar el split en público y privado\n",
    "    Publico, Privado = train_test_split(\n",
    "        bajas,\n",
    "        test_size=0.7,\n",
    "        stratify=bajas['clase_ternaria'],\n",
    "        random_state=123\n",
    "    )\n",
    "\n",
    "    # Clientes que decido estimular\n",
    "    estimulos = prediccion.iloc[:corte] \n",
    "\n",
    "    # Obtener los estímulos en el conjunto público y privado\n",
    "    estimulos_publico = pd.merge(estimulos, Publico, on='numero_de_cliente', how='inner')\n",
    "    estimulos_privado = pd.merge(estimulos, Privado, on='numero_de_cliente', how='inner')\n",
    "\n",
    "    # Calcular los verdaderos positivos en cada conjunto\n",
    "    TP_publico = estimulos_publico[estimulos_publico['clase_ternaria'] == 'BAJA+2']\n",
    "    TP_privado = estimulos_privado[estimulos_privado['clase_ternaria'] == 'BAJA+2']\n",
    "\n",
    "    # 5. Calcular la ganancia para cada conjunto con normalización\n",
    "    # Primero, calculamos la ganancia en cada conjunto\n",
    "    ganancia_publico_sin_norm = (len(TP_publico) * 273000) - ((len(estimulos_publico) - len(TP_publico)) * 7000)\n",
    "    ganancia_privado_sin_norm = (len(TP_privado) * 273000) - ((len(estimulos_privado) - len(TP_privado)) * 7000)\n",
    "\n",
    "    # Luego, normalizamos dividiendo por el porcentaje correspondiente\n",
    "    ganancia_publico = ganancia_publico_sin_norm / 0.3\n",
    "    ganancia_privado = ganancia_privado_sin_norm / 0.7\n",
    "\n",
    "    return ganancia_publico, ganancia_privado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 1.81 segundos\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "\n",
    "resultados = []\n",
    "cortes = range(5000, 20000, 1000)\n",
    "\n",
    "\n",
    "pred_model_sorted = prediccion.sort_values('Probabilidad', ascending=False)\n",
    "model_name = 'LightGBM'\n",
    "\n",
    "# Iteramos sobre cada corte\n",
    "for corte in cortes:\n",
    "    ganancia_publico, ganancia_privado = calculoGanancia(bajas, pred_model_sorted, corte)\n",
    "    \n",
    "    # Almacenamos los resultados\n",
    "    resultados.append({\n",
    "        'Modelo': model_name,\n",
    "        'Corte': corte,\n",
    "        'Ganancia Público': ganancia_publico,\n",
    "        'Ganancia Privado': ganancia_privado\n",
    "    })\n",
    "\n",
    "# Convertimos los resultados en un DataFrame\n",
    "resultados = pd.DataFrame(resultados)\n",
    "\n",
    "fin = time.time()\n",
    "tiempo_ejecucion = fin - inicio\n",
    "\n",
    "print(f\"Tiempo de ejecución: {tiempo_ejecucion:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corte</th>\n",
       "      <th>Ganancia Público_LightGBM</th>\n",
       "      <th>Ganancia Privado_LightGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>3.208333e+07</td>\n",
       "      <td>25450000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6000</td>\n",
       "      <td>3.108000e+07</td>\n",
       "      <td>27080000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000</td>\n",
       "      <td>2.800000e+07</td>\n",
       "      <td>26800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8000</td>\n",
       "      <td>2.613333e+07</td>\n",
       "      <td>24800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000</td>\n",
       "      <td>2.069667e+07</td>\n",
       "      <td>21530000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000</td>\n",
       "      <td>1.757000e+07</td>\n",
       "      <td>17270000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11000</td>\n",
       "      <td>1.498000e+07</td>\n",
       "      <td>13180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12000</td>\n",
       "      <td>1.145667e+07</td>\n",
       "      <td>9490000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13000</td>\n",
       "      <td>5.670000e+06</td>\n",
       "      <td>6370000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14000</td>\n",
       "      <td>2.823333e+06</td>\n",
       "      <td>3590000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15000</td>\n",
       "      <td>-8.866667e+05</td>\n",
       "      <td>1980000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16000</td>\n",
       "      <td>-6.440000e+06</td>\n",
       "      <td>-40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17000</td>\n",
       "      <td>-1.117667e+07</td>\n",
       "      <td>-3610000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18000</td>\n",
       "      <td>-1.234333e+07</td>\n",
       "      <td>-7910000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19000</td>\n",
       "      <td>-1.626333e+07</td>\n",
       "      <td>-12230000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Corte  Ganancia Público_LightGBM  Ganancia Privado_LightGBM\n",
       "0    5000               3.208333e+07                 25450000.0\n",
       "1    6000               3.108000e+07                 27080000.0\n",
       "2    7000               2.800000e+07                 26800000.0\n",
       "3    8000               2.613333e+07                 24800000.0\n",
       "4    9000               2.069667e+07                 21530000.0\n",
       "5   10000               1.757000e+07                 17270000.0\n",
       "6   11000               1.498000e+07                 13180000.0\n",
       "7   12000               1.145667e+07                  9490000.0\n",
       "8   13000               5.670000e+06                  6370000.0\n",
       "9   14000               2.823333e+06                  3590000.0\n",
       "10  15000              -8.866667e+05                  1980000.0\n",
       "11  16000              -6.440000e+06                   -40000.0\n",
       "12  17000              -1.117667e+07                 -3610000.0\n",
       "13  18000              -1.234333e+07                 -7910000.0\n",
       "14  19000              -1.626333e+07                -12230000.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivotamos el DataFrame 'resultados' para reorganizar las ganancias\n",
    "resultados_pivot = resultados.pivot_table(\n",
    "    index='Corte',\n",
    "    columns='Modelo',\n",
    "    values=['Ganancia Público', 'Ganancia Privado']\n",
    ")\n",
    "\n",
    "# Aplanamos las columnas para facilitar el acceso\n",
    "resultados_pivot.columns = [f'{ganancia}_{modelo}' for ganancia, modelo in resultados_pivot.columns]\n",
    "\n",
    "# Reordenamos las columnas alternando 'Público' y 'Privado' para cada modelo\n",
    "# Ordenamos primero por el modelo, luego alternando entre 'Público' y 'Privado'\n",
    "columnas_ordenadas = []\n",
    "for modelo in resultados['Modelo'].unique():\n",
    "    columnas_ordenadas.append(f'Ganancia Público_{modelo}')\n",
    "    columnas_ordenadas.append(f'Ganancia Privado_{modelo}')\n",
    "\n",
    "# Reorganizamos el DataFrame usando el nuevo orden de columnas\n",
    "resultados_pivot = resultados_pivot[columnas_ordenadas]\n",
    "\n",
    "# Convertimos el índice 'Corte' en una columna si prefieres tenerla como tal\n",
    "resultados_pivot = resultados_pivot.reset_index()\n",
    "resultados_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
