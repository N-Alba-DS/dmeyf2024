{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precarga de librerias y funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../recurrentes.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../funciones.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "#configuración de la base de datos\n",
    "\n",
    "%load_ext sql\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "%sql duckdb:///:memory:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/n_alba_dscience/buckets/b1/datasets/competencia_02_f_e_lags.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mread_parquet(dataset)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas\\io\\parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    668\u001b[0m     path,\n\u001b[0;32m    669\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    670\u001b[0m     filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    671\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    672\u001b[0m     use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    673\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    674\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    676\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas\\io\\parquet.py:267\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    265\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    268\u001b[0m     path,\n\u001b[0;32m    269\u001b[0m     filesystem,\n\u001b[0;32m    270\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    271\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    272\u001b[0m )\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    275\u001b[0m         path_or_handle,\n\u001b[0;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    280\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas\\io\\parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m    141\u001b[0m         path_or_handle, mode, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[0;32m    142\u001b[0m     )\n\u001b[0;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/n_alba_dscience/buckets/b1/datasets/competencia_02_f_e_lags.parquet'"
     ]
    }
   ],
   "source": [
    "# 2 - Cargar datos\n",
    "pd.read_parquet(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formateo pre modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - parametros para modelo\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "mes_train = 202104\n",
    "mes_test = 202108\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['clase_peso'] = 1.0\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clase_binaria'] = np.where(data['clase_ternaria']=='CONTINUA', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = data[data['foto_mes']<=202106]\n",
    "df_test = data[data['foto_mes']==202108]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_peso = df_train['clase_peso']\n",
    "X_train = df_train.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_train =df_train['clase_binaria']\n",
    "X_test = df_test.drop(['clase_ternaria', 'clase_binaria', 'clase_peso'], axis=1)\n",
    "Y_test =df_test['clase_binaria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train = df_train.loc[X_train.index, 'clase_peso']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 11:24:00,504] Using an existing study with name 'competencia_02' instead of creating a new one.\n",
      "[I 2024-11-08 11:24:00,548] Using an existing study with name 'competencia_02' instead of creating a new one.\n",
      "[I 2024-11-08 11:25:26,175] Trial 1 finished with value: 484022000.0 and parameters: {'num_leaves': 73, 'learning_rate': 0.048381168713106194, 'min_data_in_leaf': 1888, 'feature_fraction': 0.9611290073992866, 'bagging_fraction': 0.5702627562564301}. Best is trial 1 with value: 484022000.0.\n",
      "[I 2024-11-08 11:26:34,198] Trial 2 finished with value: 454993000.0 and parameters: {'num_leaves': 28, 'learning_rate': 0.03703877249854557, 'min_data_in_leaf': 393, 'feature_fraction': 0.2450786254076267, 'bagging_fraction': 0.23471371488088055}. Best is trial 1 with value: 484022000.0.\n",
      "[I 2024-11-08 11:28:04,561] Trial 3 finished with value: 489223000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.05486123634370735, 'min_data_in_leaf': 1380, 'feature_fraction': 0.6184913544411021, 'bagging_fraction': 0.4808902093417563}. Best is trial 3 with value: 489223000.0.\n",
      "[W 2024-11-08 11:28:09,636] Trial 4 failed with parameters: {'num_leaves': 70, 'learning_rate': 0.09504714430284956, 'min_data_in_leaf': 1329, 'feature_fraction': 0.6429553572890628, 'bagging_fraction': 0.8918113531122719} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2908\\754118112.py\", line 33, in objective\n",
      "    cv_results = lgb.cv(\n",
      "                 ^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\engine.py\", line 827, in cv\n",
      "    res = _agg_cv_result(cvfolds.eval_valid(feval))  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\engine.py\", line 402, in handler_function\n",
      "    ret.append(getattr(booster, name)(*args, **kwargs))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py\", line 4413, in eval_valid\n",
      "    return [\n",
      "           ^\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py\", line 4416, in <listcomp>\n",
      "    for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py\", line 5177, in __inner_eval\n",
      "    feval_ret = eval_function(self.__inner_predict(data_idx), cur_data)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2908\\3141376051.py\", line 4, in lgb_gan_eval\n",
      "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
      "                        ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 1133, in argsort\n",
      "    return _wrapfunc(a, 'argsort', axis=axis, kind=kind, order=order)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 59, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-11-08 11:28:09,640] Trial 4 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 105\u001b[0m\n\u001b[0;32m     97\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[0;32m     98\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     99\u001b[0m     study_name\u001b[38;5;241m=\u001b[39mstudy_name,\n\u001b[0;32m    100\u001b[0m     storage\u001b[38;5;241m=\u001b[39mstorage_name,\n\u001b[0;32m    101\u001b[0m     load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    102\u001b[0m )\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Optimizar el estudio con el callback personalizado\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30000\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         _optimize_sequential(\n\u001b[0;32m     63\u001b[0m             study,\n\u001b[0;32m     64\u001b[0m             func,\n\u001b[0;32m     65\u001b[0m             n_trials,\n\u001b[0;32m     66\u001b[0m             timeout,\n\u001b[0;32m     67\u001b[0m             catch,\n\u001b[0;32m     68\u001b[0m             callbacks,\n\u001b[0;32m     69\u001b[0m             gc_after_trial,\n\u001b[0;32m     70\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     71\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[105], line 33\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      8\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     27\u001b[0m }\n\u001b[0;32m     29\u001b[0m train_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_train,\n\u001b[0;32m     30\u001b[0m                          label\u001b[38;5;241m=\u001b[39mY_train,  \u001b[38;5;66;03m# elegir la clase\u001b[39;00m\n\u001b[0;32m     31\u001b[0m                          weight\u001b[38;5;241m=\u001b[39mw_train)\n\u001b[1;32m---> 33\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mcv(\n\u001b[0;32m     34\u001b[0m     params,\n\u001b[0;32m     35\u001b[0m     train_data,\n\u001b[0;32m     36\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m,  \u001b[38;5;66;03m# modificar, subir y subir... y descomentar la línea inferior\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \n\u001b[0;32m     38\u001b[0m     feval\u001b[38;5;241m=\u001b[39mlgb_gan_eval,\n\u001b[0;32m     39\u001b[0m     stratified\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     40\u001b[0m     nfold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     41\u001b[0m     seed\u001b[38;5;241m=\u001b[39msemillas[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     44\u001b[0m max_gan \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid gan_eval-mean\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     45\u001b[0m best_iter \u001b[38;5;241m=\u001b[39m cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid gan_eval-mean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mindex(max_gan) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\engine.py:827\u001b[0m, in \u001b[0;36mcv\u001b[1;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, feval, init_model, feature_name, categorical_feature, fpreproc, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[0m\n\u001b[0;32m    816\u001b[0m     cb(\n\u001b[0;32m    817\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[0;32m    818\u001b[0m             model\u001b[38;5;241m=\u001b[39mcvfolds,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    824\u001b[0m         )\n\u001b[0;32m    825\u001b[0m     )\n\u001b[0;32m    826\u001b[0m cvfolds\u001b[38;5;241m.\u001b[39mupdate(fobj\u001b[38;5;241m=\u001b[39mfobj)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 827\u001b[0m res \u001b[38;5;241m=\u001b[39m _agg_cv_result(cvfolds\u001b[38;5;241m.\u001b[39meval_valid(feval))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, key, mean, _, std \u001b[38;5;129;01min\u001b[39;00m res:\n\u001b[0;32m    829\u001b[0m     results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-mean\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(mean)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\engine.py:402\u001b[0m, in \u001b[0;36mCVBooster.__getattr__.<locals>.handler_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m booster \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboosters:\n\u001b[1;32m--> 402\u001b[0m     ret\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mgetattr\u001b[39m(booster, name)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:4413\u001b[0m, in \u001b[0;36mBooster.eval_valid\u001b[1;34m(self, feval)\u001b[0m\n\u001b[0;32m   4381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_valid\u001b[39m(\n\u001b[0;32m   4382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4383\u001b[0m     feval: Optional[Union[_LGBM_CustomEvalFunction, List[_LGBM_CustomEvalFunction]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4384\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[_LGBM_BoosterEvalMethodResultType]:\n\u001b[0;32m   4385\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate for validation data.\u001b[39;00m\n\u001b[0;32m   4386\u001b[0m \n\u001b[0;32m   4387\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4411\u001b[0m \u001b[38;5;124;03m        List with (validation_dataset_name, eval_name, eval_result, is_higher_better) tuples.\u001b[39;00m\n\u001b[0;32m   4412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m   4414\u001b[0m         item\n\u001b[0;32m   4415\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)\n\u001b[0;32m   4416\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__inner_eval(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_valid_sets[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], i, feval)\n\u001b[0;32m   4417\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:4416\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   4381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_valid\u001b[39m(\n\u001b[0;32m   4382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4383\u001b[0m     feval: Optional[Union[_LGBM_CustomEvalFunction, List[_LGBM_CustomEvalFunction]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4384\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[_LGBM_BoosterEvalMethodResultType]:\n\u001b[0;32m   4385\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate for validation data.\u001b[39;00m\n\u001b[0;32m   4386\u001b[0m \n\u001b[0;32m   4387\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4411\u001b[0m \u001b[38;5;124;03m        List with (validation_dataset_name, eval_name, eval_result, is_higher_better) tuples.\u001b[39;00m\n\u001b[0;32m   4412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m   4414\u001b[0m         item\n\u001b[0;32m   4415\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)\n\u001b[1;32m-> 4416\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__inner_eval(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_valid_sets[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], i, feval)\n\u001b[0;32m   4417\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\lightgbm\\basic.py:5177\u001b[0m, in \u001b[0;36mBooster.__inner_eval\u001b[1;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[0;32m   5175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5176\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m-> 5177\u001b[0m feval_ret \u001b[38;5;241m=\u001b[39m eval_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__inner_predict(data_idx), cur_data)\n\u001b[0;32m   5178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feval_ret, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m   5179\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m eval_name, val, is_higher_better \u001b[38;5;129;01min\u001b[39;00m feval_ret:\n",
      "Cell \u001b[1;32mIn[45], line 4\u001b[0m, in \u001b[0;36mlgb_gan_eval\u001b[1;34m(y_pred, data)\u001b[0m\n\u001b[0;32m      2\u001b[0m weight \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget_weight()\n\u001b[0;32m      3\u001b[0m ganancia \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.00002\u001b[39m, ganancia_acierto, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(weight \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1.00002\u001b[39m, costo_estimulo, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m ganancia \u001b[38;5;241m=\u001b[39m ganancia[np\u001b[38;5;241m.\u001b[39margsort(y_pred)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m      5\u001b[0m ganancia \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(ganancia)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgan_eval\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmax(ganancia) , \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1133\u001b[0m, in \u001b[0;36margsort\u001b[1;34m(a, axis, kind, order)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margsort\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \n\u001b[0;32m   1132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margsort\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, kind\u001b[38;5;241m=\u001b[39mkind, order\u001b[38;5;241m=\u001b[39morder)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datascience\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    num_leaves = trial.suggest_int('num_leaves', 8, 100)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.00005, 0.3)  # mas bajo, más iteraciones necesita\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 2000)\n",
    "    feature_fraction = trial.suggest_float('feature_fraction', 0.1, 1.0)\n",
    "    bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom', \n",
    "        'boosting_type': 'gbdt',\n",
    "        'device': 'gpu',  # Usar la GPU\n",
    "        'gpu_platform_id': 0,  # (opcional) ID de la plataforma GPU\n",
    "        'gpu_device_id': 0,     # (opcional) ID del dispositivo GPU\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'device': 'gpu',\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'min_data_in_leaf': min_data_in_leaf,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'seed': semillas[0],\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                             label=Y_train,  # elegir la clase\n",
    "                             weight=w_train)\n",
    "                             \n",
    "    cv_results = lgb.cv(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=300,  # modificar, subir y subir... y descomentar la línea inferior\n",
    "        \n",
    "        feval=lgb_gan_eval,\n",
    "        stratified=True,\n",
    "        nfold=5,\n",
    "        seed=semillas[0]\n",
    "    )\n",
    "\n",
    "    max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "    best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "    # Guardamos cual es la mejor iteración del modelo\n",
    "    trial.set_user_attr(\"best_iter\", best_iter)\n",
    "\n",
    "    return max_gan * 5\n",
    "\n",
    "storage_name = rf\"sqlite:///{optuna_path}\"\n",
    "\n",
    "study_name = \"competencia_02\"\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "import optuna\n",
    "\n",
    "class EarlyStoppingByImprovement:\n",
    "    def __init__(self, patience: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Número de pruebas consecutivas sin mejora antes de detener la optimización.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.best_value = None\n",
    "        self.no_improvement_trials = 0\n",
    "\n",
    "    def __call__(self, study, trial):\n",
    "        current_best_value = study.best_trial.value\n",
    "\n",
    "        # Si la métrica mejora, reseteamos el contador\n",
    "        if self.best_value is None or current_best_value > self.best_value:\n",
    "            self.best_value = current_best_value\n",
    "            self.no_improvement_trials = 0\n",
    "        else:\n",
    "            # Si no hay mejora, incrementamos el contador\n",
    "            self.no_improvement_trials += 1\n",
    "\n",
    "        # Detener si no ha habido mejora en 'self.patience' pruebas consecutivas\n",
    "        if self.no_improvement_trials >= self.patience:\n",
    "            print(f\"Early stopping: No hay mejora en {self.patience} pruebas consecutivas.\")\n",
    "            study.stop()\n",
    "\n",
    "# Crear el callback con 100 pruebas consecutivas sin mejora\n",
    "early_stopping_callback = EarlyStoppingByImprovement(patience=100)\n",
    "\n",
    "# Crear el estudio\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "# Optimizar el estudio con el callback personalizado\n",
    "study.optimize(objective, n_trials=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor cantidad de árboles para el mejor model 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2908\\1798680220.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_voting['promedio'] = df_voting.mean(axis=1)\n"
     ]
    }
   ],
   "source": [
    "best_iter = study.best_trial.user_attrs[\"best_iter\"]\n",
    "print(f\"Mejor cantidad de árboles para el mejor model {best_iter}\")\n",
    "\n",
    "train_data = lgb.Dataset(X_train,\n",
    "                            label=Y_train,\n",
    "                            weight=w_train)\n",
    "\n",
    "df_voting = pd.DataFrame()\n",
    "\n",
    "for semilla in numeros_random:\n",
    "    params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': study.best_params['num_leaves'],\n",
    "    'learning_rate': study.best_params['learning_rate'],\n",
    "    'min_data_in_leaf': study.best_params['min_data_in_leaf'],\n",
    "    'feature_fraction': study.best_params['feature_fraction'],\n",
    "    'bagging_fraction': study.best_params['bagging_fraction'],\n",
    "    'seed': semilla,\n",
    "    'verbose': 0\n",
    "}\n",
    "    \n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=best_iter)\n",
    "    \n",
    "    df_voting[f'semilla_{semilla}'] = model.predict(X_test)\n",
    "\n",
    "df_voting['promedio'] = df_voting.mean(axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgm = df_voting['promedio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_labels = (y_pred_lgm > 0.025).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe con las variables más importantes\n",
    "importancias = model.feature_importance()\n",
    "nombres = model.feature_name()\n",
    "df_variables_importantes = pd.DataFrame({'importancia': importancias, 'variable': nombres})\n",
    "df_variables_importantes = df_variables_importantes.sort_values(by='importancia', ascending=False)\n",
    "lista_variables_importantes =  df_variables_importantes['variable'].head(10).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado = pd.DataFrame({\n",
    "    'numero_de_cliente': X_test['numero_de_cliente'],\n",
    "    'Predicted': y_pred_labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# numero = '006'\n",
    "# entrega = f'entrega_{numero}.csv'\n",
    "# path = r\"C:\\Users\\Admin\\Documents\\1_Notebook\\1_Estudio\\1_UBA_Maestria_DS\\1_Especializacion\\1_Segundo_Semestre\\DMEyF\\Entregas\"\n",
    "# archivos = glob.glob(os.path.join(path, '*'))\n",
    "# archivos.sort(key=os.path.getmtime, reverse=True)\n",
    "# ultimo_archivo = archivos[0] if archivos else None\n",
    "# if ultimo_archivo:\n",
    "#     nombre_archivo = os.path.basename(ultimo_archivo)\n",
    "#     numero = ''.join(filter(str.isdigit, nombre_archivo))\n",
    "#     print(f\"El último archivo entregado es: {nombre_archivo}\")\n",
    "#     print(f\"El número extraído es: {numero}\")\n",
    "# else:\n",
    "#     print(\"No se encontraron archivos en la carpeta.\")\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ingresar el path sobre el cual se quiere ingresar el archivo a entregar\n",
    "entrega = 'entrega_kaggle'\n",
    "formato = '.csv'\n",
    "numero = entrega+'_001'+formato\n",
    "entrega_final = df_resultado.to_csv(rf\"{save_path}{numero}}\", index=False)\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_columnas = df_gbm.shape[1]\n",
    "message = f\"{entrega}, cantidad de columnas en el train: {cantidad_columnas}, modelo: LGBM, mejores parametros: {best_params}, mejor iteracion: {best_iter}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Kaggle -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "competition= 'DMEyF-2024-Segunda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.api.competition_submit(competition=competition, file_name= numero, message=message, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puntos de corte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predicciones = y_pred_lgm\n",
    "\n",
    "# X_test['Probabilidad'] = predicciones\n",
    "\n",
    "# tb_entrega = X_test.sort_values(by='Probabilidad', ascending=False)\n",
    "\n",
    "# cortes = range(9000,14000,100)\n",
    "\n",
    "# num_subida_kaggle = 65\n",
    "# for envios in cortes:\n",
    "    \n",
    "#     tb_entrega['Predicted'] = 0\n",
    "#     tb_entrega.iloc[:envios, tb_entrega.columns.get_loc('Predicted')] = 1\n",
    "#     resultados = tb_entrega[[\"numero_de_cliente\", 'Predicted']].reset_index(drop=True)\n",
    "    \n",
    "#     print(\"Cantidad de clientes {}\".format(envios))\n",
    "    \n",
    "#     nombre_archivo = 'entrega_0{}.csv'.format(num_subida_kaggle)\n",
    "#     entrega_final = os.path.join(path, nombre_archivo)\n",
    "#     resultados.to_csv(entrega_final, index=False)\n",
    "    \n",
    "    \n",
    "#     cantidad_columnas = df_train.shape[1]\n",
    "#     message = f\"{entrega}, cantidad de columnas en el train: {cantidad_columnas}, modelo: LGBM, mejores parametros: {best_params}, mejor iteracion: {best_iter}, archivo: {entrega_final}, punto de corte: {envios}, optimizado con optuna: {study_name}\"\n",
    "    \n",
    "#     num_subida_kaggle += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "#     entrega_final = os.path.join(path, nombre_archivo)   \n",
    "#     competencia = 'dm-ey-f-2024-primera'\n",
    "#     try:\n",
    "#         api.competition_submit(file_name=entrega_final,message=message,competition=competencia)\n",
    "#     except:\n",
    "#         print(f\"Numero máximo de envios, último envio ={num_subida_kaggle}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre_modelo = 'lgbm_e_en_abril_p_en_junio_451_features.txt'\n",
    "# model.save_model(rf\"C:\\Users\\Admin\\Documents\\1_Notebook\\1_Estudio\\1_UBA_Maestria_DS\\1_Especializacion\\1_Segundo_Semestre\\DMEyF\\modelos_lgbm\\{nombre_modelo}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
